\chapter{Setting up the system}
\label{chap:setup}

\section{\texttt{part}: Setting up particles}
\label{sec:part}

\tclcommand{part}
{
\var{particle\_number}\\
  \opt{pos \var{x} \var{y} \var{z}}
  \opt{type \var{particle\_type\_number}}
  \opt{q \var{charge}}
  \opt{v \var{x\_value} \var{y\_value} \var{z\_value}}
  \opt{f \var{x\_value} \var{y\_value} \var{z\_value}}
  \opt{quat \var{q1} \var{q2} \var{q3} \var{q4}}
  \opt{omega \var{x\_value} \var{y\_value} \var{z\_value}}
  \opt{torque \var{x\_value} \var{y\_value} \var{z\_value}}
  \opt{\opt{un}fix \var{x} \var{y} \var{z}}
  \opt{ext\_force \var{x\_value} \var{y\_value} \var{z\_value}}
  \opt{bond \var{bond\_type\_number}}
  \opt{exclude \var{exclusion\_partner}}
  \opt{delete}
}

This command modifies particle data, namely position, type (monomer, ion, ...), charge, velocity, force and bonds. Multiple properties can be changed at once. If you add a new particle the position has to be set first because of the spatial decomposition.

\begin{arguments}
\item[\var{particle\_number}]
\item[\opt{pos \var{x} \var{y} \var{z}}] Sets the position of this particle to (x,y,z).
\item[\opt{type \var{particle\_type\_number}}] Restrictions: \var{particle\_type\_type\_number} $\geq 0$.
The \var{particle\_type\_number} is used in the inter command to define the parameters of the non bonded interactions between different kinds of particles.
\item[\opt{q \var{charge}}]
\item[\opt{v \var{x\_value} \var{y\_value} \var{z\_value}}]
\item[\opt{f \var{x\_value} \var{y\_value} \var{z\_value}}]
If flag ROTATION is set in config.h, particle properties such as quat, omega and torque can be used:
\item[\opt{quat \var{q1} \var{q2} \var{q3} \var{q4}}]
\item[\opt{omega \var{x\_value} \var{y\_value} \var{z\_value}}]
\item[\opt{torque \var{x\_value} \var{y\_value} \var{z\_value}}]
\item[\opt{fix \var{x} \var{y} \var{z}}] Fixes the particle in space. By supplying a set of 3 integers as arguments it is possible to fix motion in \var{x}, \var{y}, or \var{z} coordinates independetly. For example \var{fix 0 0 1} will fix motion only in z. Note that \var{fix} without arguments is equivalent to \var{fix 1 1 1} (Needs compiled flag EXTERNAL\_FORCES in config.h).
\item[\opt{ext\_force \var{x\_value} \var{y\_value} \var{z\_value}}] An additional external force is applied to the particle (Needs compiled flag EXTERNAL\_FORCES in config.h).
\item[\opt{unfix}] Release any external influence from the particle (Needs compiled flag EXTERNAL\_FORCES in config.h).
\item[\opt{bond \var{bond\_type\_number} \var{partner}+}] Restrictions: \var{bond\_type\_number} $\geq 0$; \var{partner} must be an existing particle.
The \var{bond\_type\_number} is used for the inter command to define bonded interactions.
\item[\opt{exclude \var{exclusion\_partner}+}] Restrictions: \var{exclusion\_partner} must be an existing particle. 
Between the current particle an the exclusion partner(s), no nonbonded interactions are calculated (Needs compiled flag EXTERNAL\_FORCES in config.h). Note that unlike bonds, exclusions are stored with both partners.
Therefore this command adds the defined exclusions to both partners.
\item[\opt{exclude delete \var{exclusion\_partner}+}] Searches for the given exclusion and deletes it. Again deletes the exclusion with both partners.
\item[bond delete] Will delete all bonds attached to this particle.

\end{arguments}

\begin{code}
part <particle_number> delete
\end{code}
If instead of a property "delete" is given, the particle is deleted and all bonds referencing it.
\begin{code}
part <particle_number> print (id|pos|folded_position|type|q|v|f|fix
|ext_force|bond|connections)*
\end{code}
If instead of a property "print" is given the specified properties are written in a simple list form like.
\begin{code}
40 8.849 1.8172 1.4677 1.0 {}
\end{code}
generated by
\begin{code}
part 40 print id pos q bonds
\end{code}
This routine is primarily meant for effective use in Tcl scripts (see e. g. tcl\_blockfile\_write\_particles).

If no property is given,
\begin{code}
part <particle_number>
\end{code}
returns all properties of the particle, if it exists, in the form
\begin{tclcode}
0 pos 2.1 6.4 3.1 type 0 q -1.0 v 0.0 0.0 0.0 f 0.0 0.0 0.0
 bonds { {0 480} {0 368} ... } 
\end{tclcode}
which may be used as an input to this function later on. The first integer is the particle number. 
\begin{code}
part <particle_number> print connections [<range>]
\end{code}
Returns the connectivity of the particle up to a certain number of bonds specified by \var{range} (defaults to 1). For particle 5 in a linear chain the result up to range = 3 would look like:
\begin{tclcode}
{ { 4 } { 6 } } { { 4 3 } { 6 7 } } { {4 3 2 } { 6 7 8 } } 
\end{tclcode}
The function is useful when you want to create bonded interactions to all other particles a certain particle is connected to. Note that this output can not be used as input to the part command. Check results if you use them in ring structures.

\begin{tclcode}
part deleteall 
\end{tclcode}
deletes all particles currently present in the simulation.

Without any parameters at all,
\begin{tclcode}
part auto_exclusions [<range>]
\end{tclcode}
creates exclusions for all particles pairs connected by not more than \var{range} bonds (\var{range} defaults to 2). This is typically used in atomistic simulations, where nearest and next nearest neigbor interactions along the chain have to be omitted since they are included in the bonding potentials. For example, if the system contains particles 0...100, where particle n is bonded to particle n-1 for 1$\leq$n$\leq$100, then part auto\_exclusions will result in the exclusions:
\begin{itemize}
  \item particle 1 does not interact with particles 2 and 3
  \item particle 2 does not interact with particles 1, 3 and 4
  \item particle 3 does not interact with particles 1, 2, 4 and 5
  \item ...
\end{itemize}

\begin{tclcode}
part delete_exclusions
\end{tclcode}
deletes all exclusions currently present in the system.

\begin{tclcode}
part
\end{tclcode}
returns the properties of all stored particles in a tcl-list with the same format as specified above:
\begin{tclcode}
{0 pos 2.1 6.4 3.1 type 0 q -1.0 v 0.0 0.0 0.0 f 0.0 0.0 0.0
 bonds{{0 480}{0 368}...}} 
{1 pos 1.0 2.0 3.0 type 0 q 1.0 v 0.0 0.0 0.0 f 0.0 0.0 0.0
 bonds{{0 340}{0 83}...}} 
{2...{{...}...}}
{3...{{...}...}}
...
\end{tclcode}

\section{\texttt{polymer}: Setting up polymer chains}
\label{sec:polymer}

\tclcommand{polymer}
{\var{num\_polymers} 
  \var{monomers\_per\_chain} 
  \var{bond\_length}\\{}
  \opt{start \var{part\_id}}
  \opt{pos \var{x} \var{y} \var{z}}
  \opt{mode < RW | SAW | PSAW > [\var{shield} [\var{max\_try}]]}
  \opt{charge \var{val\_charged\_monomer}}
  \opt{distance \var{dist\_charged\_monomer}}
  \opt{types \var{type\_neutral\_monomer} [\var{type\_charged\_monomer}]}
  \opt{bond \var{type\_bond}}
  \opt{angle \var{phi} [\var{theta} [\var{x} \var{y} \var{z}]]}
}

This command will create \var{num\_polymers} polymer or
polyelectrolyte chains with \var{monomers\_per\_chain} monomers per
chain. The length of the bond between two adjacent monomers will be
set up to be \var{bond\_length}.

\begin{arguments}
\item[\var{num\_polymers}] Sets the number of polymer chains.
\item[\var{monomers\_per\_chain}] Sets the number of monomers per
  chain.
\item[\var{bond\_length}] Sets the distance between two adjacent
  monomers.
\item[\opt{start \var{part\_id}}] Sets the particle number of the
  start monomer to be used with the \keyword{part} command. This
  defaults to 0.

\item[\opt{pos \var{x} \var{y} \var{z}}] Sets the position of the
  first monomer in the chain to \var{x}, \var{y}, \var{z} (defaults to
  a randomly chosen value)
  
\item[\opt{mode < RW | PSAW | SAW > [\var{shield} [\var{max\_try}]]}]
  Selects the setup mode:
  \begin{description}
  \item[\keyword{RW} (Random walk)] The monomers are
    randomly placed by a random walk with a steps size of
    \var{bond\_length}.
  \item[\keyword{PSAW} (Pruned self-avoiding walk)] The position of a
    monomer is randomly chosen in a distance of \var{bond\_length} to
    the previous monomer. If the position is closer to another
    particle than \var{shield}, the attempt is repeated up to
    \var{try\_max} times. Note, that this is not a real self-avoiding
    random walk, as the particle distribution is not the same. If you
    want a real self-avoiding walk, use the \keyword{SAW} mode.
    However, \keyword{PSAW} is several orders of magnitude faster than
    \keyword{SAW}, especially for long chains.
  \item[\keyword{SAW} (Self-avoiding random walk)] The positions of
    the monomers are chosen as in the plain random walk. However, if
    this results in a chain that has a monomer that is closer to
    another particle than \var{shield}, a new attempt of setting up
    the whole chain is done, up to \var{max\_try} times.
  \end{description}
  The default for the mode is \keyword{RW}, the default for the
  \var{shield} is $1.0$, and the default for \var{max\_try} is
  $30000$, which is usually enough for \keyword{PSAW}. Depending on
  the length of the chain, for the \keyword{SAW} mode, \var{max\_try}
  has to be increased by several orders of magnitude.
\item[\opt{charge \var{val\_charged\_monomer}}] Sets the valency of
  the charged monomers.  If the valency of the charged polymers
  \var{val\_charged\_monomer} is smaller than $10^{-10}$, the charge
  is assumed to be zero, and the types are set to
  \var{type\_charged\_monomer} = \var{type\_neutral\_monomer}. This
  defaults to 0.0.

\item[\opt{distance \var{dist\_charged\_monomer}}] Sets the stride
  between the indices of two charged monomers. This defaults defaults
  to 1, meaning that all monomers in the chain are charged.
  
\item[\opt{types \var{type\_neutral\_monomer}
    \var{type\_charged\_monomer}}] Sets the type numbers of the
  neutral and charged monomer types to be used with the \keyword{part}
  command. If \var{type\_neutral\_monomer} is defined,
  \var{type\_charged\_monomer} defaults to 1. If the option is
  omitted, both monomer types default to 0.
  
\item[\opt{bond \var{type\_bond}}] Sets the type number of the bonded
  interaction to be set between the monomers. This defaults to 0.
  
\item[\opt{angle \var{phi} [\var{theta} [\var{x} \var{y} \var{z}]]}]
  Allows for setting up helices or planar polymers: \var{phi} sets
  the angle $\phi$ and \var{theta} sets the angle $\theta$ between
  adjacent bonds. \var{x}, \var{y} and \var{z} set the position of the
  second monomer of the first chain.
\end{arguments}

\section{\texttt{inter}: Setting up interactions}
\label{sec:inter}

\subsection{Nonbonded interactions}
\label{sec:inter_nb}
%\quickrefheading{Nonbonded interactions}

\tclcommand[LENNARD\_JONES]{inter}{%
  \var{type1 type2} 
  lennard\_jones 
  \var{epsilon sigma cutoff shift offset}
}

Defines a Lennard-Jones interaction between particles of the types
\var{type1} and \var{type2}.

$4\varepsilon((\frac{\sigma}{r-offset})^{12}-(\frac{\sigma}{r-offset})^6+shift)\\$
The potential is cut off if
$r > offset+cutoff$
For system warmup you can cap the Lennard-Jones potential with a maximal force which can be set with:
\begin{tclcode}
inter ljforcecap <maxforce> 
\end{tclcode}
 For particle distances which would lead to larger forces than \var{maxforce} the Lennard-Jones potential is replaced by \var{$r* maxforce$}
Particles placed exactly on top of each other will be subject to a force of magnitude \var{maxforce} applied in $\pm x$ direction. To return to the uncapped potential you have to set \var{maxforce} to zero using
\begin{tclcode}
inter ljforcecap 0
\end{tclcode}
Note that ljforcecap applies to all given Lennard-Jones interactions regardless of the particle types.

\tclcommand{inter}{%
  \var{type1 type2} 
  soft-sphere
  \var{a n cut offset}
}

Todo: write documentation for soft-sphere

\tclcommand{inter}{%
  \var{type1 type2} 
  lj-cos
  \var{epsilon sigma cutoff offset}
}
the Lennard-Jones+Cosine potential (Soddemann et. al. Eur. Phys. J. E. 6, 409-419 (2001))

for $r < r_{min} = offset * 2^{\frac{1}{6}} * \sigma$ :
\begin{center}
$4\varepsilon((\frac{\sigma}{r-offset})^{12}-(\frac{\sigma}{r-offset})^6)$
\end{center}
for $cutoff > r > r_{min} = offset * 2^{\frac{1}{6}} * \sigma$ :
\begin{center}
$\frac{1}{2}\varepsilon(cos(\alpha(r-offset)^2 + \beta)-1)$
\end{center}
where $\alpha$ and $\beta$ are given by:

$\alpha = \frac{\pi}{(cutoff-offset)^2-(r_{min}-offset)^2}\\$

$\beta = \pi * (1 - \frac{(r_{min}-offset)^2}{(cutoff-offset)^2-(r_{min}-offset)^2})\\$


\tclcommand{inter}{%
  \var{type1 type2} 
  lj-cos2
  \var{epsilon sigma offset $\omega$}
}

for $r < r_{change} = offset * 2^{\frac{1}{6}} * \sigma$ :
\begin{center}
$4 \varepsilon((\frac{\sigma}{r-offset})^{12}-(\frac{\sigma}{r-offset})^6)$
\end{center}
for $cutoff = offset * 2^{\frac{1}{6}} * \sigma + \omega > r > r_{change}$:
\begin{center}
$\varepsilon * cos^2(\frac{\pi * (r - r_{change})}{2 * \omega})$
\end{center}

The potential can be capped in the same way as the Lennard-Jones potential. The forcecap is also set using:

\begin{tclcode}
inter ljforcecap <maxforce>
\end{tclcode}

\tclcommand{inter}{%
  \var{type1 type2} 
  morse
  \var{epsilon alpha rmin cut}
}

Todo: write documentation for morse

\tclcommand{inter}{%
  \var{type1 type2} 
  buckingham
  \var{A B C D cut discontinuity shift}
}

Todo: write documentation for buckingham

\tclcommand[TABULATED]{inter}{%
  \var{type1 type2} 
  tabulated
  \var{filename}
}

An arbitrary tabulated non-bonded pair potential.

To use this potential you must provide a file which contains the tabulated forces and energies as a function of the separation distance.

At present the required file format is simply an ordered list separated by whitespace. The data reader first looks for a $\sharp$ character and begins reading from that point in the file. Anything before the $\sharp$ will be ignored.

The first parameter you should supply in the file is the number of data points in the table. This should be an integer. Take care when choosing an appropriate value for the number of points remembering that a copy of each lookup table is kept on each node and must be referenced very frequently.

The second parameter you should supply is the minimum tabulated separation distance. The third parameter should be the maximum tabulated separation distance This will act as the effective cutoff value for the potential. Between minval and maxval the force and energy are assumed to be tabulated at fixed intervals such that the size of this interval is given by:

$\frac{maxval-minval}{n-1}$

Where $ n $ is the number of data points in the table

The remaining data in the file should consist of n data triples \var{distance} \var{force} \var{energy}. Note that distance is only included for human readability of the file. Its values do not matter but it must be present to satisfy the file read format. In the future a more structured file format will be required for the tabulated input file. The values of force and energy should be given as follows:

force: $-\frac{U'(r)}{r}$

energy: $U(r)$

\tclcommand{inter}{%
  \var{type1 type2} 
  gay-berne
  \var{epsilon sigma cutoff k1 k2 mu nu}
}

the Gay-Berne potential for prolate and oblate particles. The Gay-Berne potential is an anisotropic version of the classic Lennard-Jones potential, with orientational dependence in the range and well-depth functions $\sigma$ and $\epsilon$:


the Gay-Berne potential for prolate and oblate particles. The Gay-Berne potential is an anisotropic version of the classic Lennard-Jones potential, with orientational dependence in the range and well-depth functions $\sigma$ and $\epsilon$:



\[ U(\mathbf{r}_{ij}, \mathbf{\hat{u}}_i, \mathbf{\hat{u}}_j) = 4 \epsilon(\mathbf{\hat{r}}_{ij}, \mathbf{\hat{u}}_i, \mathbf{\hat{u}}_j) \left[ \left(\frac {\sigma_0}{\mathbf{r}_{ij}-\sigma(\mathbf{\hat{r}}_{ij}, \mathbf{\hat{u}}_i, \mathbf{\hat{u}}_j)+\sigma_0}\right)^{12}- \left(\frac {\sigma_0}{\mathbf{r}_{ij}-\sigma(\mathbf{\hat{r}}_{ij}, \mathbf{\hat{u}}_i, \mathbf{\hat{u}}_j)+\sigma_0}\right)^{6} \right] \]

where

\[ \sigma( \mathbf{\hat{r}}_{ij}, \mathbf{\hat{u}}_i, \mathbf{\hat{u}}_j) = \sigma_{0} \left\{ 1 - \frac{1}{2} \chi \left[ \frac{ \left( \mathbf{\hat{r}}_{ij} \cdot \mathbf{\hat{u}}_i + \mathbf{\hat{r}}_{ij} \cdot \mathbf{\hat{u}}_j \right)^{2} } {1 + \chi \left( \mathbf{\hat{u}}_i.\mathbf{\hat{u}}_j \right) } + \frac{ \left( \mathbf{\hat{r}}_{ij} \cdot \mathbf{\hat{u}}_i - \mathbf{\hat{r}}_{ij} \cdot \mathbf{\hat{u}}_j \right)^{2} } {1 - \chi \left( \mathbf{\hat{u}}_i \cdot \mathbf{\hat{u}}_j \right) } \right] \right\}^{-\frac{1}{2}} \]

and

\[ \epsilon(\mathbf{\hat{r}}_{ij}, \mathbf{\hat{u}}_i, \mathbf{\hat{u}}_j) = \epsilon_0 \left( 1- \chi^{2}(\mathbf{\hat{u}}_i \cdot \mathbf{\hat{u}}_j) \right)^{-\frac {\nu}{2}} \left[1-\frac {\chi'}{2} \left( \frac { (\mathbf{\hat{r}}_{ij} \cdot \mathbf{\hat{u}}_i+ \mathbf{\hat{r}}_{ij} \cdot \mathbf{\hat{u}}_j)^{2}} {1+\chi' \, \mathbf{\hat{u}}_i \cdot \mathbf{\hat{u}}_j }+ \frac {(\mathbf{\hat{r}}_{ij} \cdot \mathbf{\hat{u}}_i-\mathbf{\hat{r}}_{ij} \cdot \mathbf{\hat{u}}_j)^{2}} {1-\chi' \, \mathbf{\hat{u}}_i \cdot \mathbf{\hat{u}}_j } \right) \right]^{\mu} \] 

re unit vectors $ \mathbf{\hat{u}}_i $ and $ \mathbf{\hat{u}}_j $ give the orientation of the two particles and vector $ \mathbf{r}_{ij} = r_{ij} \mathbf{\hat{r}}_{ij} $ is the intermolecular vector.

The parameters $ \chi = \frac{k_1^{2} - 1}{k_1^{2} + 1 } $ and $ \chi' = \frac{k_2^{1/\mu} - 1}{k_2^{1/\mu} + 1 } $ are responsible for the degree of anisotropy of the molecular properties. $ k_1 $ is the molecular elongation, and $ k_2 $ is the ratio of the potential well depths for the side-by-side and end-to-end configurations. Exponents $ \mu $ and $ \nu $ are adjastable parameters of the potential. There are several Gay-Berne paremeterizations exist; the original one being $ k_1 = 3 $, $ k_1 = 5 $, $ \mu = 2 $ and $ \nu = 1 $.

\bigskip

\subsection{Bonded interactions}
\label{sec:inter_bonded}

\index{Bonded interactions} \index{Bonded interaction type id} Bonded
interactions possess an \emph{bonded interaction type id}. On the one
hand, this id is used when particles and bonds between particles are
specified in the command \texttt{part} (see section \vref{sec:part}).
On the other hand, the id is used when the interaction is specified.

\tclcommand{inter}{%
  \var{bond\_type\_number} 
  fene
  \var{K\_fene R\_fene}
}

\[ U^{FENE} = -\frac{1}{2} K_{FENE} R_{FENE}^2 \ln \left( 1 - \left( \frac{r}{R_{FENE}} \right)^2 \right) \]

\tclcommand{inter}{%
  \var{bond\_type\_number} 
  harmonic
  \var{K\_harmonic R\_harmonic}
}

\[ U^{Harmonic} = \frac{1}{2} K_{harmonic} \left( r - R_{harmonic} \right)^2 \] 

\tclcommand{inter}{%
  \var{bond\_type\_number} 
  subt\_lj
  \var{K\_subt\_lj R\_subt\_lj}
}

This "bonded" interaction subtracts the Lennard-Jones force/energy of every bonded pair from the total force/energy. The first parameter,
\var{K\_subt\_lj}
is a dummy and is not used. The second parameter,
\var{R\_subt\_lj}
is used as a check. If the any bond length in the system exceeds this value, the program crashes. When not needed, this crashing can be disabled by commenting out a few lines in subt\_lj.h . When using this "bonded" interaction, it is worthwhile to consider capping the Lennard-Jones potential appropriately so that round-off errors can be avoided.


\tclcommand{inter}{%
  \var{bond\_type\_number} 
  angle
  \var{bend [phi0]}
}

<bend> is the bending constant in units of KT. The optional parameter <phi0> = $ \phi_o $ is the equilibirum bond angle in rad ranging from 0 to $ \pi $. If this paramter is not given the default value is $ \phi_o = \pi $ which corresponds to a stretched configuration.

\begin{itemize}
  \item Harmonic bond angle potential: (flag: BOND\_ANGLE\_HARMONIC)
      This potential is also used for example in YASP and good old polyMD.

      \[ U^{bend}_{harmonic} = \frac{bend}{2} (\phi - \phi_0)^2 \]

  \item Cosine bond angle potential: (flag: BOND\_ANGLE\_COSINE)
      The \es{} original!

      \[ U^{bend}_{cosine} = \frac{bend}{2} (1 + \cos(\phi - \phi0)) \]

  \item Cosine square bond angle potential: (flag: BOND\_ANGLE\_COSSQUARE)
      A form which is used for example in the GROMOS96 force field.

      \[ U^{bend}_{cossquare} = \frac{bend}{2} (\cos(\phi) - \cos(\phi_0))^2 \] 
\end{itemize}

\tclcommand{inter}{%
  \var{bond\_type\_number} 
  dihedral
  \var{mult bend phase}
}

\[ U^{dihedral} = bend \, (1 + phase \, \, cos(mult \, \phi)) \] 

Here $\phi$ is the dihedral angle defined by the particle quadrupel p1, p2, p3 and p4. \var{mult} is the multiplicity of the potential (number of minimas) and can take integer values from 1 to 6. <phase> is a phase parameter which takes the values $\pm1$ and \var{bend} is the bending constant of the potential. Together with appropriate Lennard-Jones interaction this potential can mimic a large number of atomic torsion potentials. The dihedral angle is the angle between the planes defined by the particle triples p1, p2 and p3 and p2, p3 and p4 as illustrated in the figure to the right. Dihedral bonds have to be stored at particle p2!.


\tclcommand[TABULATED]{inter}{%
  \var{bond\_type\_number} 
  tabulated
  \var{bond filename}
}
tabulated bonded potentials can be any potential for bond length potentials, bond angle potentials and dihedral angle potentials. The tabulated forces and energies have to be provided in a seperate file \var{filename}. The format of this file is identical to the one used for the non-bonded tabulated potentials (see the section about them above). The parameter \var{type} defines the type of the potential:

\begin{itemize}
  \item \var{type} = bond (two body interaction)

Tabulated bond length potential. The force acts in the direction of the connecting vector between the particles. The cutoff is given by the maximal tabulated distance. For distances smaller than the tabulated range it uses a linear extrapolation based on the first two tabulated force values. The C implementations are calc\_tab\_bond\_force and tab\_bond\_energy in tab.h.

  \item \var{type} = angle (three body interaction)

Tabulated bond angle potential (see also the normal implemented bond angle potentials). The force on p\_left and p\_right acts perpendicular to the connecting vector between the particle and p\_mid and in the plane defined by the three particles. The force on the middle particle balances the other two forces. The forces are scaled with the invers length of the connecting vectors. It is assumed that the potential is tabulated for all angles between 0 and $ \pi $. The C implementations are calc\_tab\_angle\_force and tab\_angle\_energy in tab.h.

  \item \var{type} = dihedral (three body interaction)

Tabulated torsional dihedral angle potenetial (see also the normal implemented dihedral potentials).It is assumed that the potential is tabulated for all angles between 0 and $ 2\pi $. This potential is not tested yet! Use on own risk. The C implementations are calc\_tab\_dihedral\_force and tab\_dihedral\_energy in tab.h.

\end{itemize}

\subsection{Coulomb interaction}
\label{sec:inter_electrostatics}

\tclcommand{inter}{%
  \var{bond\_type\_number} 
  coulomb
  \var{bjerrum\_length method parameters}
}

sets the method to calculate the electrostatic interaction.

\begin{tclcode}
inter coulomb 0.0
\end{tclcode}

disables coulomb interactions hence deactivating the electrostatic subsystem.

\begin{tclcode}
inter coulomb
\end{tclcode}

returns the actual parameters of the coulomb interaction as a tcl-list, e. g.

\begin{tclcode}
{coulomb 1.0 p3m 7.75 8 5 0.1138 0.0} {coulomb epsilon 0.1
n_interpol 32768 mesh_off 0.5 0.5 0.5}
\end{tclcode}

which has the correct format to be used as input to 'inter' as well. If

\begin{tclcode}
inter coulomb 0.0
\end{tclcode}

is returned, no electrostatics are active at the moment.

Implemented Methods are:

\subsubsection{P3M}

\tclcommand{inter}{%
  \var{bond\_type\_number} 
  p3m
  \var{r\_cut mesh cao alpha}
}

or

\tclcommand{inter}{%
  \var{bond\_type\_number} 
  p3m tune
  accuracy \var{value}
  [
    r\_cut \var{value}
    mesh \var{value}
    cao \var{value}
  ]
}

or

\tclcommand{inter}{%
  \var{bond\_type\_number} 
  p3m tunev2
  accuracy \var{value}
  [
    r\_cut \var{value}
    mesh \var{value}
    cao \var{value}
  ]
}

This is an implementation of the 1/r Coulomb potential

\[ U^{C-P3M} = \ell_B T \frac{q_1 q_2}{r} \]

with help of the P3M Method described elsewhere.

Make sure you know how to tune p3m parameters before using the automatic tuning feature. Details are described in the documentation of P3M\_tune\_parameters rsp P3M\_adaptive\_tune\_parameters.

The two tuning methods follow different methods for determining the optimal parameter. While the tune version simply tries out different values on a grid in the parameter space, the tunev2 version uses a bisection to determine the optimal parameters. In general, for small systems the tune version is faster, while for large systems tunev2 is faster. The results of tunev2 are always at least as good as the parameters achievable from the tune version, and normally the obtained accuracy is much closer to the desired value.

Note that any previous settings of r\_cut, cao and mesh will be remembered. So if you want to retune your electrostatics, e. g. after a major system change, you should use 

\begin{tclcode}
inter coulomb <bjerrum> p3m tune accuracy <acc> r_cut 0
mesh 0 cao 0
\end{tclcode}
Some additional p3m parameters have preset value
\begin{tclcode}
 epsilon = metallic 
\end{tclcode}
The dielectric constant of the surrounding medium, metallic (i.e.infinity) or some finite positive number.
\begin{tclcode}
 n_interpol = 32768 
\end{tclcode}
Number of interpolation points for the charge assignment function. When this is set to 0, interpolation is turned off.
\begin{tclcode}
 mesh_off = 0.5 0.5 0.5 
\end{tclcode}
Offset of the first mesh point from the lower left corner of the simulation box in units of the mesh constant. As soon as p3m is turned on the additional parameters can be changed with:
\begin{tclcode}
inter coulomb <parameter_name> <value(s)>
\end{tclcode}

Make sure that you know the relevance of the P3M parameters before using P3M !!!

\subsubsection{Debye-Hückel potential}

\begin{tclcode}
 dh <kappa> <r_cut>
\end{tclcode}

\[ U^{C-DH} = \ell_B T \frac{q_1 q_2 exp(-\kappa r)}{r} \]

For

\[ \kappa = 0 \]

this corresponds to the plain coulomb potential.
\subsubsection{MMM2D}
\begin{tclcode}
 mmm2d <maximal_pairwise_error> [<fixed_far_cutoff>]
\end{tclcode}
MMM2D coulomb method for systems with periodicity 1 1 0. Needs the layered cell system. The performance of the method depends on the number of slices of the cell system, which has to be tuned manually. It is automatically ensured that the maximal pairwise error is smaller than the given bound. The far cutoff setting should only be used for testing reasons, otherwise you are more safe with the automatical tuning. If you even don't know what it is, do not even think of touching the far cutoff. For details, see The MMM family of algorithms.

Make sure that you read the papers on MMM2D before using it !!!

\subsubsection{MMM1D}
\begin{tclcode}
mmm1d <switch_radius> [<bessel_cutoff>] <maximal_pairwise_error>
\end{tclcode}
or
\begin{tclcode}
mmm1d tune <maximal_pairwise_error>
\end{tclcode}
MMM1D coulomb method for systems with periodicity 0 0 1. Needs the nsquared cell system. The first form sets parameters manually. The switch radius determines at which xy-distance the force calculation switches from the near to the far formula. If the Bessel cutoff is not explicitly given, it is determined from the maximal pairwise error, otherwise this error only counts for the near formula. The second, tuning form just takes the maximal pairwise error and tries out a lot of switching radii to find out the fastest one. If this takes too long, you can change the value of the setmd variable "timings" which controls the number of test force calculations. For details, see The MMM family of algorithms.

Make sure that you read the papers on MMM2D before using MMM1D (there are no papers on MMM1D yet, but it is pretty much the same) !!!
\subsubsection{Maggs' method}
\begin{tclcode}
maggs <f_mass> <mesh> <field_friction>
\end{tclcode}
or
\begin{tclcode}
maggs <f_mass> <mesh> <field_friction> yukawa <kappa> <r_cut>
\end{tclcode}
This is an implementation of the instantaneous 1/r Coulomb interaction

\[ U = \ell_B T \frac{q_1 q_2}{r} \]

as the potential of mean force between charges which are dynamically coupled to a local electromagnetic field.

\var{f\_mass} is the mass of the field degree of freedom and equals to the square root of the inverted speed of light.

\var{mesh} is the number of mesh points for the interpolation of the electromagnetic field

\var{field\_friction} value of the friction coefficient for the transversal field degrees of freedom (reserved for future developments)

Unphysical self--energies, arised as a result of the lattice interpolation of charges, are corrected by a subtraction scheme based either on the exact lattice Green's function or the combination of the direct subtraction scheme plus the Yukawa subtraction scheme (second method).

For the case of Yukawa screened simulation (second method) one has to enter screening parameter \var{kappa} and the cut-off of the Yukawa potential \var{r\_cut}

\subsubsection{ELC}
\begin{tclcode}
inter coulomb elc <maximal_pairwise_error> <gap_size> [<far_cutoff>]
\end{tclcode}
This is a special procedure that converts a 3d method, i. e. P3M at the moment, to a 2d method, in computational order N. This is definitely faster than MMM2D for larger numbers of particles (>400 at reasonable accuracy requirements). The maximal pairwise error is the LUB error of the force between any two charges without prefactors (see the papers). The gap size gives the height of the empty region between the system box and the neighboring artificial images (again, see the paper). \es{} does not make sure that the gap is actually empty, this is the users responsibility. The method will compute fine of the condition is not fulfilled, however, the error bound will not be reached. Therefore you should really make sure that the gap region is empty (e. g. by constraints). The far cutoff finally is only intended for testing and allows to directly set the cutoff. In this case, the maximal pairwise error is ignored. The periodicity has to be set to 1 1 1 still, and the 3d method has to be set to epsilon metallic, i.e. metallic boundary conditions. For details, see The MMM family of algorithms.

Make sure that you read the papers on ELC before using it !!!

\subsection{Other interaction types}
\label{sec:inter_other}

\begin{tclcode}
inter <particle_type_number1> <particle_type_number1>
 comfixed <comfixed_flag>
\end{tclcode}
This interaction type applies a constraint on particles of type \var{particle\_type\_number1} such that during the integration the center of mass of these particles is fixed. This is accomplished as follows: The sum of all the forces acting on particles of type \var{particle\_type\_number1} are calculated. These include all the forces due to other interaction types and also the thermostat. Next a force equal in magnitude, but in the oppositte direction is applied on the particles. This force is divided equally on all the particles of type \var{particle\_type\_number1}, since currently there is no mass concept in \es{}. Note that the syntax of the declaration of comfixed interaction requires the same particle type to be input twice. If different particle types are given in the input, the program exits with an error message. The \var{comfixed\_flag} can be set to 1 (which turns on the interaction) or 0 (to turn off the interaction).
\begin{tclcode}
inter <particle_type_number1> <particle_type_number2> comforce
 <comforce_flag> <comforce_dir> <comforce_force> <comforce_fratio>
\end{tclcode}
The comforce interaction type enables one to pull away particle groups of two different types. It is mainly designed for pulling experiments on budles. Within a bundle of molecules of type number 1 (t1) lets mark one molecule as of type 2 (t2). Using comforce one can apply a force such that t2 can be pulled away from the bundle. The \var{comforce\_flag} is set to 1 to turn on the interaction, and to 0 otherwise. The pulling can be done in two different directions. Either parallel to the major axis of the bundle ( \var{comforce\_dir} = 0) or perpendicular to the major axis of the bundle (\var{comforce\_dir} = 1). \var{comforce\_force} is used to set the magnitude of the force. \var{comforce\_fratio} is used to set the ratio of the force applied on particles of t1 vs t2. This is useful if one has to keep the total applied force on the bundle and on the target molecule the same. A force of magnitude \var{comforce\_force} is applied on t2 particles, and a force of magnitude (\var{comforce\_force} * \var{comforce\_fratio}) is applied on t1 particles.

\subsection{Getting the currently defined interactions}

%\quickrefheading{Getting interactions}
\tclcommand{inter}{ }
returns a list of all bonded and non-bonded interactions as a Tcl-list, in the same formats as above, e. g.

\begin{tclcode}
{0 0 lennard-jones 1.0 2.0 1.1225 0.0 0.0} {0 FENE 7.0 2.0} {1 angle
 1.0}
\end{tclcode}

\section{The \es{} Library}

All functions described here are also contained in a library called \codebox{libEspresso.a} which can be used with any C-program. The file type is FILE *. To compile using the \es{} library, simply add the switches
\begin{code}
-L<Espresso dir>/<PLATFORM> -lEspresso 
\end{code}
to your compiler switches.

\section{The structured file format}

This describes the ASCII block format used for writing structured files for analysis or storage. Basically the file consists of blocks in curled braces, which have a single word title and some data. The data itself may consist again of such blocks. An example is:
\begin{tclcode}
{file {Demonstration of the block format}
{variable epsilon {_dval_ 1} } 
{variable p3m_mesh_offset {_dval_ 5.0000000000e-01
 5.0000000000e-01 5.0000000000e-01 } } 
{variable node_grid {_ival_ 2 2 2 } } 
{end } }
\end{tclcode}

The format does not specify the number of whitespaces or which are used as delimiters, space, tab and return are ok.

The keyword variable should be used to indicate that a variable definition follows in the form \var{name} \var{data}. \var{data} itself is a block with title \_ival\_ or \_dval\_ denoting integer rsp. double values, which then follow in a whitespace separated list. Such blocks can be read in conveniently using block\_read\_data and written using block\_write\_data.

An example C-code generating the example above is:
\begin{tclcode}
// This file is part of the ESPResSo distribution
   (http://www.espresso.mpg.de).
// It is therefore subject to the ESPResSo license agreement which
   you accepted upon receiving the distribution
// and by which you are legally bound while utilizing this file in
   any form or way.
// There is NO WARRANTY, not even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
// You should have received a copy of that license along with this
   program;
// if not, refer to http://www.espresso.mpg.de/license.html where its
   current version can be found, or
// write to Max-Planck-Institute for Polymer Research, Theory Group,
   PO Box 3148, 55021 Mainz, Germany.
// Copyright (c) 2002-2006; all rights reserved unless otherwise
   stated.
#include "blockfile.h"

/*
  Demonstration of the use of the blockfile interface.
  Build using gcc -Wall -o test test.c -LLinux -lEspresso.
*/
int main()
{
  double epsilon = 1;
  double p3m_mesh_offset[3] = {.5, .5, .5};
  int    node_grid[3] = {2, 2, 2};

  FILE *f = fopen("demofile","w");
  block_writestart(f, "file");
  fprintf(f, "{Demonstration of the block format}\n");

  /* variable epsilon */
  block_writestart(f, "variable");
  fprintf(f, "epsilon ");
  block_write_data(f, TYPE_DOUBLE, 1, &epsilon);
  block_writeend(f);
  fprintf(f, "\n");

  /* variable p3m_mesh_offset */
  block_writestart(f, "variable");
  fprintf(f, "p3m_mesh_offset ");
  block_write_data(f, TYPE_DOUBLE, 1, p3m_mesh_offset);
  block_writeend(f);
  fprintf(f, "\n");

\end{tclcode}
\begin{tclcode}
  /* variable node_grid */
  block_writestart(f, "variable");
  fprintf(f, "node_grid ");
  block_write_data(f, TYPE_DOUBLE, 1, node_grid);
  block_writeend(f);
  fprintf(f, "\n");

  /* end tag */
  block_writestart(f, "end");
  block_writeend(f);

  block_writeend(f);
  fclose(f);
  return 0;
}
\end{tclcode}


\section{Global variables}
Description of the global variables
The following list explains the usage of the variables that are accessible via The setmd command. The list gives the setmd name of (hopefully) all available variables, the data type and a link to the documentation of the corresponding C variable. Variables that are marked read only can only be written by C code.
\begin{itemize}
 \item
\begin{code}
box\_l double[3]
\end{code}
  box\_l - Simulation box length.
  Todo: document what happens to particles when box\_l is changed! 
 \item
\begin{code}
cell_grid int[3] (ro)
\end{code}
  DomainDecomposition::cell\_grid - dimension of the inner cell grid.
 \item
\begin{code}
cell_size double[3] (ro)
\end{code}
  DomainDecomposition::cell\_size - box length of a cell.
 \item
\begin{code}
dpd_gamma double (ro)
\end{code}
  dpd\_gamma - Friction constant for DPD thermostat.
 \item
\begin{code}
dpd_r_cut double (ro)
\end{code}
  dpd\_r\_cut - Cutoff for DPD thermostat.
 \item
\begin{code}
gamma double (ro)
\end{code}
  langevin\_gamma - Friction constant for LANGEVIN thermostat.
 \item
\begin{code}
integ_switch int (ro)
\end{code}
  integ\_switch - internal switch which integrator to use.
 \item
\begin{code}
local_box_l int[3] (ro)
\end{code}
  local\_box\_l - Local simulation box length of the nodes.
 \item
\begin{code}
max_cut double (ro)
\end{code}
  max\_cut - Maximal cutoff of real space interactions.
 \item
\begin{code}
max_num_cells int
\end{code}
  max\_num\_cells - Maximal number of cells for the link cell algorithm. Reasonable values are between 125 and 1000, or for some problems (n\_total\_particles / n\_nodes).
 \item
\begin{code}
max_part int (ro)
\end{code}
  max\_seen\_particle - Maximal identity of a particle. THIS IS IN GENERAL NOT RELATED TO THE NUMBER OF PARTICLES.
 \item
\begin{code}
max_range double (ro)
\end{code}
  max\_range - Maximal range of real space interactions: max\_cut + skin.
 \item
\begin{code}
max_skin double (ro)
\end{code}
  max\_skin - Maximal skin to be used for the link cell/verlet algorithm. This is Min(DomainDecomposition::cell\_size) - max\_range.
 \item
\begin{code}
min_num_cells int>
\end{code}
  min\_num\_cells - Minimal number of cells for the link cell algorithm. Reasonable values range in 1e-6 N\^2 to 1e-7 N\^2. In general just make sure that the Verlet lists are not incredibly large. By default the minimum is 0, but for the automatic P3M tuning it may be wise to larger values for high particle numbers.
 \item
\begin{code}
n\_layers int (ro)
\end{code}
  n\_layers - Number of layers in cell structure LAYERED.
 \item
\begin{code}
n\_nodes int (ro)
\end{code}
  n\_nodes - Number of nodes.
 \item
\begin{code}
n\_part int (ro)
\end{code}
  n\_total\_particles - Total number of particles.
 \item
\begin{code}
n\_part\_types int (ro)
\end{code}
  n\_particle\_types - Number of particle types that were used so far in The inter command.
 \item
\begin{code}
node_grid int[3]
\end{code}
  node\_grid - 3D node grid for real space domain decomposition (optional, if unset an optimal set is chosen automatically).
 \item
\begin{code}
nptiso_gamma0 double (ro)
\end{code}
  nptiso\_gamma0 - INSERT COMMENT
 \item
\begin{code}
nptiso_gammav double (ro)
\end{code}
  nptiso\_gammav - INSERT COMMENT
 \item
\begin{code}
npt_p_ext double (ro)
\end{code}
  nptiso\_struct::p\_ext - Pressure for NPT simulations.
 \item
\begin{code}
npt_p_inst double
\end{code}
  nptiso\_struct::p\_inst Pressure calculated during an NPT\_isotropic integration.
 \item
\begin{code}
piston double (ro)
\end{code}
  nptiso\_struct::piston - Mass off the box when using NPT\_isotropic integrator.
 \item
\begin{code}
periodicity bool[3]
\end{code}
  periodic - Specifies periodicity for the three directions. If the compiler flag PARTIAL\_PERIODIC from config.h is set, this variable can be set to (1,1,1) or (0,0,0) at the moment. If not it is readonly and gives the default setting (1,1,1).
 \item
\begin{code}
skin double
\end{code}
  skin - Skin for the Verlet list.
 \item
\begin{code}
temperature double (ro)
\end{code}
  temperature - Temperature of the simulation. Enters the thermostat and the coulomb prefactor = bjerrum * temperature.
 \item
\begin{code}
thermo\_switch double (ro)
\end{code}
  thermo\_switch - internal variable which thermostat to use.
 \item
\begin{code}
time double
\end{code}
  sim\_time - The simulation time.
 \item
\begin{code}
time_step double
\end{code}
  time\_step - Time step for MD integration
 \item
\begin{code}
timings int
\end{code}
  timing\_samples - number of timing samples to take into account if set.
 \item
\begin{code}
transfer_rate int (ro)
\end{code}
  transfer\_rate - Transfer rate for VMD connection. You can use this to transfer any integer value to the simulation from VMD.
 \item
\begin{code}
verlet_flag bool
\end{code}
  rebuild\_verletlist - Indicates whether the Verlet list will be rebuild. The program decides this normally automatically based on your actions on the data. see initialize.h for more information
 \item
\begin{code}
verlet_reuse bool
\end{code}
  verlet\_reuse - Average number of integration steps the verlet list has been re-used.
\end{itemize}

\section{The MMM family of algorithms}

Introduction
In the MMM family of algorithms for the electrostatic interaction, a convergence factor approach to tackle the conditionally convergent Coulomb sum is used (even the authors of the original MMM method have no idea what this acronym stands for). Instead of defining the summation order, one multiplies each summand by a continuous factor $c(\beta,r_{ij},n_{klm})$ such that the sum is absolutely convergent for $\beta>0$, but $c(0,.,.)=1$. The energy is then defined as the limit $\beta\rightarrow 0$ of the sum, i. e. $\beta$ is an artificial convergence parameter. For a convergence factor of $e^{-\beta n_{klm}^2}$ the limit is the same as the spherical limit, and one can derive the classical Ewald method quite conveniently through this approach (Smith 81). To derive the formulas for MMM, one has to use a different convergence factor, namely $e^{-\beta|r_{ij}+n_{klm}|}$, which defines the alternative energy

\[ \tilde{E}=\,\frac{1}{2}\lim_{\beta\rightarrow 0}\sum_{k,l,m}{\sum_{i,j=1}^N}' \frac{q_i q_je^{-\beta|p_{ij} + n_{klm}|}} {|p_{ij} + n_{klm}|} =:\,\frac{1}{2}\lim_{\beta\rightarrow 0}\sum_{i,j=1}^N q_iq_j\phi_\beta(x_{ij}, y_{ij},z_{ij}). \]

$\phi_\beta$ is given by $ \phi_\beta(x,y,z)=\,\tilde\phi_\beta(x,y,z) + \frac{e^{-\beta r}}{r} $ for $(x,y,z)\neq 0$ and $\phi_\beta(0,0,0)=\,\tilde\phi_\beta(0,0,0)$, where

\[ \tilde\phi_\beta(x,y,z)=\,\sum_{(k,l,m)\neq 0} \frac{e^{-\beta r_{klm}}}{r_{klm}}. \]

The limit $\tilde{E}$ exists, but differs for three dimensionally periodic systems by some multiple of the square of the dipole moment from the spherical limit as obtained by the Ewald summation (Smith 81). From the physical point of view the Coulomb interaction is replaced by a screened Coulomb interaction with screening length $1/\beta$. $\tilde{E}$ is then the energy in the limit of infinite screening length. But because of the conditional convergence of the electrostatic sum, this is not necessarily the same as the energy of an unscreened system. Since the difference to the Ewald methods only depends on the dipole moment of the system, the correction can be calculated easily in linear time and can be ignored with respect to accuracy as well as to computation time.

For one or two dimensionally systems, however, $\tilde{E}=E$, i.e. the convergence factor approach equals the spherical summation limit of the Ewald sum, and MMM1D and MMM2D do not require a dipole correction.

Starting from this convergence factor approach, R. Strebel and R. Sperb constructed a method of computational order $O(N\log N)$, MMM (Strebel 99). The favourable scaling is obtained, very much like in the Ewald case, by technical tricks in the calculation of the far formula. The far formula has a product decomposition and can be evaluated hierarchically similarly to the fast multipole methods.

For particles sufficiently separated in the z-axis one can Fourier transform the potential along both x and y. We obtain the far formula as

\[ \phi(x,y,z) =\, u_x u_y\sum_{p,q\neq 0} \frac{e^{2\pi f_{pq}z} + e^{2\pi f_{pq}(\lambda_z-z)}}{f_{pq} \left(e^{2\pi f_{pq}\lambda_z} - 1\right)} e^{2\pi i u_y q y}e^{2\pi i u_x p x} + 2\pi u_x u_y\left(u_z z^2 - z + \frac{\lambda_z}{6}\right). \]

where $\lambda_{x,y,z}$ are the box dimensions, $ f_{pq} =\, \sqrt{(u_x p)^2 + (u_y q)^2},\quad f_p =\, u_x p,\quad f_q =\, u_x q $, $ \omega_p=2\pi u_x p$ and $\omega_q=2\pi u_y q$. The advantage of this formula is that it allows for a product decomposition into components of the particles. For example

\[ e^{2\pi f_{pq}z}=e^{2\pi f_{pq}(z_i-z_j)}=e^{2\pi f_{pq}z_i}e^{-2\pi f_{pq}z_j} \]

etc. Therefore one just has to calculate the sum over all these exponentials on the left side and on the right side and multiply them together, which can be done in $O(N)$ computation time. As can be seen easily, the convergence of the series is excellent as long as z is sufficiently large. By symmetry one can choose the coordinate with the largest distance as z to optimise the convergence. Similar to the Lekner sum, we need a different formula if all coordinates are small, i. e. for particles close to each other. For sufficiently small $u_y\rho$ and $u_xx$ we obtain the near formula as

\[ \begin{array}{rl} \tilde\phi(x,y,z)=\, & 2 u_x u_y\sum\limits_{p,q>0} \frac{\cosh(2\pi f_{pq}z)}{f_{pq} \left(e^{2\pi f_{pq}\lambda_z} - 1\right)} e^{2\pi i u_y q y}e^{2\pi i u_x p x} +\\ & 4u_x\sum\limits_{l,p>0}\left(K_0(2\pi u_x p\rho_l) + K_N(2\pi u_x p\rho_{-l})\right)cos(2\pi u_x p x) -\\ & 2u_x\sum\limits_{n\ge 1}\frac{b_{2n}}{2n(2n)!}\Re\bigl((2\pi u_y (z+iy))^{2n}\bigr) +\\ & u_x\sum\limits_{n\ge 0}\left(\begin{array}{c}-\frac{1}{2}\\ n\end{array}\right)\frac{\left( \psi^{(2n)}(1 + u_x x) + \psi^{(2n)}(1 - u_x x)\right)}{(2n)!}\rho^{2n} -\\ & 2\log(4\pi). \end{array} \]

Note that this time we calculate $\tilde{\phi}$ instead of $\phi$, i. e. we omit the contribution of the primary simulation box. This is very convenient as it includes the case of self energy and makes $\tilde{\phi}$ a smooth function. To obtain $\phi$ one has to add the $1/r$ contribution of the primary box. The self energy is given by

\[ \tilde\phi(0,0,0)=\, 2 u_x u_y\sum\limits_{p,q>0} \frac{1}{f_{pq} \left(e^{2\pi f_{pq}\lambda_z} - 1\right)}+ 8u_x\sum\limits_{l,p>0}K_N(2\pi u_x\lambda_y p l) + 2 u_x\psi^{(0)}(1) - 2\log(4\pi). \]

Both the near and far formula are derived using the same convergence factor approach, and consequently the same singularity in $\beta$ is obtained. This is important since otherwise the charge neutrality argument does not hold.

To obtain the $O(N\log N)$ scaling, some algorithm tricks are needed, which are not used in MMM1D, MMM2D or ELC and are therefore not discussed here. For details see Strebel,99. MMM is not implemented in \es{}.

MMM2D
In the case of periodicity only in the x and y directions, the far formula looks like

\[ \begin{array}{rl} \phi(x,y,z) = \, & 4 u_x u_y\sum_{p,q>0} \frac{e^{-2\pi f_{pq}|z|}} {f_{pq}} \cos(\omega_p x)\cos(\omega_q y) +\\ & 2 u_x u_y\left(\sum_{q>0} \frac{e^{-2\pi f_q|z|}}{f_q} \cos(\omega_q y) + \sum_{p>0} \frac{e^{-2\pi f_p|z|}}{f_p} \cos(\omega_p x)\right) -\\ & 2\pi u_x u_y |z| \end{array} \],

and the near formula is

\[ \begin{array}{rl} \tilde\phi(x,y,z)=\, & 4u_x\sum_{l,p>0}\left(K_0(\omega_p\rho_l) + K_0(\omega_p\rho_{-l})\right)\cos(\omega_p x) -\\ & 2u_x\sum_{n\ge 1}\frac{b_{2n}}{2n(2n)!} \Re\bigl((2\pi u_y (z+iy))^{2n}\bigr)\,+\, \sum_{k=1}^{N_\psi-1}\left(\frac{1}{r_{k}} + \frac{1}{r_{-k}}\right) -\\ & u_x\sum_{n\ge 0}\left(\begin{array}{c}-\frac{1}{2}\\n\end{array}\right)\frac{\left( \psi^{(2n)}(N_\psi + u_x x) + \psi^{(2n)}(N_\psi - u_x x)\right)}{(2n)!}(u_x\rho)^{2n} -\\ & 2u_x\log\left(4\pi\frac{u_y}{u_x}\right). \end{array} \]

As said before, the energy obtained from these potentials is equal to the electrostatic energy obtained by the spherical summation limit. The deeper reason for this is that in some sense the electrostatic sum is absolutely convergent, see Arnold,02 for a discussion.

The near formula is used for particles with a small distance along the z axis, for all other particles the far formula is used. Below is shown, that the far formula can be evaluated much more efficiently, however, its convergence breaks down for small z distance. To efficiently implement MMM2D, the layered cell system is required, which splits up the system in equally sized gaps along the z axis. The interaction of all particles in a layer S with all particles in the layers S-1,S,S+1 is calculated using the near formula, for the particles in layers 1,...,S-2, and in layers S+2,...,N, the far formula is used.

The implementation of the near formula is relatively straight forward and can be treated as any short ranged force is treated using the link cell algorithm, here in the layered variant. The special functions in the formula are somewhat demanding, but for the polygamma functions Taylor series can be achieved, which are implemented in mmm-common.h. The Bessel functions are calculated using a Chebychev series, see specfunc.h "specfunc.h".

The treatment of the far formula is algorithmically more complicated. For a particle i in layer $ S_i$,The formula can product decomposed, as in

\[ \begin{array}{rl} \sum_{j\in I_S, S < S_i - 1} q_iq_j\frac{e^{-2\pi f_{pq}|z_i-z_j|}}{f_{pq}} \cos(\omega_p (x_i - x_j))\cos(\omega_q (y_i - y_j)) = \\
q_i\frac{e^{-2\pi f_{pq}z_i}}{f_{pq}} \cos(\omega_p x_i)\cos(\omega_q y_i) \sum_{j\in I_S, S < S_i - 1}q_je^{2\pi f_{pq}z_j} \cos(\omega_p x_j)\cos(\omega_q y_j) + \\ q_i\frac{e^{-2\pi f_{pq}z_i}}{f_{pq}} \cos(\omega_p x_i)\sin(\omega_q y_i) \sum_{j\in I_S, S < S_i - 1}q_je^{2\pi f_{pq}z_j} \cos(\omega_p x_j)\sin(\omega_q y_j) + \\ q_i\frac{e^{-2\pi f_{pq}z_i}}{f_{pq}} \sin(\omega_p x_i)\cos(\omega_q y_i) \sum_{j\in I_S, S < S_i - 1}q_je^{2\pi f_{pq}z_j} \sin(\omega_p x_j)\cos(\omega_q y_j) + \\ q_i\frac{e^{-2\pi f_{pq}z_i}}{f_{pq}} \sin(\omega_p x_i)\sin(\omega_q y_i) \sum_{j\in I_S, S < S_i - 1}q_je^{2\pi f_{pq}z_j} \sin(\omega_p x_j)\sin(\omega_q y_j). \end{array} \]

This representation has the advantage, that the contributions of the two particles are decoupled. For all particles j only the eight terms

\[ \xi^{(\pm,s/c,s/c)}_j= q_je^{\pm 2\pi f_{pq}z_j} \sin/\cos(\omega_p x_j)\sin/\cos(\omega_q y_j) \]

are needed. The upper index describes the sign of the exponential term and whether sine or cosine is used for $x_j$ and $y_j$ in the obvious way. These terms can be used for all expressions on the right hand side of the product decomposition. Moreover it is easy to see from the addition theorem for the sine function that these terms also can be used to calculate the force information up to simple prefactors that depend only on p and q.

Every processor starts with the calculation of the terms $\xi^{(\pm,s/c,s/c)}_j$ and adds them up in each layer, so that one obtains

\[ \Xi^{(\pm,s/c,s/c)}_s= \sum_{j\in S_s}\xi^{(\pm,s/c,s/c)}_j. \]

Now we calculate

\[ \Xi^{(l,s/c,s/c)}_s=\sum_{t < s - 1}\Xi^{(+,s/c,s/c)}_t \]

and

\[ \Xi^{(h,s/c,s/c)}_s=\sum_{t > s + 1}\Xi^{(-,s/c,s/c)}_t, \]

which are needed for the evaluation of the product decomposition. While the bottom processor can calculate $\Xi^{(l,s/c,s/c)}_s$ directly, the other processors are dependent on its results. Therefore the bottom processor starts with the calculation of its $\Xi^{(l,s/c,s/c)}_s$ and sends up $\Xi^{(l,s/c,s/c)}_s$ and $\Xi^{(+,s/c,s/c)}_s$ of its top layer s to the next processor dealing with the layers above. Simultaneously the top processor starts with the calculation of the $\Xi^{(h,s/c,s/c)}_s$ and sends them down. After the communicated has been completed, every processor can use the $\Xi^{(l/h,s/c,s/c)}_j$ and the $\xi^{(\pm,s/c,s/c)}_j$ to calculate the force rsp. energy contributions for its particles.

In pseudo code, the far formula algorithm looks like this

    * for each layer s=1,...,S
          o $\Xi^{(\pm,s/c,s/c)}_s=0$
          o for each particle j in layer s
                + calculate $\xi^{(\pm,s/c,s/c)}_j$
                + $\Xi^{(\pm,s/c,s/c)}_s += \xi^{(\pm,s/c,s/c)}_j$
    * $\Xi^{(l,s/c,s/c)}_3=\Xi^{(+,s/c,s/c)}_1$
    * for each layer s=4,...,S
          o $\Xi^{(l,s/c,s/c)}_s=\Xi^{(l,s/c,s/c)}_{s-1} + \Xi^{(+,s/c,s/c)}_{s-2}$
    * $\Xi^{(l,s/c,s/c)}_{S-2}=\Xi^{(-,s/c,s/c)}_S$
    * for each layer s=(S-3),...,1
          o $\Xi^{(l,s/c,s/c)}_s=\Xi^{(l,s/c,s/c)}_{s+1} + \Xi^{(-,s/c,s/c)}_{s+2}$
    * for each layer s=1,...,S
          o for each particle j in layer s
                + calculate particle interaction from $\xi^{(+,s/c,s/c)}_j\Xi^{(l,s/c,s/c)}_s$ and $\xi^{(-,s/c,s/c)}_j\Xi^{(h,s/c,s/c)}_s$

For further details, see the articles of Arnold and Holm, 2002.
Dielectric contrast
A dielectric contrast at the lower and/or upper simulation box boundary can be included comparatively easy by using image charges. Apart from the images of the lowest and topmost layer, the image charges are far enough to be treated by the far formula, and can be included as starting points in the calculation of the $\Xi$ terms. The remaining particles from the lowest and topmost layer are treated by direct summation of the near formula.

This means, that in addition to the algorithm above, one has to only a few things: during the calculation of the particle and cell blocks $\xi$ and $\Xi$, one additionally calculates the contributions of the image charges and puts them either in a separate array or, for the boundary layers, into two extra $\xi$ cell blocks outside the simulation box. The entries in the separate array are then added up over all processors and stored in the $\Xi$-terms of the lowest/topmost layer. This are all modifications necessary for the far formula part. In addition to the far formula part, there is an additional loop over the particles at the boundary to directly calculate their interactions with their images. The exact details can be found in Tyagi, Arnold and Holm, 2006.
MMM1D
In one dimensionally periodic systems with z being the periodic coordinate, the far formula looks like

\[ \begin{array}{rl} \phi(\rho,z) &=\, 4 u_z\sum_{p\neq 0} K_0(\omega\rho)\cos(\omega z) - 2u_z\log(\frac{\rho}{2\lambda_z}) - 2u_z\gamma\\ F_\rho(\rho,z) &=\, 8\pi u_z^2\sum_{p\neq 0} p K_1(\omega\rho)\cos(\omega z) + \frac{2 u_z}{\rho}\\ F_z(\rho,z) &=\, 8\pi u_z^2 \sum_{p\neq 0} pK_0(\omega\rho)\sin(\omega z), \end{array} \]

the near formula is

\[ \begin{array}{rl} \tilde{\phi}(\rho,z) &=\, -u_z\sum_{n\ge 0} \left(\begin{array}{c}-\frac{1}{2}\\n\end{array}\right) \frac{\left(\psi^{(2n)}(N_\psi + u_z z) + \psi^{(2n)}(N_\psi - u_z z)\right)}{(2n)!}(u_z\rho)^{2n} - 2u_z\gamma + \\ &\phantom{=\,++} \sum_{k=1}^{N_\psi-1}\left(\frac{1}{r_k}+\frac{1}{r_{-k}}\right)\\ \tilde{F}_\rho(\rho,z) &=\, -u_z^3 \sum_{n\ge 0} \left(\begin{array}{c}-\frac{1}{2}\\n\end{array}\right) \frac{\left(\psi^{(2n)}(N_\psi + u_z z) + \psi^{(2n)}(N_\psi - u_z z)\right)}{(2n)!}(u_z\rho)^{2n-1} + \\ &\phantom{=\,++} \sum_{k=1}^{N_\psi-1}\left(\frac{\rho}{r_k^3}+\frac{\rho}{r_{-k}^3}\right) \\ \tilde{F}_z(\rho,z) &=\, -u_z^2 \sum_{n\ge 0} \left(\begin{array}{c}-\frac{1}{2}\\n\end{array}\right) \frac{\left(\psi^{(2n + 1)}(N_\psi + u_z z) + \psi^{(2n + 1)}(N_\psi - u_z z)\right)}{(2n)!}(u_z\rho)^{2n} + \\ &\phantom{=\,++} \sum_{k=1}^{N_\psi-1}\left(\frac{z+k\lambda_z}{r_k^3}+\frac{z-k\lambda_z}{r_{-k}^3}\right), \end{array} \]

where $\rho$ denotes the xy-distance of the particles. As for the two dimensional periodic case, the obtained energy is equal to the one dimensional Ewald sum. Algorithmically, MMM1D is uninteresting, since neither the near nor far formula allow a product decomposition or similar tricks. MMM1D has to be implemented as a simple NxN loop. However, the formulas can be evaluated efficiently, so that MMM1D can still be used reasonably for up to 400 particles on a single processor.
ELC
The ELC method differs from the other MMM algorithms in that it is not an algorithm for the calculation of the electrostatic interaction, but rather represents a correction term which allows to use any method for threedimensionally periodic systems with spherical summation order for twodimensional periodicity. The basic idea is to expand the two dimensional slab system of height h in the non-periodic z-coordinate to a system with periodicity in all three dimensions, with a period of $\lambda_z>h$, which leaves an empty gap of height $\delta=\lambda_z - h$ above the particles in the simulation box.

Since the electrostatic potential is only finite if the total system is charge neutral, the additional image layers (those layers above or below the original slab system) are charge neutral, too. Now let us consider the n-th image layer which has an offset of $n\lambda_z$ to the original layer. If $n\lambda_z$ is large enough, each particle of charge q\_j at position $(x_j,y_j,z_j+n\lambda_z)$ and its replicas in the xy-plane can be viewed as constituting a homogeneous charged sheet of charge density $\sigma_j = \frac{q_j}{\lambda_x\lambda_y}$. The potential of such a charged sheet at distance z is $2\pi \sigma_j |z|$. Now we consider the contribution from a pair of image layers located at $\pm n\lambda_z$, n>0 to the energy of a charge q\_i at position $(x_i,y_i,z_i)$ in the central layer. Since $|z_j - z_i| < n\lambda_z$, we have $|z_j - z_i + n\lambda_z| = n\lambda_z + z_j - z_i$ and $|z_j - z_i - n\lambda_z|= n\lambda_z - z_j + z_i$, and hence the interaction energy from those two image layers with the charge $q_i$ vanishes by charge neutrality:

\[ 2\pi q_i \sum_{j=1}^N \sigma_j(|z_j - z_i + n\lambda_z| + |z_j - z_i - n\lambda_z|) = 4\pi q_i n\lambda_z \sum_{j=1}^N \sigma_j = 0. \]

The only errors occurring are those coming from the approximation of assuming homogeneously charged, infinite sheets instead of discrete charges. This assumption should become better when increasing the distance $n\lambda_z$ from the central layer.

However, in a naive implementation, even large gap sizes will result in large errors. This is due to the order of summation for the standard Ewald sum, which is spherical, while the above approach orders the cells in layers, called slab--wise summation. Smith has shown that by adding to the Ewald energy the term

\[ E_c=2\pi M_z^2 - \frac{2\pi M^2}{3}, \]

where M is the total dipole moment, one obtains the result of a slab--wise summation instead of the spherical limit (Smith 81). Although this is a major change in the summation order, the difference is a very simple term. In fact, Smith shows that changes of the summation order always result in a difference that depends only on the total dipole moment.

Using the far formula of MMM2D, one can calculate the contributions of the additional layers up to arbitrarily precision, even for small gap sizes. This method is called electrostatic layer correction, ELC. The advantage of this approach is that for the image layers, z is necessarily large enough, so that all interactions can be represented using the product decomposition. This allows for an order N evaluation of the ELC term.

The electrostatic layer correction term is given by

\[ E_{lc}=\sum_{i,j=1}^Nq_iq_j\psi(p_i-p_j), \]

where

\[ \begin{array}{rl} \psi(x,y,z)=&4u_xu_y\sum_{p,q>0}\frac{\cosh(2\pi f_{pq}z)}{f_{pq}(e^{2\pi f_{pq}\lambda_z} - 1)} \cos(\omega_p x)\cos(\omega_q y) + \\ &2u_xu_y\sum_{p>0}\frac{\cosh(2\pi f_p z)}{f_p(e^{2\pi f_p\lambda_z} - 1)}\cos(\omega_p x)+\\ &2u_xu_y\sum_{q>0}\frac{\cosh(2\pi f_q z)}{f_q(e^{2\pi f_q\lambda_z} - 1)}\cos(\omega_q y). \end{array} \]

The implementation is very similar to MMM2d, except that the separation between slices closeby, and above and below is not necessary.
Errors
Common to all algorithms of the MMM family is that accuracy is cheap with respect to computation time. More precisely, the maximal pairwise error, i.e. the maximal error of the $\psi$ expression, decreases exponentially with the cutoffs. In turn, the computation time grows logarithmically with the accuracy. This is quite in contrast to the Ewald methods, for which decreasing the error bound can lead to excessive computation time. For example, P3M cannot reach precisions above $10^{-5}$ in general. The precise form of the error estimates is of little importance here, for details see again Arnold,02.

One important aspect is that the error estimates are also exponential in the non-periodic coordinate. Since the number of closeby and far away particles is different for particles near the border and in the center of the system, the error distribution is highly non--homogenous. This is unproblematic as long as the maximal error is really much smaller than the thermal energy. However, one cannot interprete the error simply as an additional error source. Image
elc\_errordist.gif
shows the error distribution of the ELC method for a gap size of 10% of the total system height. For MMM2D and MMM1D the error distribution is less homogenous, however, also here it is always better to have some extra precision, especially since it is computationally cheap.
References
\begin{itemize}
 \item
  E. R. Smith, "Electrostatic energy in ionic crystals", Proc. R. Soc. Lond. A, 375 (1981), 475-505
 \item
  R. Strebel, "Pieces of software for the Coulombic m body problem", Dissertation, ETH Zürich, 13504 (1999) http://e-collection.ethbib.ethz.ch/show?type=diss\&nr=13504
 \item
  A. Arnold and C. Holm, "MMM2D: A fast and accurate summation method for electrostatic interactions in 2D slab geometries", Comp. Phys. Comm., 148/3 (2002), 327-348
 \item
  A. Arnold and C. Holm, "A novel method for calculating electrostatic interactions in 2D periodic slab geometries", Chem. Phys. Lett., 354 (2002), 324-330
 \item
  A. Arnold, J. de Joannis and C. Holm, "Electrostatics in Periodic Slab Geometries I", J. Chem. Phys., 117 (2002), 2496-2502
 \item
  J. de Joannis and A. Arnold and C. Holm, "Electrostatics in Periodic Slab Geometries II", J. Chem. Phys., 117 (2002), 2503-2512
\end{itemize}

\section{other functions}

\begin{code}
stopParticles
stop_particles 
\end{code}
halts all particles in the current simulation, setting their velocities and forces to zero. The latter syntax does not provide feedback on the execution status.

\begin{code}
countBonds <particle_list> 
\end{code}

returns a tcl-list of the complete topology described by <particle\_list>, which must have the same format as [part] (see The part command).
The output list contains only particle\_number and the corresponding bonding informations, thus it looks like e. g.
\begin{tclcode}
{106 {0 107}} {107 {0 106} {0 108}} {108 {0 107} {0 109}} ...
{210 {0 209} {0 211}} {211 {0 210}} 212 213 ... 
\end{tclcode}
for a single chain of 106 monomers between particle 106 and 211, with additional loose particles 212, 213, ... (e. g. counter-ions).
Note, that The part command stores any bonds only with the particle of lower particle number, which is why [part 109] would only return {... bonds {{0 110}}}, therefore not revealing the bond between particle 109 and (the preceding) particle 108, while countBonds would return all bonds particle 109 participates in.

\begin{tclcode}
findPropPos <particle_property_list> <property>
\end{tclcode}
returns the index of <property> within <particle\_property\_list>, which is expected to have the same format as [part <particle\_number>]. If <property> is not found, -1 is returned.
This function is useful to access certain properties of particles without hard-wiring their index-position, which might (again) change in future releases of part.
\begin{tclcode}
[lindex [part $i] [findPropPos [part $i] type]]
\end{tclcode}
for example returns the \var{particle\_type} of particle \$i without fixing where exactly that information has to be in the output of [part \$i].
\begin{code}
findBondPos <particle_property_list>
\end{code}
returns the index of the bonds within var{particle\_property\_list}, which is expected to have the same format as [part \var{particle\_number}];
hence its output is the same as [findPropPos <particle\_property\_list> bonds]. If the particle does not have any bonds, -1 is returned.
\begin{code}
timeStamp <path> <prefix> <postfix> <suffix>
\end{code}
modifies the filename contained within <path> to be preceded by a <prefix> and having a <postfix> before the <suffix>; e. g.
\begin{tclcode}
timeStamp ./scripts/config.gz DH863 001 gz
\end{tclcode}
returns './scripts/DH863\_config001.gz'.
If <postfix> is '-1' the current date is used in the format '%y%m%d' thus leading to './scripts/DH863\_config021022.gz' on October 22nd, 2002.

\section{Running Jobs at the Blade-Center}
The MPI-P has a 28 node Blade-Cluster at the RZG in Garching (see http://www.mpip-mainz.mpg.de/theory/computers/blade/index.html and

http://www.rzg.mpg.de/docs/linux/bladecenter.html) which may be used with \es{} as well. However, thanks to a certain custom level in their installation, some slight adjustments are required:

Only once you'll have to do the following to setup a suitable environment there:
\begin{itemize}
 \item
  Transfer your Espresso-directory to ibmr.rzg.mpg.de along with the following files:
  \begin{itemize}
   \item /usr/local/lib/libfftw.a
   \item /usr/local/lib/libfftw.la
   \item /usr/local/lib/librfftw.a
   \item /usr/local/lib/librfftw.la
   \item /usr/include/fftw.h
  \end{itemize}
 \item
  Login to ibmr.rzg.mpg.de and edit Makefile.Linux by setting
\begin{code}
BLADE=yes
\end{code}
 \item
  Prepare (another) script-file submit\_parallel.sh for the queuing system

 (see http://www.rzg.mpg.de/docs/linux/sge.html, but note that their example script does not work) which should look like:

\begin{tclcode}
#!/bin/sh
############################################################
# SGE options:
#
# Change to the current working directory upon starting of
 the job
#$ -cwd
#
# join the error and standard output streams
#$ -j y
#
# use the parallel environment mpich with 1 (or 2)
 processor(s)
#$ -pe mpich 1
#
# set the required resources (up) to 96 hours of computing
#$ -l h_rt=96:00:00
# do _not_ attempt to request num_proc here, or your job
 may not run, since num_proc is only a local resource.
#
# don't flood myself with e-mail
#$ -m n
#
# notify me about pending SIG_STOP and SIG_KILL
#$ -notify
#
# name of the job
#$ -N diamond_NpT
#
# end of SGE stuff
############################################################
# now execute my job:

export ESPRESSO_SOURCE=/afs/ipp-garching.mpg.de/home/b/bhm
/Espresso
export ESPRESSO_SCRIPTS=/afs/ipp-garching.mpg.de/home/b/bhm
/Espresso/scripts
/afs/ipp-garching.mpg.de/i386_linux24/bin/mpirun -np 1
 $ESPRESSO_SOURCE/Linux/Espresso diamond_NpT.tcl

# end of job script
############################################################
\end{tclcode}

  You'll have to replace \codebox{/home/b/bhm/Espresso} with the appropriate (absolute!) path to your home-directory (if that's where your \es{}-copy is residing), but note that path-abbreviations such as \codebox{~/Espresso} will not work over there!
  In addition, replace \codebox{diamond\_NpT.tcl} with the tcl-script you want to run, and change '-np 1' if you wanted more than one processor.
\end{itemize}

Each time you want to use the Blade-Center have at look at these things:
\begin{itemize}
 \item Transfer your tcl-script to ibmr.rzg.mpg.de and login there.
 \item Remove the header of your tcl-script (the stuff like \codebox{<tt>tricking...</tt>} 'til \codebox{<tt>fi;</tt>}) and copy it to your desired output-location, preferable the local scratch areas \codebox{/gmpip/mpo/\$USER}.
 \item Copy that submit\_parallel.sh-script from above to wherever your tcl-script just went, and go there, too.
 \item Edit submit\_parallel.sh to have the correct tcl-script-name and the desired CPU-numbers and -time.
 \item Use
\begin{code}
qsub submit_parallel.sh
\end{code}
  to launch your simulation, and
\begin{code}
qstat -f
\end{code}
  to check all nodes' status.
 \item The joined stdout and stderr are written to \var{Name}.o\var{PID} in your current directory, where \var{Name} is whatever you specified for the -N-option in the job-script and \var{PID} is your job's process number.
\end{itemize}


\section{The blockfile command}
In a nutshell:

The blockfile command is provided for saving and restoring the current state of \es{}, e. g. for creating and using checkpoints. Hence you can transfer all accessible informations to and from disk from and to \es{}.

\begin{itemize}
 \item
\begin{code}
set out [open "|gzip -c - > checkpoint.block.gz" "w"]
blockfile $out write variable all
blockfile $out write interactions
blockfile $out write random
blockfile $out write bitrandom
blockfile $out write particles "id pos type q v f" all
blockfile $out write bonds all
blockfile $out write configs
close $out 
\end{code}

 This example writes all variables accessible by The setmd command, all interactions known to The inter command, the full current state of the random number generator (The t\_random command or The bit\_random command), all informations (i.e. id, position, type-number, charge, velocity, forces, bonds) on all particles, and all particle configurations appended (using e. g. analyze append) for offline-analysis purposes to the file 'checkpoint.block.gz' which is even being compressed on-the-fly (if you don't want that, use \begin{code}set out [open "checkpoint.block" "w"]\end{code} instead).
 Note that interactions must be stored before particles before bonding informations, as for the bonds to be set all particles and all interactions must already be known to \es{}.

 \item
\begin{tclcode}
set in [open "|gzip -cd checkpoint.block.gz" "r"]
while { [blockfile $in read auto] != "eof" } {}
close $in 
\end{tclcode}
 This is basically all you need to restore the informations in the blockfile (again, if you don't have a compressed file, use 
\begin{code}
set out [open "checkpoint.block" "r"]
\end{code}
 instead) overwriting the current settings in \es{}.
\end{itemize}
And now the full documentation on how The blockfile command actually works:

\tclcommand{blockfile}
{
  \var{channel} 
  read|write 
  start|end|variable|auto|toend
  \opt{\var{param}}
}

blockfile allows for convienent access to a block format structured file \var{channel}. Some of the possible actions are:
\begin{enumerate}
 \item
\begin{code}
blockfile <channel>  write start <tag> 
\end{code}
  which writes a start "\{" and the title of the block given by tag.
 \item
\begin{code}
blockfile <channel> write end 
\end{code}
  just writes a "\}" to \var{channel}.
 \item
\begin{code}
blockfile <channel> write variable {<varname1> <varname2> ...} 
\end{code}
  writes the variables \var{varname1}, \var{varname2},..., which are known to The setmd command (a list can be found in Global variables), to \var{channel}. When reading the block, all variables with names listed in blockfile\_variable\_blacklist are ignored.
 \item
\begin{code}
blockfile <channel> write variable all
\end{code}
  will write all variables known to The setmd command to \var{channel}.
 \item
\begin{code}
blockfile <channel> write tclvariable {<varname1> <varname2> ...}
\end{code}
  writes the tcl global variables \var{varname1}, \var{varname2},..., to \var{channel}. Global variables are those declared in the top scope or those declared global in procedures. When reading the block, all variables with names listed in blockfile\_tclvariable\_blacklist are ignored.
 \item
\begin{code}
blockfile <channel> write tclvariable all
\end{code}
  will write all global variables to \var{channel}. The predefined globals from Tcl (tcl\_version, argv, argv0, tcl\_interactive, auto\_oldpath, errorCode, auto\_path, errorInfo, auto\_index, env, tcl\_pkgPath, tcl\_patchLevel, argc, tcl\_libPath, tcl\_library and tcl\_platform) are omitted.
 \item
\begin{code}
blockfile <channel> write tclvariable reallyall
\end{code}
  will even write those variables, which you probably almost never want...
 \item
\begin{code}
blockfile <channel> write particles <what> <range>
\end{code}
  writes particle information in a standardized format to the file \var{channel}. \var{what} can be any list of parameters that part \var{x} print takes except for "bonds". Notice that if "id" or "pos" is missing, this is added in the front to the list automatically. \var{range} is a Tcl list of ranges which particles to write. The range "all" is valid as well as a boundary of "end". For example
\begin{code}
 blockfile file10 write particles "id pos q" "all 0-end 0" 
\end{code}
  will write all particles two times to file10 and then particle 0 alone.
 \item
\begin{code}
 blockfile <channel> write interactions
\end{code}
  writes interactions information in a standardized format to the file \var{channel}.
 \item
\begin{code}
blockfile <channel> write bonds <range>
\end{code}
  writes bonds information in a standardized format to the file \var{channel}. The involved particles and bond types must exist and be valid.
 \item
\begin{code}
blockfile <channel> write random
\end{code}
  writes the full informations on the current state of the random number generators on any node to the file \var{channel}. Using this information, it is possible to recover the exact state the generators were in at that moment.
 \item
\begin{code}
blockfile <channel> write seed
\end{code}
  writes only the seed(s) which were used to initialize the random number generators. Note that this information is not sufficient to pick up the random sequences where they were left, because The t\_random command also uses a table of previous random numbers to determine the next one; to also save that information use tcl\_blockfile\_write\_random.
 \item
\begin{code}
blockfile <channel> write bitrandom
\end{code}
  writes the full informations on the current state of the R250 random number generators on any node to the file \var{channel}. Using this information, it is possible to recover the exact state the generators were in at that moment.
 \item
\begin{code}
blockfile <channel> write bitseed
\end{code}
  writes only the seed(s) which were used to initialize the bit random number generators. Note that this information is not sufficient to pick up the random sequences where they were left, because The bit\_random command uses a huge matrix of integers whose bit-patterns are XOR-ed to determine the next one; to also save that information use tcl\_blockfile\_write\_bitrandom.
 \item
\begin{code}
blockfile <channel> write configs
\end{code}
  writes the complete content of the 'configs'-array in statistics.c to \var{channel}, thereby saving all particle configurations appended (e. g. using analyze append) for analysis-purposes.
      Using this offline-analysis is quite easy: Just append regularly the current configurations, include this command after the derivation of the last time step, and blockfile read auto will load them later on resetting 'configs' to the state needed for most of the more complex analyze-commands.
 \item
\begin{code}
blockfile <channel> read start 
\end{code}
  reads the start part of a block and returns the block title.
 \item
\begin{code}
blockfile <channel> read toend 
\end{code}
  reads the blocks data and returns it.
 \item
\begin{code}
blockfile <channel> read particles|interactions|bonds|variable
 |seed|random|bitrandom|configs
\end{code}
  reads one block, checks wether it contains data of the given type and reads it.
 \item
\begin{code}
blockfile <channel> read auto 
\end{code}
  reads in one block and does the following:
  \begin{enumerate}
   \item
    if a procedure blockfile\_read\_auto\_\var{tag} exists, this procedure takes over (\var{tag} is the first expression in the block). For most block types, at least all mentioned above, i. e. particles, interactions, bonds, seed, random, bitrandom, configs, and variable, the corresponding procedure will overwrite the current information with the information from the block.
   \item
    if the procedure does not exist, it returns \codebox{usertag <tag> <rest of block>}
   \item
    if the file is at end, it returns \codebox{eof}
  \end{enumerate}
\end{enumerate}
If \codebox{blockfile <channel> read auto} finds a block, it tries to load the corresponding procedure as described above. \codebox{blockfile <channel> read <block>} checks for a block with tag \var{block} and then again executes the corresponding blockfile\_read\_auto\_\var{tag}, if it exists.

If that fails, blockfile executes \codebox{blockfile\_arg1\_arg2}, if it exists, with the all arguments given to blockfile. For example
\begin{code}
blockfile channel write particles "id pos" all 
\end{code}
results in the evaluation of
\begin{code}
blockfile_write_particles channel write particles "id pos" all 
\end{code}
If the next block in a blockfile is a particle block, e. g.
\begin{tclcode}
{particles {id pos type q}
           {0 27.251 62.31 58.707 1 1.0}
           {1 27.226 61.483 58.146 0 0.0}
}
\end{tclcode}	
\begin{code}
blockfile <channel> read auto 
\end{code}
will call
\begin{code}
blockfile_read_auto_particles <channel> read auto
\end{code}
, which then will delete all particles and insert the two particles above.

In the contrary that means that for a new blocktype you will normally implement two procedures:
\begin{tclcode}
blockfile_write_<tag> {channel "write" "<tag>" param...}
\end{tclcode}
which writes the block including the header and enclosing braces and
\begin{tclcode}
blockfile_read_auto_<tag> {channel "read" "auto"}
\end{tclcode}
which reads the block data and the closing brace. The parameters "write", "read", "\var{tag}" and "auto" are regular parameters which will always have the specified value. They occur just for technical reasons.



\section{Cell systems}
This page deals with the flexible particle data organization of \es{}. Due to different needs of different algorithms, \es{} is able to change the organization of the particles in the computer memory, according to the needs of the used algorithms. The cellsystem is change by the command
\begin{code}
cellsystem <system> <parameters> 
\end{code}
For details on the possible cellsystems and their parameters see the sections below. For details on the internal organization see Internal particle organization. The C implementation of the cellsystem command is cellsystem.

\subsection{Domain decomposition}
\begin{code}
cellsystem domain_decomposition -no_verlet_list
\end{code}
This selects the domain decomposition cell scheme, using Verlet for the calculation of the interactions. If you specify -no\_verlet\_list, only the domain decomposition is done, but no Verlet lists.

The domain decomposition cellsystem is the default system and suits most applications with short ranged interactions. The particles are divided up spatially into small compartments, the cells, such that the cell size is larger than the maximal interaction range. In this case interactions only occur between particles in adjacent cells. Since the interaction range should be much smaller than the total system size, leaving out all interactions between non-adjacent cells can mean a tremendous speed-up. Moreover, since for constant interaction range, the number of particles in a cell depends only on the density. The number of interactions is therefore of the order N instead of order N\^2 if one has to calculate all pair interactions. For further details, see domain\_decomposition.h.

\subsection{N-squared}
\begin{code}
nsquare 
\end{code}
This selects the very primitive nsquared cellsystem, which calculates the interactions for all particle pairs. Therefore it loops overall particles, giving an unfavorable computation time scaling of N\^2. However, algorithms like MMM1D or the plain Coulomb interaction in the cell model require the calculation of all pair interactions.

In a multiple processor environment, the nsquared cellsystem uses a simple particle balancing scheme to have a nearly equal number of particles per CPU, i. e. n nodes have m particles, and p-n nodes have m+1 particles, such that n*m+(p-n)*(m+1)=N, the total number of particles. Therefore the computational load should be balanced fairly equal among the nodes, with one exception: This code always uses one CPU for the interaction between two different nodes. For an odd number of nodes, this is fine, because the total number of interactions to calculate is a multiple of the number of nodes, but for an even number of nodes, for each of the p-1 communication rounds, one processor is idle.

E. g. for 2 processors, there are 3 interactions: 0-0, 1-1, 0-1. Naturally, 0-0 and 1-1 are treated by processor 0 and 1, respectively. But the 0-1 interaction is treated by node 1 alone, so the workload for this node is twice as high. For 3 processors, the interactions are 0-0, 1-1, 2-2, 0-1, 1-2, 0-2. Of these interactions, node 0 treats 0-0 and 0-2, node 1 treats 1-1 and 0-1, and node 2 treats 2-2 and 1-2.

Therefore it is highly recommended that you use nsquared only with an odd number of nodes, if with multiple processors at all. For further details, see nsquare.h.

\subsection{Layered cell system}
\begin{code}
layered <n_layers>
\end{code}
This selects the layered cell system, which is specifically designed for the needs of the MMM2D algorithm. Basically it consists of a nsquared algorithm in x and y, but a domain decomposition along z, i. e. the system is cut into equally sized layers along the z axis. The current implementation allows for the cpus to align only along the z axis, therefore the processor grid has to have the form 1x1xN. However, each processor may be responsible for several layers, which is determined by <n\_layers>, i. e. the system is split into N*<n\_layers> layers along the z axis. Since in x and y direction there are no processor boundaries, the implementation is basically just a stripped down version of the domain decomposition cellsystem.

\subsection{Internal particle organization}

Since basically all major parts of the main MD integration have to access the particle data, efficient access to the particle data is crucial for a fast MD code. Therefore the particle data needs some more elaborate organisation, which will be presented here. A particle itself is represented by a structure (Particle) consisting of several substructures (e. g. ParticlePosition, ParticleForce or ParticleProperties), which in turn represent basic physical properties such as position, force or charge. The particles are organised in one or more particle lists on each node, called Cell cells. The cells are arranged by several possible systems, the cellsystems as described above. A cell system defines a way the particles are stored in \es{}, i. e. how they are distributed onto the processor nodes and how they are organised on each of them. Moreover a cell system also defines procedures to efficiently calculate the force, energy and pressure for the short ranged interactions, since these can be heavily optimised depending on the cell system. For example, the domain decomposition cellsystem allows an order N interactions evaluation.

datastorage.gif

Technically, a cell is organised as a dynamically growing array, not as a list. This ensures that the data of all particles in a cell is stored contiguously in the memory. The particle data is accessed transparently through a set of methods common to all cell systems, which allocate the cells, add new particles, retrieve particle information and are responsible for communicating the particle data between the nodes. Therefore most portions of the code can access the particle data safely without direct knowledge of the currently used cell system. Only the force, energy and pressure loops are implemented separately for each cell model as explained above.

The domain decomposition or link cell algorithm is implemented in \es{} such that the cells equal the \es{} cells, i. e. each cell is a separate particle list. For an example let us assume that the simulation box has size $20\times 20\times 20$ and that we assign 2 processors to the simulation. Then each processor is responsible for the particles inside a $10\times 20\times 20$ box. If the maximal interaction range is 1.2, the minimal possible cell size is 1.25 for 8 cells along the first coordinate, allowing for a small skin of 0.05. If one chooses only 6 boxes in the first coordinate, the skin depth increases to 0.467. In this example we assume that the number of cells in the first coordinate was chosen to be 6 and that the cells are cubic. \es{} would then organise the cells on each node in a $6\times 12\times 12$ cell grid embedded at the centre of a $8\times 14 \times 14$ grid. The additional cells around the cells containing the particles represent the ghost shell in which the information of the ghost particles from the neighbouring nodes is stored. Therefore the particle information stored on each node resides in 1568 particle lists of which 864 cells contain particles assigned to the node, the rest contain information of particles from other nodes.a

Classically, the link cell algorithm is implemented differently. Instead of having separate particle lists for each cell, there is only one particle list per node, and a the cells actually only contain pointers into this particle list. This has the advantage that when particles are moved from one cell to another on the same processor, only the pointers have to be updated, which is much less data (4 rsp. 8 bytes) than the full particle structure (around 192 bytes, depending on the features compiled in). The data storage scheme of \es{} however requires to always move the full particle data. Nevertheless, from our experience, the second approach is 2-3 times faster than the classical one.

To understand this, one has to know a little bit about the architecture of modern computers. Most modern processors have a clock frequency above 1GHz and are able to execute nearly one instruction per clock tick. In contrast to this, the memory runs at a clock speed around 200MHz. Modern double data rate (DDR) RAM transfers up to 3.2GB/s at this clock speed (at each edge of the clock signal 8 bytes are transferred). But in addition to the data transfer speed, DDR RAM has some latency for fetching the data, which can be up to 50ns in the worst case. Memory is organised internally in pages or rows of typically 8KB size. The full $2\times 200$ MHz data rate can only be achieved if the access is within the same memory page (page hit), otherwise some latency has to be added (page miss). The actual latency depends on some other aspects of the memory organisation which will not be discussed here, but the penalty is at least 10ns, resulting in an effective memory transfer rate of only 800MB/s. To remedy this, modern processors have a small amount of low latency memory directly attached to the processor, the cache.

The processor cache is organised in different levels. The level 1 (L1) cache is built directly into the processor core, has no latency and delivers the data immediately on demand, but has only a small size of around 128KB. This is important since modern processors can issue several simple operations such as additions simultaneously. The L2 cache is larger, typically around 1MB, but is located outside the processor core and delivers data at the processor clock rate or some fraction of it.

In a typical implementation of the link cell scheme the order of the particles is fairly random, determined e. g. by the order in which the particles are set up or have been communicated across the processor boundaries. The force loop therefore accesses the particle array in arbitrary order, resulting in a lot of unfavourable page misses. In the memory organisation of \es{}, the particles are accessed in a virtually linear order. Because the force calculation goes through the cells in a linear fashion, all accesses to a single cell occur close in time, for the force calculation of the cell itself as well as for its neighbours. Using the domain decomposition cell scheme, two cell layers have to be kept in the processor cache. For 10000 particles and a typical cell grid size of 20, these two cell layers consume roughly 200 KBytes, which nearly fits into the L2 cache. Therefore every cell has to be read from the main memory only once per force calculation. 

\section{The constraint command}
\tclcommand{constraint}
{
  \var{typename}|\var{delete} 
  \opt{\var{parameters}}
}

A constraint is a surface which interacts with the desired particles via a Lennard-Jones potential.
\[4 \epsilon \left(\left(\frac{\sigma}{r}\right)^{12} - \left(\frac{\sigma}{r}\right)^6 + shift\right)\]
with r being the distance of the center of the particle to the surface. The corresponding force acts in direction of the normal vector of the surface. The constraints are identified like a particle for the lennard-jones force calculation. Possible surfaces are:
\begin{code}
constraint wall normal <n_x> <n_y> <n_z> dist <d> type <id>  
\end{code}
The resulting surface is a plane defined by the normal vector \var{n\_x} \var{n\_y} \var{n\_z} and the distance \var{d} from the origin.
\begin{code}
constraint sphere center <c_x> <c_y> <c_z> radius <rad> direction
 <direction> type <id> 
\end{code}
The resulting surface is a sphere with center \var{c\_x} \var{c\_y} \var{c\_z} and radius \var{rad}. The \var{direction} determines the force direction, -1 or inside for inward and +1 or outside for outward
\begin{code}
constraint cylinder center <c_x> <c_y> <c_z> axis <n_x> <n_y> <n_z>
 radius <rad> length <length> direction <direction> type <id> 
\end{code}
The resulting surface is a cylinder with center \var{c\_x} \var{c\_y} \var{c\_z} and radius \var{rad}. The \var{length} parameter is not the whole length but a half of the cylinder length. The \var{axis} is a vector along the cylinder axis, which is normalized in the program. The \var{direction} is defined the same way as for the spherical constraint.
\begin{code}
constraint maze nsphere <n> dim <d> sphrad <r_s> cylrad <r_c>
 type 10 <id> 
\end{code}
The resulting surface is \var{n} spheres of radius \var{r\_s} along each dimension, connected by cylinders of radius \var{r\_c}. The spheres have simple cubic symmetry. The spheres are distributed evenly by dividing the \var{box\_l} by \var{n}. Dimension of the maze can be controlled by \var{d}: 0 for one dimensional, 1 for two dimensional and 2 for three dimensional maze.
\begin{code}
constraint force <n> 
\end{code}
gives the force acting on the \var{n}ths constraint.
\begin{code}
constraint delete <num> 
\end{code}
Delete constraint with number \var{num}. This may change the numbers of the other constraints. The constraint numbers can be obtained with:
\begin{code}
constraint 
\end{code}
Print out all constraint information.

After a type is defined for each constraint one has to define the interaction of all different particle types with the constraint using the
\begin{code}
inter 
\end{code}
command.


\section{Conversion of Deserno files}
The following procedures are found in scripts/convertDeserno.tcl.

\begin{itemize}
 \item
\begin{code}
convertDeserno2MD <source_file> <destination_file>
\end{code}
  converts the particle configuration stored in \var{source\_file} from Deserno-format into blockfile-format, importing everything to \es{} and writing it to \var{destination\_file}. The full particle information, bonds, interactions, and parameters will be converted and saved.
  If \var{destination\_file} is "-1", the data is only loaded into \es{} and nothing is written to disk.
  If \var{destination\_file} has the suffix \codebox{.gz}, the output-file will be compressed.
  The script uses some assumptions, e. g. on the \var{particle\_type\_number}s of The part command for polymers, counter-ions, or on sigma, shift, offset for Lennard-Jones-potentials (The inter command; current defaults are 2.0, 0, 0, respectively); these are all set by
\begin{code}
initConversion 
\end{code}
  (which is automatically called by convertDeserno2MD) so have a look at the sourcecode of \codebox{convertDeserno.tcl} in the \codebox{scripts}-directory for a complete list of assumptions.
  However, if for some reasons different values need to be set, it is possible to bypass the initialization routine and/or override the default values, e. g. by explicitly executing initConversion, afterwards overwriting all variables which need to be re-set, and manually invoking the main conversion script
\begin{code}
convertDeserno2MDmain <source_file> <destination_file> 
\end{code}
  to complete the process.
 \item
\begin{code}
convertMD2Deserno <source_file> <destination_file>
\end{code}
  converts the particle configuration stored in the \es{}-blockfile \var{source\_file} into a Deserno-compatible \var{destination\_file}.
  If \var{source\_file} is "-1", the data is entirely taken from \es{} without loading anything from disk.
  If \var{source\_file} has the suffix \codebox{.gz}, it is assumed to be compressed; otherwise it will be treated as containing plain text.
  Since Deserno stores much more than \es{} does due to a centralized vs. a local storage policy, it depends on correct values for the following properties, which therefore should be contained in \var{source\_file}:
  \begin{enumerate}
   \item the \var{particle\_type\_number} used for polymers, counter-ions, and salt-molecules (defaults are: \codebox{set type\_P 0}, \codebox{set type\_CI 1}, and \codebox{set type\_S 2}
   \item the \var{bond\_type\_number} used for FENE-interactions (default is: \codebox{set type\_FENE 0})
  \end{enumerate}
  As for convertDeserno2MD, the defaults are set upon initialization by
\begin{code}
initConversion 
\end{code}
  (which is automatically called by convertMD2Deserno as well), but may be overwritten the same way as explained for tcl\_convertDeserno2MD. However, parameters stored in \var{source\_file} cannot (and will not) be overwritten, because they were part of the system originally saved and should not be altered initially.
  Note, that some entries in a Deserno-file cannot be determined at all, these are by default set to
\begin{code}
set prefix AA0000
set postfix 0
set seed -1
set startTime -1
set endTime -1
set integrationSteps -1
set saveResults -1
set saveConfig -1
set subbox_1D -1
set ip -1
set step -1 
\end{code}
  but of course may be overwritten as well after calling initConversion and before continuing with
\begin{code}
convertMD2DesernoMain <source_file> <destination_file>
\end{code}
  the actual conversion process.
  The Deserno-format assumes knowledge of the topology, hence a respective analysis is conducted to identify the type and structure of the polymer network. The script allows for randomly stored polymer solutions and melts, no matter how they're messed up; however, crosslinked networks need to be aligned to be recognized correctly, i.e. they must be set up consecutively, such that the first chain with \$MPC monomers corresponds to the first \$MPC particles in [part], the 2nd one to the \$MPC following particles, etc. etc.
 \item
  It is now possible to save the whole state of \es{}, including all parameters and interactions. These scripts make use of that advantage by storing everything they find in the Deserno-file - but vice versa they also expect you to provide a blockfile containing all possible informations.
\end{itemize}
These conversion scripts have been tested with both polymer melts and end-to-end-crosslinked networks in systems with or without counterions. It should work with additional salt-molecules or neutral networks as well, although that hasn't been tested yet - if you've some of these systems in a Deserno-formated file, please submit them for extensive analysis.

\section{How to use CVS}
Befor checking in any changes you should make sure that
\begin{enumerate}
 \item your file contains no conflicts with the cvs version.
 \item the code compiles without warning on Linux and OSF1.
 \item make test runs.
 \item you have informed the responsible person of that file about major changes.
\end{enumerate}

Here a list of the most common cvs commands we need:
\begin{itemize}
 \item
\begin{code}
cvs add <file>
\end{code}
  Adds \var{file} to the cvsroot directory. You have to use commit to make your add complete.
 \item
\begin{code}
cvs checkout <project>
\end{code}
  This will create a new directory \var{project} in the CWD, containing an up-to-date version of <project>.
 \item
\begin{code}
cvs commit <file>
\end{code}
  Puts your changes into the cvsroot directory and makes them available for the others. When you execute this command, you will be asked to enter a log message. Use with care and write a meaningful log message!!! If you have done changes that ought to go into the relase notes, please start the log message with one of the following tags:
  \begin{itemize}
   \item [NEW] or [FEATURE] for new features
   \item [BUGFIX] or [FIX] for bug fixes
   \item [CHANGE] for important changes
  \end{itemize}
  The log message will then automatically go into the release notes of the next release.
 \item
\begin{code}
cvs diff <file>
\end{code}
  Shows differences of your local copy of \var{file} with respect to the cvs version.
 \item
\begin{code}
cvs log <file>
\end{code}
  Shows the log file for \var{file}, e. g. comments on changes that have been made in the past and who is responsible for them.
 \item
\begin{code}
cvs remove <file>
\end{code}
  removes a file from the cvsroot directory. That means, it is still there and can be restored, but will not be contained in future checkouts and updates. Use with care!!!
  For permanent deletion use commit one final time on that file, adding e. g. 'removed.' as comment. Use with even more care!!!
 \item
\begin{code}
cvs status <file>
\end{code}
  Reports the status of your local copy of \var{file} with respect to the cvs version.
 \item
\begin{code}
cvs update
\end{code}
  Get the current version of all files from the cvsroot directory. There will be a U in front of files that are updated, a M before files where cvs merges your local copy with the cvs version and a ? if there are files in your local directory which are not known to cvs. You will get a warning
\begin{code}
conflicts during merge
\end{code}
  for files where cvs is not able to merge. \textbf{You have to look at these files by hand!} They contain sections like
\begin{code}
<<<<<<< init.tcl
Local version of the file (e. g. 'init.tcl')
as stored in your local directory
=======
CVS version of the file (e. g. release 1.5)
from the repository in the cvsroot directory
>>>>>>> 1.5
\end{code}
  You have to \textbf{think first} and then decide how to combine the two versions.
\end{itemize}
For more help on CVS, see CVS Manual 

\section{How to do the documentation (Doxygen)}
The documentation for \es{} is mainly contained in the source code and is automatically generated using doxygen.

For each modul the documentation of the user interface, these are public funtions and external variable, should be in the header file. All other documentation should be in the c-file.

The documentation for each function should contain a short description, if necessary a more detailed description and a description for the return value and parameters.

Look at the documentation of existing files and functions to get a feeling how it should be!

Doxygen is able to understand simple LaTex and HTML commands as well as some special command in order to give the documentation a nice structure and to make it more readable. In the following list you find a short description of the most common commands we need:

\begin{itemize}
 \item
\begin{code}
\(\backslash{anchor}\) <name> <description>
\end{code}
  Set an anchor to which you can refer using \codebox{$\backslash ref$}
 \item
\begin{code}
<a href="http://www.your_url.html"> name </a>
\end{code}
  Link to an external html source.
 \item
\begin{code}
\(\backslash{file}\) <name> <description>
\end{code}
  Special anchor for a file.
 \item
\begin{code}
\(\backslash{image}\) html <image>
\end{code}
  Include a picture. The picture has to be in doc/figs/. Do not use the HTML \codebox{<img>} tag! The pictures will not be copied into the documentation!
 \item
\begin{code}
<ul>
 <li> List entry
</ul>
\end{code}
  Creates a list in the documentation (For example the list you are reading at the moment).
 \item
\begin{code}
/** \(\backslash{name}\) <group_name> <short description>.

<long_description>

*/

/*@ \{ */ 

<group members>

...

/*@ \} */
\end{code}
  Introduces a group to which one can refer with \codebox{$\backslash ref$}. The documentation of the group members must be inside the @{ ... @} comments.
 \item
\begin{code}
\(\backslash{param}\) <parameter> <description>
\end{code}
  Documentation for a parameter of a function
 \item
\begin{code}
\(\backslash{ref}\) <name> ["<text>"]
\end{code}
  Inserts a link to the documentation of \var{name}.
 \item
\begin{code}
\(\backslash{return}\) <description>
\end{code}
  Documentation for the return value of a function
 \item
\begin{code}
\(\backslash{todo}\) <task to be done>
\end{code}
  Adds an item to the Todo List. The item on the list will be linked to the origin.
\end{itemize}


\section{Features of the \es{} program}
\es{} provides a number of features that can be compiled into the program. It is recommended to turn on only the required features to optimise \es{} for your problem.

\subsection{Basic features}

\begin{itemize}
 \item PARTIAL\_PERIODIC
  if defined, the code will be slower, but with the periodic array you can choose which coordinates are bound to p.b.c and which are not. If not defined, all coordinates are bound to p.b.c.

  Has effect on: per\_callback(), fields, and functions in domain\_decomposition.c, grid.c, interaction\_data.c, layered.c, statistics\_chain.c

 \item ELECTROSTATICS
  Enable charges and the various electrostatics algorithms.

 \item ROTATION
  Enable describing and processing particle orientations. This will allow to use such particle properties as quart, omega, and torque.

 \item EXTERNAL\_FORCES
  Enable external forces. Eg. apply a fixed external force to a particle or fix a particle in space.

 \item CONSTRAINTS
  Enable constraints, eg. walls or spheres. See constraint.h and interaction\_data.h

 \item MASS
  Allow particles to have different masses.

 \item EXCLUSIONS
  Exclusion of nonbonded interactions for specific particle pairs. Currently works only with domain decomposition and Verlet lists.

 \item COMFORCE
  Enable the COMFORCE potential.

 \item COMFIXED
  Enable the COMFIXED potential.

 \item MOLFORCES
  Enables molecular forces. At present this only includes the trapping of molecules in a harmonic potential

 \item BOND\_CONSTRAINT
  Enable bond constraints. See rattle.h (merged but not tested). If you need this, I wish you happy debugging. 
\end{itemize}

\subsection{Short ranged potentials}
For optimization it might be useful to switch off the ones you don't need.
\begin{itemize}
 \item LENNARD\_JONES
  Enable the 12-6-Lennard-Jones potential.

 \item LJ\_WARN\_WHEN\_CLOSE
  If defined, you will get a warning when particles approach closer than 0.9 $\sigma$, because then it's likely the integration will blow up.

 \item MORSE
  Enable the Morse potential.

 \item LJCOS
  Enable the Lennard-Jones potential with cosine tail.

 \item BUCKINGHAM
  Enable the Buckingham potential.

 \item SOFT\_SPHERE
  Enable the soft sphere potential. 
\end{itemize}

\subsection{Angle potential}
Important: Activate only one of the possible variants!

Unpredicted behaviour will occur if you enable more than one!
\begin{itemize}
 \item BOND\_ANGLE\_HARMONIC
  Harmonic bond angle potential: $V = \frac{1}{2} k (\phi - \phi_0)^2$

 \item BOND\_ANGLE\_COSINE
  Cosine bond angle potential: $V = k (1+\cos(\phi-\phi_0))$

 \item BOND\_ANGLE\_COSSQUARE
  Cosine square bond angle potential: $V = \frac{1}{2} k (\cos(\phi)-cos(\phi_0))^2$
\end{itemize}

\subsection{Simulation methods, integrators and thermostats}
\begin{itemize}
 \item NEMD
  Non Eqilibrium Molecular Dynamics. This is used to perform shear simulations.

 \item NPT
  Allows to use (N,p,T)-ensembles during integration as well.

 \item DPD
  DPD Thermostat (Dissipative Particle Dynamics). Flag needed only because DPD acts like a short range potential.

 \item LB
  LB Thermostat (fluctuating Lattice Boltzmann fluid).
\end{itemize}

\subsection{Checking for features in the \es Tcl-Script}

In the \es{}-script, you can get information whether or not one or some of the features above are compiled into the current program with help of the following Tcl-commands:
\begin{itemize}
 \item
\begin{code}
code\_info
\end{code}
  provides information on the version, compilation status and the debug status of the used code. It is highly recommended to store this information with your simulation data in order to maintain the reproducibility of your results.
  Exemplaric output:
\begin{tclcode}
ESPRESSO: v1.5.Beta (Neelix), Last Change: 23.01.2004
{ Compilation status { PARTIAL_PERIODIC } { ELECTROSTATICS }
{ EXTERNAL_FORCES } { CONSTRAINTS } { TABULATED }
{ LENNARD_JONES } { BOND_ANGLE_COSINE } }
{ Debug status { MPI_CORE FORCE_CORE } }
\end{tclcode}
 \item
\begin{code}
has\_feature <feature> ...
\end{code}
  tests, if \var{feature} is compiled into the \es{} kernel. A list of possible features and their names can be found here.
 \item
\begin{code}
require\_feature <feature> ...
\end{code}
  tests, if \var{feature} is feature is compiled into the \es{} kernel, will exit the script if it isn't and return the error code 42. A list of possible features and their names can be found here.
\end{itemize}

Adding and removing features from the \es{} program

The file config.h contains the preprocessor switches that can be used to activate or deactivate a certain feature in \es{}. It is recommended to turn everything off which you do not need in order to optimize the performance of \es{} for your problem. There are also quite a number of features which are turned off by default since they are used only rarely.


\section{IMD}
IMD (Interactive Molecular Dynamics) is the protocol VMD uses to communicate with a simulation. Tcl\_md implements this protocol to allow online visual analysis of running simulations.

In IMD, the simulation acts as a data server. That means that a simulation can provide the possibility of connecting VMD, but VMD need not be connected all the time. You can watch the simulation just from time to time.

In the following the setup up and using of IMD is described.

\subsection{IMD in the script}

In your simulation, the IMD connection is setup up using
\codebox{imd connect <port>}

where \var{port} is an arbitrary port number (it has to be between 1024 and 65000). Normally \es{} will try to open port 10000, but the port may be in use already by another \es{} simulation. In that case it is a good idea to just try another port (see lj\_liquid.tcl).

Now while the simulation is running, you should execute
\begin{code}
imd positions <flag>
\end{code}
from time to time, which will transfer the current coordinates to VMD, if it is connected. If not, nothing happens and imd connect just consumes a small amount of CPU time. The optional flag argument can take values -unfolded or -fold\_chains. By specifying -unfolded the unfolded coordinates for each particle will be given to VMD. Specifying -fold\_chains causes imd to call the routine analyze\_fold\_molecules which folds chains according to their centers of mass and retains bonding connectivity. Note that this routine requires the chain structure to be specified first using the analyze command.
\begin{code}
imd listen <seconds>
\end{code}
can be used to let the simulation wait for \var{seconds} seconds or until IMD has connected. This is normally only useful in demo scripts, if you want to see all frames of the simulation.

If your simulations terminates,
\begin{code}
imd disconnect
\end{code}

will terminate the IMD session. This is normally not only nice but also the operating system will not free the port for some time, so that without disconnecting for some 10 seconds you will not be able to reuse the port.

Additionally, you have to provide VMD with the structural information for your system. Therefore your program has to write out psf-/pdb-files using tcl\_writepsf and tcl\_writepdb.

That hassle is greatly reduced by using the built-in auxiliary script
\begin{code}
prepare\_vmd\_connection [<filename> [<wait> [<start>]]]
\end{code}

which writes out the necessary psf-/pdb-files to \var{filename}.psf and \var{filename}.pdb (default for <filename is 'vmd'), doing some nice stuff such as coloring the molecules, bonds and counterions appropriately, rotating your viewpoint, and connecting your system to the visualization server. If \var{start} is 1 (the default), it does all that by itself; otherwise it writes those steps out to a script-file 'vmd\_start.script and waits for \var{wait} seconds (default: 0) for you to connect.

\subsection{Using IMD in VMD}
So after your simulation runs and has written the psf/pdb files, you start VMD. Then click on "Molecule", choose fileformat "psf and pdb", and select your psf/pdb files in the corresponding entries. Now click on "Load Molecule". You should see the snapshot you saved in the psf/pdb files.

Then execute "imd connect \var{host} \var{port}", where \var{host} is the host running the simulation and \var{port} is the port it listens to. Note that VMD crashes, if you do that without loading the molecule before .

For more information on how to use VMD to extract more information or hide parts of configuration, see the VMD Quick Help. 

\section{The internal Directory}
\begin{enumerate}
 \item cell\_model.tcl

  This example shows the use of constraints and non periodic boundary conditions. It simulates a bundle of semiflexible polyelectrolyes with hydrophobic side chains neutralized by counterions in a spherical simulation cell.

 \item diamond.tcl

   This reproduces the data of S.Schneider/P.Linse, Eur.Phys.J.E 8, 457-460 (2002): A diamond-shape network of 16 polyelectrolyte chains with 20 monomers each connected at 8 nodes is simulated for varying network packing fractions (densities) while the pressure is analysed (The analyze command). Similar to kremerGrest.tcl it additionally uses electrostatics including the auto-tuning feature (The inter command).
\end{enumerate}

\section{The invalidate\_system command}
DOCUMENTATION NOT UP TO DATE!!!
\begin{code}
invalidate\_system
\end{code}

forces a system re-init which, among others, causes the integrator to also update the forces at its beginning (instead of re-using the values from the previous integration step).
This is particularly necessary to ensure continuity after setting a checkpoint: integrate - set\_checkpoint - integrate has only one call to ???, while read\_checkpoint - integrate has two at the beginning of the 2nd integrate (because loading a new system from disk typically requires re-initializing the system), and since ??? also uses the thermostat which in turn draws random numbers, the two situations do not end up at the same segment of the random number sequence, all random events will therefore slightly differ.
To prevent this, simply include a call to invalidate\_system upon setting the checkpoint (this is being done automatically if using tcl\_checkpoint\_set and tcl\_checkpoint\_read beginning with v1.1 of \es{}), because in that case both scenarios will call ??? twice at the beginning of the second integration phase thus having their random number sequences in total sync. The C implementation is invalidate\_system.

\section{Using Checkpoints, saving configurations}
The following procedures may be used to save/restore checkpoints to minimize the hassel involved when your simulations crashes after long runs. The scripts are located in scripts/auxiliary.tcl and use The blockfile command as file format.
\begin{itemize}
 \item
\begin{code}
checkpoint\_set <destination> [<\# of configs> [<tclvar>
 [<ia\_flag> [<var\_flag> [<ran\_flag]]]]]
\end{code}
  creates a checkpoint with path/filename \var{destination} (compressed if \var{destination} ends with '.gz'), saving the last \var{\# of configs} which have been appended using analyze\_append (defaults to 'all'), adds all tcl-embedded variables specified in the tcl-list \var{tclvar} (defaults to '-'), all interactions (The inter command) / \es{}-variables (The setmd command) / random-number-generator informations (The t\_random command etc.) unless their respective flags \var{ia\_flag} / \var{var\_flag} / \var{ran\_flag} are set to '-'; you may however choose to only include certain \es{}-variables (The setmd command) by providing their names as a tcl-list in place of \var{var\_flag}.
  When you're reading this, tcl\_checkpoint\_set will be using The invalidate\_system command automatically; therefore continuing an integration after setting a checkpoint or restarting it there by reading one should make absolutely no difference anymore, since the current state of the random number generator(s) is/are completely (re)stored to (from) the checkpoint and the integrator is forced to re-init the forces (incl. thermostat) no matter what.
  It may be a good choice to use filenames such as 'kremer\_checkpoint.[eval format 05 \$integration\_step]' or 'kremer\_checkpoint.029.gz' for \var{destination} because the command stores all the names of checkpoints set to a file derived from \var{destination} by replacing the very last suffix plus maybe '.gz' with '.chk' (in the above examples: 'kremer\_checkpoint.chk') which is used by tcl\_checkpoint\_read to restore all checkpoints.
  Although 'checkpoint\_set \var{destination}' without the optional parameters will store a complete checkpoint sufficient for re-starting the simulation later on, you may run out of memory while trying to save a huge number of timesteps appended (analyze\_append). Hence one should rather only save those configurations newly added since the last checkpoint, i.e. if a checkpoint is created every 100,000 steps while a configuration is appended every 500 steps you may want to use 'checkpoint\_set \var{destination} 200' which saves the current configuration, all interactions, all bonds, the precise state of the random number generator(s), and the last 200 entries appended to configs since the last checkpoint was created. Since tcl\_checkpoint\_read reads in successively the checkpoints given in the '.chk'-file, the configs-array will nevertheless be completely restored to its original state although each checkpoint-file contains only a fraction of the whole array.
 \item
\begin{code}
checkpoint\_read <origin>
\end{code}

  restores all the checkpoints whose filenames are listed in \var{origin} in the order given therein, consequently putting the simulation into the state it was in when tc\_checkpoint\_set was called. If parts of the configs array are given in the files listed in \var{origin}, it is assumed that they represent a fraction of the whole array.
 \item
\begin{code}
polyBlockWrite <path> <param\_list> <part\_list>
\end{code}
  writes out the current '\es{}' configuration as an AxA-blockfile, including parameters, interactions, particles, and bonds.
  \var{path} should contain the filename including the full path to it.
  \var{param\_list} gives a tcl-list of the '\es{}'-parameters (out of ) to be saved; if an empty list '{}' is supplied, no parameters are written. If 'all', all parameters available through The setmd command are written. Defaults to the full parameter set.
  \var{part\_list} gives a string of the particle-properties (out of pos | type | q | v | f) to be saved to disk; if an empty string ' "" 'is provided, no particles, no bonds, and no interactions are written. Defaults (if omitted) to all particle-properties.
  Depending on the file-name's suffix, the output will be compressed (if \var{path} ends with '.gz'), too.
  Note, that 'polyBlockWrite' in combination with tcl\_convertMD2Deserno replaces the (undocumented) function 'polywr': To save the current configuration to a Deserno-compatible file (e. g. for use with 'poly2pdb') you may now use tcl\_polyBlockWrite to save your current configuration to a blockfile, and convert that with tcl\_convertMD2Deserno afterwards, or you directly write a Deserno-compatible file by invoking
\begin{code}
convertMD2Deserno "-1" <output-filename>
\end{code}

  out of \es{} to save your current active configuration.
  However, this last paragraph now has only historical meaning (see Writing pdb/psf files).
 \item
\begin{code}
polyBlockWriteAll <destination> [<tcl-var> [<rdm> [<configs>]]]
\end{code}

  does even more than tcl\_polyBlockWrite, i.e. it saves all current interactions, particles, bonds, \es{}-variables to \var{destination}, but in addition it also saves the tcl-variables specified by \var{tcl-var} (if 'all', then all the variables in the active script are stored), it saves the state of the random number generator if \var{rdm} is 'random' (= complete state) or 'seed' (= only the seeds), and it saves all the particle configurations used for analysis purposes if \var{configs} is all but '-'.
  Using '-' as value usually skips that entry.
  With this one can set real checkpoints which should reproduce the script-state as precisely as possible.
\end{itemize}


\section{Additional Tcl math-functions}
The following procedures are found in scripts/ABHmath.tcl.
\begin{itemize}
 \item
  CONSTANTS
  \begin{itemize}
   \item
\begin{code}
PI
\end{code}
    returns $\pi$ with 16 digits precision.
   \item
\begin{code}
KBOLTZ
\end{code}
    Returns Boltzmann constant in Joule/Kelvin
   \item
\begin{code}
ECHARGE
\end{code}
    Returns elementary charge in Coulomb
   \item
\begin{code}
NAVOGADRO
\end{code}
    Returns Avogadro number
   \item
\begin{code}
SPEEDOFLIGHT
\end{code}
    Returns speed of light in meter/second
   \item
\begin{code}
EPSILON0
\end{code}
    Returns dielectric constant of vaccum in Coulomb\^2/(Joule meter)
   \item
\begin{code}
ATOMICMASS
\end{code}
    Returns the atomic mass unit u in kilogramms
  \end{itemize}
 \item
  MATHEMATICAL FUNCTIONS
  \begin{itemize}
   \item
\begin{code}
sqr <arg>
\end{code}
    returns the square of \var{arg}.
   \item
\begin{code}
min <arg1> <arg2>
\end{code}
   \item
\begin{code}
min <arg1> <arg2>
\end{code}
    returns the minimum of \var{arg1} and \var{arg2}.
   \item
\begin{code}
max <arg1> <arg2>
\end{code}
    returns the maximum of \var{arg1} and \var{arg2}.
   \item
\begin{code}
sign <arg>
\end{code}
    returns the signum-function of \var{arg}, namely +1 for \var{arg} $>0$, -1 for $<0$, and =0 otherwise.
  \end{itemize}
 \item
  RANDOM FUNCTIONS
  \begin{itemize}
   \item
\begin{code}
gauss\_random
\end{code}
    returns random numbers which have a Gaussian distribution
   \item
\begin{code}
dist\_random <dist> [max]
\end{code}
    returns random numbers in the interval $[0,1]$ which have a distribution according to the distribution function p(x) \var{dist} which has to be given as a tcl list containing equally spaced values of p(x). If p(x) contains values larger than 1 (default value of max) the maximum or any number larger than that has to be given \var{max}. This routine basically takes the function p(x) and places it into a rectangular area ([0,1],[0,max]). Then it uses to random numbers to specify a point in this area and checks wether it resides in the area under p(x). Attention: Since this is written in tcl it is probably not the fastest way to do this!
   \item
\begin{code}
vec\_random [len]
\end{code}
    returns a random vector of length \var{len} (uniform distribution on a sphere) This is done by chosing 3 uniformly distributed random numbers $[-1,1]$ If the length of the resulting vector is $<= 1.0$ the vector is taken and normalized to the desired length, otherwise the procedure is repeated until succes. On average the procedure needs 5.739 random numbers per vector. (This is probably not the most efficient way, but it works!) Ask your favorit mathematician for a proof!
   \item
\begin{code}
phivec\_random <v> <phi> [len]
\end{code}
    return a random vector at angle \var{phi} with \var{v} and length \var{len}
  \end{itemize}
 \item
  PARTICLE OPERATIONS

  Operations involving particle positions. The parameters \var{pi} can either denote the particle identity (then the particle position is extracted with the The part command command) or the particle position directly When the optional \var{box} parameter for minimum image conventions is omited the functions use the the \codebox{setmd box\_l} command.
  \begin{itemize}
   \item
\begin{code}
bond\_vec <p1> <p2>
\end{code}
    Calculate bond vector pointing from particles \var{p2} to \var{p1}
    return = (\var{p1}.pos - \var{p2}.pos)
   \item
\begin{code}
bond\_vec\_min <p1> <p2> [box]
\end{code}
    Calculate bond vector pointing from particles \var{p2} to \var{p1}
    return = MinimumImage(\var{p1}.pos - \var{p2}.pos)
   \item
\begin{code}
bond\_length <p1> <p2>
\end{code}
    Calculate bond length between particles \var{p1} and \var{p2}
   \item
\begin{code}
bond\_length\_min <p1> <p2> [box]
\end{code}
    Calculate minimum image bond length between particles \var{p1} and \var{p2}
   \item
\begin{code}
bond\_angle <p1> <p2> <p3> [type]
\end{code}
    Calculate bond angle between particles \var{p1}, \var{p2} and \var{p3}. If \var{type} is "r" the return value is in radiant. If it is "d" the return value is in degree. The default for \var{type} is "r".
   \item
\begin{code}
bond\_dihedral <p1> <p2> <p3> <p4> [type]
\end{code}
    Calculate bond dihedral between particles \var{p1}, \var{p2}, \var{p3} and \var{p4} If \var{type} is "r" the return value is in radiant. If it is "d" the return value is in degree The default for \var{type} is "r".
   \item
\begin{code}p
art\_at\_dist <p> <dist>
\end{code}
    return position of a new particle at distance \var{dist} from \var{p} with random orientation
   \item
\begin{code}
part\_at\_angle <p1> <p2> <phi> [len]
\end{code}
    return position of a new particle at distance \var{len} (default=1.0) from \var{p2} which builds a bond angle \var{phi} for (\var{p1}, \var{p2}, p-new)
   \item
\begin{code}
part\_at\_dihedral <p1> <p2> <p3> <theta> [phi] [len]
\end{code}
    return position of a new particle at distance \var{len} (default=1.0) from \var{p3} which builds a bond angle \var{phi} (default=random) for (\var{p2}, \var{p3}, p-new) and a dihedral angle \var{theta} for (\var{p1}, \var{p2}, \var{p3}, p-new)
  \end{itemize}
 \item
  VECTOR OPERATIONS

  A vector \var{v} is a tcl list of numbers with an arbitrary length Some functions are provided only for three dimensional vectors. corresponding functions contain 3d at the end of the name.
  \begin{itemize}
   \item
\begin{code}
veclen <v>
\end{code}
    return the length of a vector
   \item
\begin{code}
veclensqr <v>
\end{code}
    return the length of a vector squared
   \item
\begin{code}
vecadd <a> <b>
\end{code}
    add vector \var{a} to vector \var{b}: return = (\var{a}+\var{b})
   \item
\begin{code}
vecsub <a> <b>
\end{code}
    subtract vector \var{b} from vector \var{a}: return = (\var{a}-\var{b})
   \item
\begin{code}
vecscale <s> <v>
\end{code}
    scale vector \var{v} with factor \var{s}: return = (\var{s}*\var{v})
   \item
\begin{code}
vecdot\_product <a> <b>
\end{code}
    calculate dot product of vectors \var{a} and \var{b}: return = (\var{a}.\var{b})
   \item
\begin{code}
veccross\_product3d <a> <b>
\end{code}
    calculate the cross product of vectors \var{a} and \var{b}: return = (\var{a} x \var{b})
   \item
\begin{code}
vecnorm <v> [len]
\end{code}
    normalize a vector to length \var{len} (default 1.0)
   \item
\begin{code}
unitvec <p1> <p2>
\end{code}
    return unit vector pointing from position \var{p1} to position \var{p2}
   \item
\begin{code}
orthovec3d <v> [len]
\end{code}
    return orthogonal vector to \var{v} with length \var{len} (default 1.0) This vector does not have a random orientation in the plane perpendicular to \var{v}
   \item
\begin{code}
create\_dihedral\_vec <v1> <v2> <theta> [phi] [len]
\end{code}
    create last vector of a dihedral (\var{v1}, \var{v2}, res) with dihedral angle \var{theta} and bond angle (\var{v2}, res) \var{phi} and length \var{len} (default 1.0). If \var{phi} is ommited or set to rnd then \var{phi} is assigned a random value between 0 and 2 Pi.
  \end{itemize}
 \item
  TCL LIST OPERATIONS
  \begin{itemize}
   \item
\begin{code}
average <list>
\end{code}
    Returns the avarage of the provided \var{list}
   \item
\begin{code}
list\_add\_value <list> <val>
\end{code}
    Add \var{val} to each element of \var{list}
   \item
\begin{code}
flatten <list>
\end{code}
    flattens a nested \var{list}
   \item
\begin{code}
list\_contains <list> <val>
\end{code}
    Checks wether \var{list} contains \var{val}. returns the number of occurences of \var{val} in \var{list}.
  \end{itemize}
 \item
  REGRESSION
  \begin{itemize}
   \item
\begin{code}
LinRegression <l>
\end{code}
    \var{l} is a list {{x1 y1} {x2 y2} ...} of points. LinRegression returns the least-square linear fit a*x+b and the standard errors da and db.
   \item
\begin{code}
LinRegressionWithSigma <l>
\end{code}
    \var{l} is a list {{x1 y1 s1} {x2 y2 s2} ...} of points with standard deviations. LinRegression returns the least-square linear fit a*x+b plus the standard errors da and db, cov(a,b) and chi.
  \end{itemize}
\end{itemize}


\section{Programmer's guide}
This page contains some hints on extending \es{}. It is not exhaustive, so for major changes the best documentation are still the original developers:
\begin{itemize}
 \item Axel
 \item Hanjo
\end{itemize}

For some simple tasks here is a small compendium of often requested things:
\begin{itemize}
 \item Adding global variables
 \item Adding new bonded interactions
 \item Adding new nonbonded interactions
 \item Adding constraints
 \item Particle data organization
 \item Errorhandling for developers
\end{itemize}

\subsection{Adding global variables}
Global variables are the simplest way to communicate values between the Tcl script and the C simulation code. To make a C variable available to Tcl, declare the variable extern in a header file that you then include in global.c. Then add a new line to fields (for details on the entries see Datafield). Basically you have to declare where the variable is stored, which type (INT or DOUBLE) it has and how many elements. A callback procedure can be given which checks if the given value is valid and stores it. It is also responsible for dispatching the new value to the other nodes, if necessary. The easiest way to do that is by using mpi\_bcast\_parameter, which will transfer the value to the other nodes. A simple example is box\_l with the callback procedure boxl\_callback. For mpi\_bcast\_parameter to work, it is necessary that they occur in the variables enumeration. So please keep this list in sync! Another list to keep up to date is the Description of the global variables.

\subsection{Adding new bonded interactions}
Every interaction resides in an own header file. A simple example for a bonded interaction is the FENE bond in fene.h. The data structures, however, reside in interaction\_data.h. The bonded interactions are all stored in a union, Bonded\_ia\_parameters. For a new interaction, just add another struct. Each bonded interaction is assigned a type number, which has the form BONDED\_IA\_*, e. g. BONDED\_IA\_FENE. The new interaction also has to have such a unique number.

After the setup of the necessary data structures in interaction\_data.h, write the header file, something like new\_interaction.h. You may want to use fene.h as a template file. Typically, you will have the following procedures:
\begin{itemize}
 \item
\begin{code}
int *\_set\_params(int bond\_type, <parameters>)
\end{code}
  this function is used to define the parameters for a bonded interaction. The \var{bond\_type} is the bond type number from the inter command, and not one of the BONDED\_*. It is rather an index to the bonded\_ia\_params array. make\_bond\_type\_exist makes sure that all bond types up the given type exist and are preinitialized with BONDED\_IA\_NONE, i. e. are empty bond types. Therefore fill bonded\_ia\_params[bond\_type] with the parameters of your interaction type.
 \item
\begin{code}
int calc\_*\_force(Particle *p1, Particle *p2,...,
 Bonded\_ia\_parameters *iaparams, double dx[3],
 double force[3],...)
\end{code}
  This routine calculate the force between the particles. ia\_params represents the parameters to use for this bond, dx represents the vector pointing from particle 2 to particle 1. The force on particle 1 is placed in the force vector (and not added to it). The force on particle 2 is obtained from Newton's law. For many body interactions, just add more particles in the beginning, and return the forces on particles 1 to N-1. Again the force on particle N is obtained from Newton's law. The procedure should return 0 except when the bond is broken, in which case 1 is returned.
 \item
\begin{code}
int *\_energy(Particle *p1, Particle *p2, ...,
 Bonded\_ia\_parameters *iaparams, double dx[3],
 double *\_energy)
\end{code}
  This calculates the energy originating from this bond. The result is placed in the location \var{\_energy} points to, \var{ia\_params} and \var{dx} are the same as for the force calculation, and the return value is also the flag for a broken bond.
\end{itemize}

After the preparation of the header file, the bonded interaction has to be linked with the rest of the code. In interaction\_data.c, most of the work has to be done:
\begin{enumerate}
 \item Add a name for the interaction to get\_name\_of\_bonded\_ia.
 \item In calc\_maximal\_cutoff, add a case for the new interaction which makes sure that max\_cut is larger than the interaction range of the new interaction, typically the bond length. This value is always used as calculated by calc\_maximal\_cutoff, therefore it is not strictly necessary that the maximal interaction range is stored explicitly.
 \item Add a print block for the new interaction to printBondedIAToResult. The print format should be such that the output can be used as input to inter, and defines the same bond type.
 \item in inter\_parse\_bonded, add a parser for the parameters. See the Tcl I/O - Parsing and printing section below.
\end{enumerate}

Besides this, you have enter the force rsp. energy calculation routines in add\_bonded\_force, add\_bonded\_energy, add\_bonded\_virials and calc\_p\_tensor. The pressure occurs twice, once for the parallelized isotropic pressure and once for the tensorial pressure calculation. For pair forces, the pressure is calculated using the virials, for many body interactions currently no pressure is calculated.

After the new bonded interaction works properly, it would be a good idea to add a testcase to the testsuite, so that changes breaking your interaction can be detected early.

\subsection{Adding new nonbonded interactions}
Writing nonbonded interactions is similar to writing nonbonded interactions. Again we start with interaction\_data.h, where the parameter structure has to be setup. Just add your parameters with reasonable names to IA\_parameters. Note that there must be a setting for the parameters which disables the interaction.

Now write the header file for the interaction. This time ljcos.h may be a good example. The needed routines are
\begin{itemize}
 \item
\begin{code}
int print*IAToResult(Tcl\_Interp *interp, int i, int j)
\end{code}
  writes out the interaction parameters between particles of type \var{i} and \var{j} to the interpreters result such that the result can be fed into the inter command again to obtain the same interaction. The IA\_parameters pointer can be obtained conveniently via get\_ia\_param(i,j).
 \item
\begin{code}
int *\_parser(Tcl\_Interp * interp, int part\_type\_a, int
 part\_type\_b, int argc, char ** argv)
\end{code}
  parses the command line given by \var{argc} and \var{argv} for the parameters needed for the interaction, and writes them to the IA\_parameters for types \var{part\_type\_a} and \var{part\_type\_b}. For details on writing the parser, see Tcl I/O - Parsing and printing. The routine returns 0 on errors and otherwise the number of parameters that were read from the command line.
 \item
\begin{code}
void add\_*\_pair\_force(Particle *p1, Particle *p2, IA\_parameters
 *ia\_params, double d[3], double dist2, double dist, double force[3])
double *\_pair\_energy(Particle *p1, Particle *p2, IA\_parameters
 *ia\_params, double d[3], double dist2, double dist)
\end{code}
  are the force rsp. energy calculation routines. \var{ia\_params} gives the interaction parameters for the particle types of particles \var{p1} and \var{p2}, \var{d} gives the vector from particle 2 to particle 1, \var{dist} its length and \var{dist2} its squared length. The last three parameters can be chosen on demand. Note that unlike in the bonded case, the force routine is called add\_*, i. e. the force has to be added to force. The *\_pair\_energy routine simply returns the energy directly instead of the pointer approach of the bonded interactions.
\end{itemize}

Change interaction\_data.c as follows (most changes are pretty much the same for all potentials):
\begin{enumerate}
 \item modify initialize\_ia\_params and copy\_ia\_params to take care of the additional parameters needed for your potential.
 \item checkIfParticlesInteract has to be modified to also check for the no interaction condition for the new interaction (typically zero cutoff).
 \item calc\_maximal\_cutoff has to modified such that max\_cut is larger than the maximal cutoff your interaction needs. Again, the code always uses the result from this function, therefore the cutoff does not have to be stored explicitly in the interaction parameters.
 \item add your print*IAToResult routine to printNonbondedIAToResult.
 \item add the *\_parser routine to inter\_parse\_bonded.
\end{enumerate}
After this, add the force calculation to add\_non\_bonded\_pair\_force, add\_non\_bonded\_pair\_virials and calc\_p\_tensor, and the energy calculation to add\_non\_bonded\_pair\_energy.

After the new nonbonded interaction works properly, it would be a good idea to add a testcase to the testsuite, so that changes breaking your interaction can be detected early.

\subsection{Adding constraints}

\subsection{Tcl I/O - Parsing and printing}
\begin{itemize}
 \item ARG\_0\_IS
 \item Tcl\_GetDouble/Int etc
 \item Tcl\_PrintDouble/Int
 \item take care of number of arguments
 \item TCL\_INTEGER\_SPACE...
\end{itemize}

\subsection{Particle data organization}
The particle data organization is described in Cell systems, its implementation is briefly described in cells.h and ghosts.h. Here only some details on how to access the data is assembled. Writing a new cellsystem almost always requires deep interactions with the most low level parts of the code and cannot be explained in detail here.

Typically, one has to access all real particles stored on this node, or all ghosts. This is done via a loop similar to the following:
\begin{tclcode}
Cell *cell;
int c,i,np,cnt=0;
Particle *part;

for (c = 0; c < local_cells.n; c++) {
  cell = local_cells.cell[c];
  part = cell->part;
  np   = cell->n;
  for(i=0 ; i < np; i++) {
    do_something_with_particle(part[i]);
  }
}
\end{tclcode}
To access the ghosts instead of the real particles, use ghost\_cells instead of local\_cells.

Another way to access particle data is via local\_particles. This array has as index the particle identity, so that local\_particles[25] will give you an pointer to the particle with identity 25, or NULL, if the particle is not stored on this node, neither as ghost nor as real particle. Note that the local\_particle array does not discriminate between ghosts and real particles. Its primary use is for the calculation of the bonded interactions, where it is used to efficiently determine the addresses of the bonding partner(s).

The master node can add and remove particles via place\_particle and remove\_particle, or change properties via set\_particle\_v etc. This is the preferred way to handle particles, since it is multiprocessor save.

However, some algorithms, especially new cellsystems, may force you to operate locally on the particle data and shift them around manually. Since the particle organization is pretty complex, there are additional routines to move around particles between particle lists. The routines exist in two versions, one indexed, and one unindexed. The indexed version take care of the local\_particles array, which for each particle index tells where to find the particle on this node (or NULL if the particle is not stored on this node), while the unindexed versions require you to take care of that yourself (for example by calling update\_local\_particles). The second way is much faster if you do a lot of particle shifting. To move particles locally from one cell to another, use move\_indexed\_particle or move\_unindexed\_particle, never try to change something directly in the lists, you will create a mess! Inserting particles locally is done via append\_indexed\_particle or append\_unindexed\_particle.

Besides the local\_particles array, which has to be up to date at any time, there is a second array particle\_node, which is available on the master node only outside of the integrator, i. e. in the Tcl script evaluation phases. If particle\_node is NULL, you have to call build\_particle\_node to rebuild it. It contains for each particle identity the node the particle is currently located on.

The proper cell for a particle is obtained via CellStructure::position\_to\_node, which calculates for a given position the node it belongs to, and CellStructure::position\_to\_cell, which calculates the cell it belongs to on this node, or NULL, if the cell is from a different node. However, you should normally not be bothered with this information, as long as you stick to place\_particle and the other routines to modify particle data.

Writing a new cellsystem basically requires only to create the functions listed in CellStructure. The init function has to also setup the communicators, which is the most complex part of writing a new cellsystem and contains all the communication details. prepare\_comm is a small wrapper for the most common operations. Otherwise just grep for CELL\_STRUCTURE\_DOMDEC, and add some appropriate code for your cell system. Note, however, that each cell system has its specific part of the code, where only this cellsystem does something strange and unique, so here you are completely on your own. Good luck.

\subsection{Errorhandling for developers}
Developers should use the errorhandling mechanism whenever it is possible to recover from an error such that continuing the simulation is possible once the source of the error is removed, i. e. the bond is removed or a parameter changed. For example, if due to excessive forces, particles have been far out of their current node, \es{} puts them into one of the local cells. Since the position is unphysical anyways, it is of no importance anymore, but now the user can place the particles anew and perhaps decrease the time step such that the simulation can continue without error. However, most often the recovery requires no special action.

To issue an background error, call errtxt=runtime\_error(length), where length should be the maximal length of the error message (you can use TCL\_DOUBLE\_SPACE rsp. TCL\_INTEGER\_SPACE to obtain space for a double rsp. integer). The function returns a pointer to the current end of the string in error\_msg. After doing so, you should use the "ERROR\_SPRINTF" - macro, which substitutes to a simple "sprintf", so that your errormessage will automatically be added to the "runtime\_errors resolved"-page. Please make sure that you give each of your errors an unique 3-digit errorcode (for already used errorcodes have a look at the "runtime\_errors resolved"-page), have the curled braces around your message and the space at the end, otherwise the final error message will look awful and will propably not automatically be added to our error-page. Typically, this looks like this:
\begin{tclcode}
if (some_error_code != OK) {
 char *errtxt = runtime_error(TCL_INTEGER_SPACE + 128);
 ERROR_SPRINTF(errtxt, "{error occured %d} ", some_error_code);
 recovery;
}
\end{tclcode}

If you have long loops during which runtime errors can occur, such as the integrator loop, you should call check\_runtime\_errors from time to time inbetween and exit the loop on errors. Note that this function requires all nodes to call it synchronously.

In all cases, all Tcl commands should call mpi\_gather\_runtime\_errors before exiting. You simply handover the result you were just about to return. If the result was TCL\_ERROR, then mpi\_gather\_runtime\_errors will keep the Tcl error message and eventually append the background errors. If the result was TCL\_OK, i. e. your function did not find an error, the result will be reset (since \es{} is in an undefined state, the result is meaningless), and only the background errors are returned. Whenever a Tcl command returns, instead of "return TCL\_OK/TCL\_ERROR" you should use
\codebox{return mpi\_gather\_runtime\_errors(interp, TCL\_OK/TCL\_ERROR);}
For a full list of background-errors visit the background\_errors resolved page

\subsection{Adding other stuff}
Here you are mostly on your own. Contacting the original developers might really help. Nevertheless the next two sections contain some information you very likely will need. But keep in mind that \es{} is a parallel code; therefore the organization is more complicated as one thinks it has to be.


\section{The t\_random command}
\begin{itemize}
 \item
   Without further arguments,
\begin{code}
t\_random
\end{code}
   returns a random double between 0 and 1 using the 'ran1' random number generator from Numerical Recipes.
 \item
\begin{code}
t\_random int <n>
\end{code}
  returns a random integer between 0 and n-1.
 \item
\begin{code}
t\_random seed
\end{code}
  returns a tcl-list with the seeds of the random number generators on each of the 'n\_nodes' nodes, while
\begin{code}
t\_random seed <seed(0)> ... <seed(n\_nodes-1)>
\end{code}
  sets those seeds to the new values respectively, re-initialising the random number generators on each node.
  Note that this is automatically done on invoking Espresso, however due to that your simulation will always start with the same random sequence on any node unless you use this tcl-command to reset the sequences' seeds.
 \item
  Since internally the random number generators' random sequences are not based on mere seeds but rather on whole random number tables, to recover the exact state of the random number generators at a given time during the simulation run (e. g. for saving a checkpoint) requires knowledge of all these values. They can be accessed by
\begin{code}
t\_random stat
\end{code}
  which returns a tcl-list with all status informations for any node (e. g. 8 nodes $=>$ approx. 350 parameters). To overwrite those internally in Espresso (e. g. upon restoring a checkpoint) submit the whole list back using
\begin{code}
t\_random stat <status-list>
\end{code}
  with \var{status-list} being the tcl-list mentioned above without any braces.
  Be careful! A complete recovery of the current state of the simulation is only possible if you make sure to include a call to The invalidate\_system command after you saved the checkpoint (tcl\_checkpoint\_set will do this automatically for you), because the integration algorithm re-uses the old forces calculated in the previous time-step; if something has changed in the system (or if it has just been read from a file) the forces are re-derived (including application of the thermostat and its random numbers) leading to slightly different results compared to the uninterrupted run (see The invalidate\_system command for details)!
\end{itemize}
The C implementation is t\_random

\section{The bit\_random command}
\begin{itemize}
 \item
  Without further arguments,
\begin{code}
bit\_random
\end{code}
  returns a random double between 0 and 1 using the R250 generator XOR-ing a table of 250 linear independent integers.
 \item
\begin{code}
bit\_random seed
\end{code}
  returns a tcl-list with the seeds of the random number generators on each of the 'n\_nodes' nodes, while
\begin{code}
bit\_random seed <seed(0)> ... <seed(n\_nodes-1)>
\end{code}
  sets those seeds to the new values respectively, re-initialising the random number generators on each node.
  Note that this is automatically done on invoking Espresso, however due to that your simulation will always start with the same random sequence on any node unless you use this tcl-command to reset the sequences' seeds.
 \item
  Since internally the random number generators' random sequences are not based on mere seeds but an array of 250 linear independent integers whose bits are used as matrix elements which are XOR-ed, to recover the exact state of the random number generators at a given time during the simulation run (e. g. for saving a checkpoint) requires knowledge of all these values. They can be accessed by
\begin{code}
bit\_random stat
\end{code}
  which returns a tcl-list with all status informations for any node (e. g. 8 nodes $=>$ approx. 2016 parameters). To overwrite those internally in Espresso (e. g. upon restoring a checkpoint) submit the whole list back using
\begin{code}
bit\_random stat <status-list>
\end{code}
  with <status-list> being the tcl-list mentioned above without any braces.
  Be careful! A complete recovery of the current state of the simulation is only possible if you make sure to include a call to The invalidate\_system command after you saved the checkpoint (tcl\_checkpoint\_set will do this automatically for you), because the integration algorithm re-uses the old forces calculated in the previous time-step; if something has changed in the system (or if it has just been read from a file) the forces are re-derived (including application of the thermostat and its random numbers) leading to slightly different results compared to the uninterrupted run (see The invalidate\_system command for details)!
 \item
  Note further that the bit-wise display of integers, as it is used by this random number generator, is platform dependent. As long as you stay on the same architecture this doesn't matter at all; however, it wouldn't be wise to use a checkpoint including the state of the R250 to restart the simulation on a different platform - most likely, the integers will have a different bit-muster leading to a completely different random matrix.
  So, if you're using this random number generator, always remain on the same platform!
\end{itemize}

The C implementation is bit\_random

\section{The Samples Directory}
In the directory \es{}/samples you find several scripts that can serve as samples how to use \es{}.
\begin{enumerate}
 \item lj\_liquid.tcl
  Simple Lennard-Jones particle liquid. Shows the basic features of \es{}: How to set up system parameters, particles and interactions. How to warm up and integrate. How to write parameters, configurations and observables to files. How to handle the connection to VMD.
 \item kremerGrest.tcl
  This reproduces the data of K.Kremer/G.S.Grest, J.Chem.Phys. 92(8), 5057-5086 (1990): Multiple systems with different number of neutral polymer chains of various lengths are simulated for very long times at melt density 0.85 while their static and some dynamic properties are measured.
  Shows the advanced features of \es{}: How to run several simulations from a single script. How to use online-analysis (The analyze command) with comparision to expectation values. How to get averages of the observables. How to set/restore checkpoints (Using Checkpoints, saving configurations) including auto-detection of previously derived parts of the simulation(s). How to create gnuplots from within the script and combine multiple plots onto duplex pages (Statistical Analysis and Creating Gnuplots).
  In the end the script will provide plots of all important quantities as .ps- and .pdf-files while compressing the data-files. Note however, that the simulation uses the original time scale, hence it may take quite some time to finish.
 \item pe\_solution.tcl
  Polyelectrolyte solution under poor solvent condition. Test case for comparison with data produced by polysim9 from M.Deserno. Note that the ewuilibration of this system takes roughly 15 000 tau.
  \begin{itemize}
   \item pe\_analyze.tcl
    Example for doing the analysis after the actual simulation run (offline analysis). Calculates the integrated iondistribution P(r) for several different time slaps, compares them and presents the final result using gnuplot to generate some ps-files.
  \end{itemize}
 \item harmonic\_oscillator.tcl
  A chain of harmonic oscillators. This is a T=0 simulation to test the energy conservation.
 \item espresso\_logo.tcl
  The \es{} Logo, the exploding espresso cup, has been created with this script. It is a regular simulation of a polyelectrolyte solution. It makes use of some nice features of the The part command command, namely the capability to fix a particle in space and to apply an external force.
 \item watch.tcl
  Script to visualize any of your productions. Use the -h option when calling it to see how it works.
\end{enumerate}

\section{The setmd command}
\begin{code}
setmd <variable> <value>+
\end{code}
modifies variables declared in fields. More information can be found in Global variables. The C implementation is setmd. Using
\begin{code}
[setmd <variable>]
\end{code}
gives the actual value of <variable> in the MD code back to the Tcl script.


\section{Statistical Analysis and Creating Gnuplots}
The following procedures are found in scripts/statistics.tcl.
\begin{itemize}
 \item
\begin{code}
plotObs <file> {x:y1 ... x:yn} [titles {"title.y1" ... "title.yn"}]
 [labels {"xlabel" "ylabel"}] [scale <gnuplot-scale>]
 [cmd <gnuplot-command>] [out <out>]
\end{code}
  creates a gnuplot of the column-wise stored data in \var{file} writing it to \var{file}.ps by default.
  Using gnuplot syntax, the columns x:y1,... are plotted (e. g. '3:2 3:5 3:8' plots the 3rd column as x-axis, the 2nd, 5th and 8th column in \var{file} as three independent data-series on the y-axis). The scale of the axis may be given with an optional flag using the gnuplot keywords, e. g. 'scale logscale xy' to enable log-log-plotting; by default, nologscale xy is assumed.

  With titles each of the data-series can be given an individual description. labels allow to set the annotation of the axis; if only the xlabel is specified, the filename \var{file} is used for the y-axis.
  If the different data series are in multiple files, \var{files} may be given as a tcl-list '{ \var{file1} \var{file2} ... }'; however, in this case each x:yi refers to one file only, hence the length of both tcl-lists must be equal.
  For executing any other gnuplot-commands simply pass them as one-liner using the 'cmd <gnuplot-command>'-option, e. g. plotObs ... cmd "set key left" to adjust the titles on the left side.
  To specify a different output-file than the default \var{file}.ps, use the out \var{out}-option; in that case <out>.ps is the result.
 \item
\begin{code}
plotJoin <destinations> <final>
\end{code}
  joins the .ps-files given by the tcl-list <destinations> into one single .ps-file '<final>.ps' while placing any two files on one page.
  Note that the resulting files may be huge and therefore hard to print!
 \item
\begin{code}
calcObAv <file> <index> [<start>]
\end{code}
  returns the average of the column with index \var{index} in \var{file}.
  If the optional parameter <start> is given, the first <start> lines are discarded, the average is only taken for the remaining data in <file>.
 \item
\begin{code}
calcObErr <file> <index> [<start>]
\end{code}
  returns the error of the average of the column with index \var{index} in \var{file}.
  If the optional parameter \var{start} is given, the first <start> lines are discarded, the average is only taken for the remaining data in \var{file}.
 \item
\begin{code}
calcObsAv <file> { <i1> <i2> ... } [<start>]
\end{code}
  derives column-averages of the observables stored at columns with index \var{i1}, \var{i2},... in \var{file}, returning a tcl-list
\begin{code}
<amount of samples> \{ names (taken from the first line) \}
 \{ averaged values \} \{ errors of averaged values \}
\end{code}
  This is most effective if you are using
\begin{code}
puts \$file-handle "[setmd time] \$observable1 \$observable 2 ..."
\end{code}
  in your tcl-script to create the data file \var{file}, and you need the averages of the observables afterwards.
  Again, if \var{start} is given, as many lines are skipped before the derivation of the average commences.
 \item
\begin{code}
findObsAv <val> <what>
\end{code}
  extracts the values whose names are given in the tcl-list \var{val} at their respective positions in \var{what}, where \var{what} has the list-format as returned by tcl\_calcObsAv, returning just these values as tiny tcl-list.
 \item
\begin{code}
nameObsAv <file> { <name1> <name2> ... } [<start>]
\end{code}
  combines tcl\_calcObsAv and tcl\_findObsAv by accepting the header-names '\var{name1}...' as input argument, returning the averages as a tiny tcl-list
\begin{code}
<\# of samples> <average of name1> <average of name2> ...
 <error of average1> <error of average2> ...
\end{code}
 \item
  Example:
  If the data-file 'data.obs2' looks like
\begin{code}
t mindist re rg rh Temp p p2 ideal pid 
0.0 0.926135 6.39158 2.66884 2.53191 1.0 5.954496
 35.456017 ideal 0.851101 
3.0 0.898834 6.21145 2.67247 2.54319 0.974109 6.003794
 36.045547 ideal 0.851101
6.0 0.907179 6.27208 2.66989 2.52997 0.97327 6.200693
 38.448588 ideal 0.851101
9.0 0.902748 6.83424 2.69967 2.53421 0.988377 6.366481
 40.532074 ideal 0.851101 
... 
\end{code}
  the following will create a tcl-list '\$avg' containing the averages of some of the observables:
\begin{tclcode}
lappend what [calcObsAv data.obs2 { 1 5 6 7 9 } ]
set avg [findObsAv { Temp mindist p p2 pid } [lindex
 \$what end]] 
\end{tclcode}
  The same is achievable with just one line using:
\begin{tclcode}
set avg [nameObsAv data.obs2 { Temp mindist p p2 pid }] 
\end{tclcode}
In both cases, the resulting tcl-list will have the form:
\begin{tclcode}
4801 0.909671168923 1.0011450302 6.27845111352 ... 
\end{tclcode}
\end{itemize}

\section{Using the Tcl Extension}
The program \es{} is an enhanced Tcl interpreter. Additionally to the standard commands of Tcl it offers the following commands, which are implemented in C and provide the interface between the Tcl script and the MD code:
\begin{itemize}
 \item Setting up the particles
  Most important commands: part .
 \item Setting up the interactions
  Most important commands: inter, setmd
 \item Running your simulation
  Most important commands: integrate, thermostat, cellsystem
 \item Analyzing your data
  Most important commands: analyze
 \item File I/O and utilities
  Most important commands: blockfile, checkpoints
 \item Checking for features of \es{}
  Most important commands: code\_info, has\_feature, require\_feature
 \item Additional TCL-Procedures
  File format conversions, Math, Analysis, Graphics 
\end{itemize}
Section Errorhandling describes the structure of error messages that may be returned. Furthermore, you may put a file .espressorc into your home directory that contains Tcl-commands. This file will be loaded upon the start of an \es{} script.

\subsection{Setting up the particles}
\begin{itemize}
 \item
\begin{code}
part <particle\_number> ( pos|type|q|v|f|quat|omega|torque|
 [un]fix <x> <y> <z> |ext\_force|bond| [delete] <value>+ )*
\end{code}
  modifies particle data. For more information, see The part command.
\end{itemize}
Pre-defined geometries:
\begin{itemize}
 \item
\begin{code}
polymer <N\_P> <MPC> <bond\_length> [start <part\_id>] [pos <x> <y>
 <z>] [mode { SAW | RW } [<shield> [<max\_try>]]] [charge <val\_cM>]
 [distance <cM\_dist>] [types <type\_nM> [<type\_cM>]]
 [FENE <type\_FENE>] [angle <angle> [<angle2> [<x2> <y2> <z2>]]]
\end{code}
  creates \var{N\_P} polymer chains with \var{MPC} monomers each \var{bond\_length} apart in the simulation box. For more information, see The polymer command.
 \item
\begin{code}
counterions <N\_CI> [start <part\_id>] [mode { SAW | RW } [<shield>
 [<max\_try>]]] [charge <val\_CI>] [type <type\_CI>]
\end{code}
  creates \var{N\_CI} counterions in the simulation box. For more informations, see The counterions command.
 \item
\begin{code}
salt <N\_pS> <N\_nS> [start <part\_id>] [mode { SAW | RW } [<shield>
 [<max\_try>]]] [charges <val\_pS> [<val\_nS>]] [types <type\_pS>
 [<type\_nS>]]
\end{code}
  creates \var{N\_pS} positively and \var{N\_nS} negatively charged salt ions of charge \var{val\_pS} and \var{val\_nS} within the simulation box. For more information, see The salt command.
 \item
\begin{code}
diamond <a> <bond\_length> <MPC> [counterions <N\_CI>] [charges
 <val\_nodes> <val\_cM> <val\_CI>] [distance <cM\_dist>] [nonet]
\end{code}
  Creates a diamond-shaped polymer network with 8 tetra-functional nodes connected by 2*8 polymer chains of length \codebox{MPC}. For more information, see The diamond command.
 \item
\begin{code}
icosahedron <a> <MPC> [counterions <N\_CI>] [charges <val\_cM>
 <val\_CI>] [distance <cM\_dist>]
\end{code}
  Creates a modified icosahedron to model a fulleren (or soccer ball). For more information, see The icosahedron command.
\end{itemize}

Auxiliary functions:
\begin{itemize}
 \item
\begin{code}
crosslink <N_P> <MPC> [start <part_id>] [catch <r_catch>]
 [distLink <link_dist>] [distChain <chain_dist>] [FENE
 <type_FENE>] [trials <max_try>] 
\end{code}
  Attempts to end-crosslink the current configuration of <N\_P> equally long polymers with <MPC> monomers each, returning how many ends are successfully connected. For more information, see The crosslink command.
 \item
\begin{code}
velocities <v_max> [start <part_id>] [count <N_T>] 
\end{code}
  Sets the velocities of the particles with particle ID (see The part command) between <part\_id> and <part\_id>+<N\_T> (defaults to '0' \& '[setmd npart]-<part\_id>') to a random vector with length in [-vmax,vmax], and returns the absolute value of the total velocity assigned.
\end{itemize}

\subsection{Setting up the interactions and parameters}
\begin{itemize}
 \item
\begin{code}
inter ( <particle_type_number1> <particle_type_number2> |
 <bond_type_number> ) <interaction_type> <value>+ 
\end{code}
  sets the parameters for interactions. For more information, see The inter command.
 \item
\begin{code}
setmd <variable> <value>+ 
\end{code}
  modifies variables declared in fields. For more information, see The setmd command.
 \item
\begin{code}
constraint <type_name | delete> [parameters] 
\end{code}
  sets the parameters for constraints. For more information, see The constraint command.
\end{itemize}

\subsection{Running the simulation}
\begin{itemize}
 \item
\begin{code}
integrate { <steps> | set <method> <parameter>+ } 
\end{code}
  Run <steps> integration steps or set an integration method. The C implementation is integrate.
 \item
\begin{code}
thermostat { <method> <parameter>+ | off } 
\end{code}
  Change thermostat settings. See also thermostat.h The C implementation is thermostat.
 \item
\begin{code}
change_volume { <V_new> | <L_new> { x | y | z | xyz } } 
\end{code}
  changes the volume of either a cubic simulation box to the new volume <V\_new> or its given x-/y-/z-/xyz-extension to the new box-length <L\_new>, and isotropically adjusts the particles coordinates as well. The function returns the new volume of the deformed simulation box. The C implementation is change\_volume.
 \item
\begin{code}
invalidate_system 
\end{code}
  forces a system re-init which, among others, helps to ensure continuity upon working with checkpoints. For more information, see The invalidate\_system command.
 \item
\begin{code}
cellsystem 
\end{code}
  Changes the data structure to the desired cell system. For more information, see Cell systems.
 \item
\begin{code}
nemd { <method> <parameter>+ | off | profile | viscosity } 
\end{code}
  Use NEMD (Non Equilibrium Molecular Dynamics) to simulate a system under shear. See also nemd.h. The C implementation is nemd.
 \item
\begin{code}
imd ( connect|disconnect|listen|positions ) <param>
\end{code}
 \item
\begin{code}
prepare_vmd_connection [<filename> [<wait> [<start>]]] 
\end{code}
  network connection handling to the visual interface program VMD. For more information, see IMD.
\end{itemize}

\subsection{Performing an analysis of the system}
\begin{itemize}
 \item
\begin{code}
analyze ( mindist|nbhood|distto| energy | pressure | rdf |
 distribution | set|re|rg|rh|g123|formfactor|internal_dist... )
\end{code}
  calculates different observables of the current configuration and/or of a given set of previous states.
  For more information on its vast abilities, see The analyze command.
 \item
\begin{code}
uwerr <data> <nrep> {<col>|<f>} [<s_tau> [<f_args>]] 
\end{code}
  get the error of errors of Monte Carlo simulations. (see The uwerr comand)
\end{itemize}

\subsection{File-I/O, checkpoints}
\begin{itemize}
 \item
\begin{code}
blockfile <channel> ( read|write start|end|variable|auto|toend )
 <param>?
\end{code}
  blockfile allows for convenient access to a block format structured file <channel>. For more information, see The blockfile command.
 \item
\begin{code}
checkpoint_set <destination> [<# of configs> [<tclvar>
 [<ia_flag>]]]
\end{code}
 \item
\begin{code}
checkpoint_read <origin>
\end{code}
 \item
\begin{code}
polyBlockWrite <path> <param_list> <part_list>
\end{code}
 \item
\begin{code}
polyBlockWriteAll <destination> [<tcl-var> [<rdm> [<configs>]]] 
\end{code}
  The first two commands aid in saving/restoring the complete current and previous states of the simulation run, while the other two use The blockfile command to write informations about the current timestep to disk. For details on checkpoints, refer to Using Checkpoints, saving configurations.
 \item
\begin{code}
t_random [{ int <n> | seed [<seed(0)> ... <seed(n_nodes-1)>] |
 stat [status-list] }]
\end{code}
 \item
\begin{code}
bit_random [{ seed [<seed(0)> ... <seed(n_nodes-1)>] | stat
 [status-list] }] 
\end{code}
 \item
\begin{code}
g_random 
\end{code}
  different implementations of random number generators returning random deviates with a uniform probability distribution, except for gauss\_random which returns normally (Gaussian) distributed deviates with zero mean and unit variance, using t\_random as the source of uniform deviates, and Numerical Recipes' Transformation Mehod (ch. 7.2).
  For details and more information, see The t\_random command or The bit\_random command.
\end{itemize}

\subsection{Checking for features of the \es{} kernel}
\begin{itemize}
 \item
\begin{code}
code_info 
\end{code}
 \item
\begin{code}
has_feature [<feature>...]
\end{code}
 \item
\begin{code}
require_feature [<feature>...]
\end{code}
  get information on version, compilation status and the Features of the \es{} program of the used \es{} program. For more information, see Checking for features in the \es{} Tcl-Script.
\end{itemize}

\subsection{Additional TCL-Procedures}
At program start, \es{} reads in a starting script 'init.tcl'. It is assumed to be located in a directory "scripts", but this default value can be overridden by the environment variable ESPRESSO\_SCRIPTS.
It also includes some useful tcl-scripts (which should always be located in the same directory "scripts") providing additional commands which are implemented in tcl and enhance the interface between the tcl-script and the MD-code. For details on these procedures see
\begin{itemize}
 \item Conversion of Deserno files
 \item Statistical Analysis and Creating Gnuplots
 \item Using Checkpoints, saving configurations
 \item Writing pdb/psf files
 \item Additional Tcl math-functions
 \item Auxiliary Tcl functions
 \item Running Jobs at the Blade-Center
\end{itemize}

\subsection{Errorhandling}
Errors in the parameters are detected as early as possible, and hopefully self explanatory error messages returned without any changes to the data in the internal data of \es{}. This include errors such as setting nonexistent properties of particles or simply misspelled commands. These errors are returned as standard Tcl errors and can be caught on the Tcl level via
\begin{tclcode}
catch {script} err 
\end{tclcode}
When run noninteractively, Tcl will return a nice stack backtrace which allows to quickly find the line causing the error.

However, some errors can only be detected after changing the internal structures, so that \es{} is left in a state such that integration is not possible without massive fixes by the users. Especially errors occuring on nodes other than the primary node fall under this condition, for example a broken bond or illegal parameter combinations.

For error conditions such as the examples given above, an Tcl error message of the form
\begin{tclcode}
<Tcl error> background 0 {<error a>} {<error b>} 1 {<error c>}
\end{tclcode}
is returned. Following possibly a normal Tcl error message, after the background keyword all severe errors are listed node by node, preceeded by the node number. a special error is "<consent>", which means that one of the slave nodes found exactly the same errors as the master node. This happens mainly during the initialization of the integrate, e. g. if the time step is not set. In this case the error message will be
\begin{tclcode}
background_errors 0 {time_step not set} 1 <consent> 
\end{tclcode}
In each case, the current action was not fulfilled, and possibly other parts of the internal data also had to be changed to allow \es{} to continue, so you should really know what you do if you try and catch these errors.

For a full list of background-errors visit the background\_errors resolved page 


\section{The uwerr comand}


\tclcommand{uwerr}
{
  \var{data}
  \var{nrep}
  \opt{\var{col}|\var{f}}
  \opt{\var{a\_tau} \opt{\var{f\_args}}}
  \opt{plot}
}
calculates the value, the error and the error of the error for arbitrary functions of elementary observables in Monte Carlo simulations.

\begin{arguments}
\item[\var{data}]
 is a matrix filled with the primary estimates $a_\alpha^{i,r}$ from $R\/$ replica with $N_1,N_2,\ldots,N_R$ measurements each.
 \[data=\left(\begin{array}{*{4}{c}} a_1^{1,1}&a_2^{1,1}&a_3^{1,1}&\cdots\\ a_1^{2,1}&a_2^{2,1}&a_3^{2,1}&\cdots\\ \vdots&\vdots&\vdots&\vdots\\ a_1^{{N_1},1}&a_2^{{N_1},1}&a_3^{{N_1},1}&\cdots\\ a_1^{1,2}&a_2^{1,2}&a_3^{1,2}&\cdots\\ \vdots&\vdots&\vdots&\vdots\\ a_1^{{N_R},R}&a_2^{{N_R},R}&a_3^{{N_R},R}&\cdots\\ \end{array}\right)\]

\item[\var{nrep}]
 is a vector whose elements specify the length of the individual replica.
 $$nrep=\left(N_1,N_2,\ldots,N_R\right)$$

\item[\opt{\var{f}}]
     is a user defined tcl function returning a double with first argument a vector which has as many entries as data has columns. If \var{f} is given instead of the column the coresponding derived quantity is anlayzed. 

\item[\opt{\var{f\_args}}]
 further arguments to f.

\item[\opt{\var{s\_tau}}]
 is the estimate $S=\tau/tau_{\textrm{int}}$ as explained in section (3.3) of [1]. The default is 1.5 and it is never taken larger than $\min_{r=1}^R{N_r}/2$. 

\item[\opt{plot}]
 If plot is given you will get the plots of $\Gamma/\Gamma(0)$ and $\tau_{int}$ vs. $W$.
 The data and gnuplot script is written to the current directory. 
\end{arguments}

It returns a string containing the following values in the given order.
\begin{enumerate}
 \item The calculated value
 \item The error
 \item The error of the error
 \item The integrated autocorrelation time
 \item The error of that
 \item if length(nrep) > 1 The Q-value, i.e. the probability to find a $\chi^2$ fit of the replica estimates
\end{enumerate}

The users is warned with a string if the windowing failed or if the error in one of the replica is to large.

This function is based on the matlab function presented in
[1] arXiv:hep-lat/0306017 v1 13. Jun 2003, Wolff, U., Monte Carlo errors with less errors. 


\section{The Testsuite Directory}
The scripts in the directory your\_directory/Espresso/testsuite are used to check wether changes in the program code affect basic properties of ESPResSo. Befor checking in any changes please make sure that this test is succesfull. To run the test type gmake test in the directory your\_directory/Espresso. If you write any new features for \es{} please provide new tests for them.

This is a list of the tests that will be performed and a short description what they test.
\begin{enumerate}
 \item lj.tcl
  Tests Lennard-Jones potential: Energy, Pressure and Forces
 \item madelung.tcl
  Calculates the energy of a NaCl crystal. Test case for the electrostatic energy / force.
 \item cell\_model.tcl
  This example shows the use of constraints and non periodic boundary conditions. It simulates a bundle of semiflexible polyelectrolyes with hydrophobic side chains neutralized by counterions in a spherical simulation cell.
 \item diamond.tcl
  This reproduces the data of S.Schneider/P.Linse, Eur.Phys.J.E 8, 457-460 (2002): A diamond-shape network of 16 polyelectrolyte chains with 20 monomers each connected at 8 nodes is simulated for varying network packing fractions (densities) while the pressure is analysed (The analyze command). Similar to kremerGrest.tcl it additionally uses electrostatics including the auto-tuning feature (The inter command).
\end{enumerate}


\section{Writing the User's Guide}
\subsection{Structure}
The User's Guide is written in LaTeX and contains the following parts:
\begin{itemize}
 \item Introduction: this chapter shall give the reader an overview over all of ESPResSo's algorithms and methods.
 \item First steps: shall give a quick introduction on compiling and running ESPResSo, as well as on how to write a script.
 \item Installation: shall explain the installation of ESPResSo in detail.
 \item Setting up the system, Running the simulation, Analysis and Auxilliary commands: shall explain all of ESPResSo's Tcl-commands in detail.
 \item Under the hood: shall explain the important internals of ESPResSo: parallelization, cell system, ...
 \item Getting involved: where to find the DG, how to get started in using the C-code, where to report bugs, mailing list, etc.
 \item ESPResSo quick reference: automatically generated list of all Tcl command syntax descriptions
 \item Features: lists all features of ESPResSo
 \item The rest of the chapters contain scientific descriptions of some of the employed algorithms that are not to be found anywhere else.
\end{itemize}

\subsection{General issues}
\begin{itemize}
 \item Headings should start with a capital letter and continue with lower-case letters (First steps and not First Steps)
\end{itemize}

\subsection{Additional environments and commands}
To maintain a consistent layout, a number of environments and commands have been defined that should be used where applicable.
\begin{itemize}
 \item For the description of Tcl-commands, read Documentation of Tcl commands.
 \item The name of ESPResSo should be set via the command \es.
 \item The strings i.e., e.g. and et al. should be set via \ie, \eg and \etal.
 \item For short code pieces that can be displayed inline, use
\begin{tclcode}
\codebox{<text>}
\end{tclcode}
 \item For longer code pieces or the syntax decription of non-Tcl commands, the environment code exists:
\begin{tclcode}
\begin{code}
 ...
\end{code}
\end{tclcode}
  This is not a verbatim environment, i.e. it will evaluate LaTeX-commands inside. Therefore, it is necessary to be careful when using the characters $\backslash,\{ and \}$ inside! On the other hand, it is possible to use other layout commands (like \textit inside).
 \item For pieces of Tcl-code that use \{ and \}, a verbatim environment tclcode exists:
\begin{code}
\(\backslash{begin}\)\{tclcode\}
 ...
\(\backslash{end}\)\{tclcode\}
\end{code}
\end{itemize}

\subsection{Documentation of Tcl commands}
In general, all Tcl-commands have to be documented in the User's Guide. The documentation consists of two parts:
\begin{itemize}
 \item
  The formal syntax definition as described in the UG in the chapter Introduction. This syntax description should be as simple as possible, as it will be what a user references to. Avoid very long definitions and constructs like nested alternatives and options! In those cases, prefer to split the syntax definition into several subdefinitions instead of writing it in a single, complicated definition!
  Example:

  Instead of using
\begin{code}
inter <particle\_type\_number1 particle\_type\_number2
 | bond\_type\_number> interaction\_type value+
\end{code}
  better use
\begin{code}
inter type1 type2 nb\_inter\_type parameters
inter bond\_type bond\_inter\_type parameters
\end{code}
 \item
  The description of the command. In this description, every variable argument introduced via the \codebox{$\backslash var$} command in the definition has to be explained in detail:
  \begin{itemize}
   \item state explicitly the type of the argument (integer, float, string, Tcl-list)
   \item explain the meaning of the argument 
  \end{itemize}
\end{itemize}

As the Tcl-commands shall also be added to the quick reference in the appendix and furthermore a script should check whether all implemented commands are documented, Tcl commands have to be documented as follows:
\begin{itemize}
 \item
  For the syntax definition, the following LaTeX-commands exist:
  \begin{itemize}
   \item
\begin{code}
\(\backslash{var}\)\{text\}
\end{code}
     to typeset a variable argument
   \item
\begin{code}
\(\backslash{keyword}\)\{text\}
\end{code}
    or
\begin{code}
\(\backslash{lit}\)\{text\}
\end{code}
    to typeset keywords or literals These commands should be used in the syntax definition as well as in the description of the command.
  \end{itemize}
 \item
  The syntax definition of a command has to be introduced via
\begin{tclcode}
\tclcommand[<required_features>]{<name>}{<arguments>}
\end{tclcode}
  \begin{itemize}
   \item \var{required\_features} should contain a whitespace-separated list of features that are required for the command. If the fetaures are only required for certain subcommands, use brackets "()" to indicate this.
   \item \var{name} gives the base name of the command.
   \item \var{arguments} defines the arguments of the command. In this definition, stick to the description given in the Introduction and use the commands \var , \lit, \keyword. To separate lines, \\ can be used.
  \end{itemize}
  The command will generate the subheadings Syntax, Required features and Description. Furthermore, it will generate the corresponding entry in the quick reference. Example:
\begin{tclcode}
\tclcommand[LENNARD\_JONES]{inter}{%
 \var{type1 type2} 
 lennard\_jones 
 \var{epsilon sigma cutoff shift offset}
}
Defines a Lennard-Jones interaction...
\end{tclcode}
 \item
  If the command has a number of different options, i.e. independent, optional arguments, they can be described in the tcloptions environment:
\begin{tclcode}
\begin{tcloptions}
 \option{<option1>}
 <description>
 \option{<option2>}
 <description>
 ...
\end{tcloptions}
\end{tclcode}
  The environment will generate the subheading Options and nicely format the descriptions. Example:
\begin{tclcode}
\begin{tcloptions}
 \option{<short|verbose>}
 Specify, whether the output is in a human-readable, but
 somewhat longer format (\keyword{verbose}), or in a more
 compact form (\keyword{short}). The default is
 \keyword{verbose}.
 \option{<radius \var{radii}|auto>}
 Specify the VDW radii of the atoms. \var{radii} is either
 \keyword{auto}, or a Tcl-list describing the radii of the
 different...
 ...
\end{tcloptions}
\end{tclcode}
\end{itemize}

\section{Writing pdb/psf files}
The PDB (Brookhaven Protein DataBase) format is a widely used format for describing atomic configurations. PSF is a format that is used by VMD to describe the topology of a PDB file. You need the PDB and PSF files for example for IMD.
\begin{tclcode}
writepsf <file> { <N_P> <MPC> <N_CI> <N_pS> <N_nS> }|-molecule
\end{tclcode}
writes the current topology to the file <file> (here <file> is not a channel since additional information cannot be written anyways). <N\_P>, <MPC> and so on are parameters describing a system consisting of equally long charged polymers, counterions and salt. This information is used to set the residue name and can be used to color the atoms in VMD. If you specify -molecule, the residue name is taken from the molecule identity of the particle. Of course different kinds of topologies can also be handled by modified versions of writepsf.
\begin{code}
writepdb <file>
\end{code}
writes the corresponding particle data.
\begin{tclcode}
writepdbfoldchains <file> { < chain_start> <n_chains> <chain_length>
 <box_l> }
\end{tclcode}
Writes folded particle data where the folding is performed on chain centers of mass rather than single particles. In order to fold in this way the chain topology and box length must be specified. Note that this method is outdated. Use writepdbfoldtopo instead.
\begin{tclcode}
writepdbfoldtopo <file> { <shift> } 
\end{tclcode}
Writes folded particle data where the folding is performed on chain centers of mass rather than single particles. This method uses the internal box length and topology information from espresso. If you wish to shift particles prior to folding then supply the optional shift information. Shift should be a three member tcl list consisting of x, y, and z shifts respectively and each number should be a floating point (ie with decimal point).


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "ug"
%%% End: 
