Input / Output
==============

No generic checkpointing!
-------------------------

One of the most asked-for feature that seems to be missing in is
*checkpointing*, a simple way to tell to store and restore the current
state of the simulation, and to be able to write this state to or read
it from a file. This would be most useful to be able to restart a
simulation from a specific point in time.

Unfortunately, it is impossible to provide a simple command
(``checkpoint``), out of two reasons. The main reason is that has no way
to determine what information constitutes the actual state of the
simulation. On the one hand, scripts sometimes use Tcl-variables that
contain essential information about a simulation, the stored values of
an observable that was computed in previous time steps, counters, etc.
These would have to be contained in a checkpoint. However, not all
Tcl-variables are of interest. For example, Tcl has a number of
automatically set variables that contain information about the hostname,
the machine type, etc. These variables should most probably *not* be
included the simulation state. has no way to distinguish between these
variables. On the other hand, the core has a number of internal
variables, the particle coordinates. While most of these are probably
good candidates for being included into a checkpoint, this is not
necessarily so. For example, when you have particles in your system that
have fixed coordinates, should these be stored in a checkpoint, or not?
If the system contains mostly fixed particles and only very few moving
particles, this would increase the memory size of a checkpoint
needlessly. And what about the interactions in the system, or the bonds?
Should these be stored in a checkpoint, or are they generated by the
script?

Another problem with a generic checkpoint would be the control flow of
the script. In principle, the checkpoint would have to store where in
the script the checkpointing function was called to be able to return
there. All this is even further complicated by the fact that is running
in parallel.

Instead, in , the user has to specify what information needs to be saved
to a file to be able to restore the simulation state. The ``blockfile``
and ``writemd`` commands help you to do that. ``blockfile`` writes text
files. When floating point numbers are stored in such files (the
particle positions), there is only a limited precision. Therefore, it is
not possible to bitwise reproduce a simulation state using this
function. When you need bitwise reproducibility, you will have to use
the command , which stores positions, forces and velocities in binary
format. Note that there is no command to write other MD parameters like
time step or interactions in binary format. You should restore these
using exactly the same Tcl command that you used to create them.

Finally, there is one more complication: random forces are computed in
the order the particles are stored in memory. This order usually differs
after reading a blockfile back, since the particles are stored in
consecutive identity order. In memory, they are usually not in a
specific order. Therefore, you need to use ``sort_particles`` after
writing a blockfile that you want to use for checkpointing, so that the
particles are resorted to the same consecutive order. Note that this
does not change physics, just the order the random numbers are applied.

When using an LB fluid, you need to also write out the fluid nodes, see
the ``lbfluid`` command for further details.

(Almost) generic checkpointing in Python
----------------------------------------

Referring to the previous section, generic checkpointing poses
difficulties in many ways. Fortunatelly, the Python checkpointing module
presented in this section provides a comfortable workflow for an almost
generic checkpointing.

The idea is to let the user initially define which data is of interest
for checkpointing and thus solve the above mentioned problem. Once this
is done, checkpoints can then be saved simply by calling one save
function.

The checkpoint data can then later be restored easily by calling one
load function that will automatically process the checkpoint data by
setting the user variables and the checkpointed properties in .

In addition, the checkpointing module is also able to catch signals that
are invoked for example when the simulation is aborted by the user or by
a timeout.

The checkpointing module can be imported with

from espressomd import checkpointing

[ checkpoint\_path= ]

Determines the identifier for a checkpoint. Legal characters for an id
are “0-9”, “a-zA-Z”, “-”, “\_”.

Specifies the relative or absolute path where the checkpoints are
stored.

For example,

checkpoint = checkpointing.Checkpointing(checkpoint\_id=“mycheckpoint”)

would create the new checkpoint with id “mycheckpoint” and all the
checkpointing data will be stored in the current directory.

After the system and checkpointing user variables are set up they can be
registered for checkpointing:

[ , ]

Name string of the object or user variable that should be registered for
checkpointing.

To give an example,

myvar = “some variable value” skin = 0.4 checkpoint.register(“myvar”)
checkpoint.register(“skin”)

system = espressomd.System() # ... set system properties like box\_l or
timestep here ... checkpoint.register(“system”)

system.thermostat.set\_langevin(kT=1.0, gamma=1.0)
checkpoint.register(“system.thermostat”)

# ... set system.non\_bonded\_inter here ...
checkpoint.register(“system.non\_bonded\_inter”)

# ... add particles to the system with system.part.add(...) here ...
checkpoint.register(“system.part”)

# ... set charges of particles here ... from espressomd import
electrostatics p3m = electrostatics.P3M(bjerrum\_length=1.0,
accuracy=1e-2) system.actors.add(p3m) checkpoint.register(“p3m”)

will register the user variables and , system properties, a langevin
thermostat, non-bonded interactions, particle properties and a p3m
object for checkpointing. It is important to note that the checkpointing
of will only save basic system properties. This excludes for example the
system thermostat or the particle data. For this reason one has to
explicitly register and for checkpointing.

Analogous to this, objects that have been registered for checkpointing
but are no longer needed in the next checkpoints can be unregistered
with

[ , ]

A list of all registered object names can be generated with

A new checkpoint with a consecutive index that contains the latest data
of the registered objects can then be created by calling

An existing checkpoint can be loaded with

[ checkpoint\_index= ]

If no is passed the last checkpoint will be loaded. Concerning the
procedure of registering objects for checkpointing it is good to know
that all registered objects saved in a checkpoint will be automatically
re-registered after loading this checkpoint.

In practical implementations it might come in handy to check if there
are any available checkpoints for a given checkpoint id. This can be
done with

which returns a bool value.

As mentioned in the introduction the checkpointing module also enables
to catch signals in order to save a checkpoint and quit the simulation.
Therefore one has to register the signal which should be caught with

The registered signals are associated with the and will be automatically
re-registered when the same checkpoint id is used later.

Following the example above, the next example loads the last checkpoint,
restores the state of all checkpointed objects and registers a signal.

import espressomd from espressomd import checkpointing import signal

checkpoint = checkpointing.Checkpointing(checkpoint\_id=“mycheckpoint”)
checkpoint.load()

system = espressomd.System() system.cell\_system.skin = skin
system.actors.add(p3m)

#signal.SIGINT: signal 2, is sent when ctrl+c is pressed
checkpoint.register\_signal(signal.SIGINT)

# integrate system until user presses ctrl+c while True:
system.integrator.run(1000)

The above example runs as long as the user interrupts by pressing
ctrl+c. In this case a new checkpoint is written and the simulation
quits.

It is perhaps surprising that one has to explicitly create again. But
this is necessary as not all modules like or have implementations for
checkpointing yet. By calling these modules are created and can be
easily initialized with checkpointed user variables (like ) or
checkpointed submodules (like ).

.. _Writing H5MD-Files:

Writing H5MD-files
------------------

For large amounts of data it’s a good idea to store it in the hdf5 (H5MD
is based on hdf5) file format (see https://www.hdfgroup.org/ for
details). Currently |es| supports some basic functions for writing simulation
data to H5MD files. The implementation is MPI-parallelized and is capable
of dealing with varying numbers of particles.

To write data in a hdf5-file according to the H5MD proposal (see
http://nongnu.org/h5md/), first an object of the class
:class:`espressomd.io.writer.h5md.H5md` has to be created and linked to the
respective hdf5-file. This may, for example, look like:

.. code:: python

    from espressomd.io.writer import h5md
    system = espressomd.System()
    # ... add particles here
    h5 = h5md.H5md(filename=“trajectory.h5”, write_pos=True, write_vel=True)

If a file with the given filename exists and has a valid H5MD structures
it will be backed up to a file with suffix “.bak”. This file will be
removed by the close() method of the class which has to be called at the
end of the simulation to close the file. The current implementation
allows to write the following properties: positions, velocities, forces,
species (|es| types), and masses of the particles. In order to write any property, you
have to set the respective boolean flag as an option to the H5md class.
Currently available:

    - write_pos: particle positions

    - write_vel: particle velocities

    - write_force: particle forces

    - write_species: particle types

    - write_mass: particle masses

    - write_ordered: if particles should be written ordered according to their
      id (implies serial write). 



In simulations with varying numbers of particles (MC or reactions), the
size of the dataset will be adapted if the maximum number of particles
increases but will not be decreased. Instead a negative fill value will
be written to the trajectory for the id. If you have a parallel
simulation please keep in mind that the sequence of particles in general
changes from timestep to timestep. Therefore you have to always use the
dataset for the ids to track which position/velocity/force/type/mass
entry belongs to which particle. To write data to the hdf5 file, simply
call the H5md objects write method without any arguments.

h5.write()

After the last write call, you have to call the close() method to remove
the backup file and to close the datasets etc.

Writing and reading binary files
--------------------------------

Binary files are written using the command

writemd …

This will write out particle data to the Tcl channel for all particles
in binary format. Apart from the mandatory particle id, only limited
information can be stored. The coordinates (, and ), velocities (, and )
and forces (, and ). Other information should be stored in a blockfile
or reconstructed differently. Note that since both ``blockfile`` and
``writemd`` are using a Tcl channel, it is actually possible to mix
them, so that you can write a single checkpoint file. However, the
``blockfile read auto`` mechanism cannot handle the binary section, thus
you need to read this section manually. Reading of binary particle data
happens through

readmd

For the exact format of the written binary sequence, see
``src/tcl/binary_file_tcl.cpp``.

MPI-IO
------

When using with MPI, blockfiles and writemd have the disadvantage, that
the master node does *all* the output. This is done by sequentially
communicating all particle data to the master node. MPI-IO offers the
possibility to write out particle data in parallel using binary IO. To
output variables and other non-array information, use normal blockfiles
(section [sec:structured-file-format]).

To dump data using MPI-IO, use the following syntax:

mpiio …

This command writes data to several files using as common filename
prefix. Beware, that must not be a Tcl channel but a string which must
not contain colons. The data can be positions (), velocities (),
particle types () and particle bonds () or any combination of these. The
particle ids are always dumped. For safety reasons, MPI-IO will not
overwrite existing files, so if the command fails and prints
``MPI_ERR_IO`` make sure the files are non-existent.

The files produced by this command are (assumed is “1”):

1.head
    Internal information (Dumped fields, bond partner num); always
    produced

1.pref
    Internal information (Exscan results of nlocalparts); always
    produced

1.ids
    Particle ids; always produced

1.type
    Particle types; optional

1.pos
    Particle positions; optional

1.vel
    Particle velocities; optional

1.bond
    Bond information; optional

1.boff
    Internal bond prefix information; optional, necessary to read 1.bond

Currently, these files have to be read by exactly the same number of MPI
processes that was used to dump them, otherwise an error is signalled.
Also, the same type of machine (endianess, byte order) has to be used.
Otherwise only garbage will be read. The read command replaces the
particles, i.e. all previous existent particles will be *deleted*.

There is a python script (``tools/mpiio2blockfile.py``) which converts
MPI-IO snapshots to regular blockfiles.

Writing VTF files
-----------------

The formats VTF (**V**\ TF **T**\ rajectory **F**\ ormat), VSF
(**V**\ TF **S**\ tructure **F**\ ormat) and VCF (**V**\ TF
**C**\ oordinate **F**\ ormat) are formats for the visualization
software VMD:raw-latex:`\cite{humphrey96a}` [1]_. They are intended to
be human-readable and easy to produce automatically and modify.

The format distinguishes between *structure blocks* that contain the
topological information of the system (the system size, particle names,
types, radii and bonding information, amongst others), while *coordinate
blocks* (a.k.a. as *timestep blocks*) contain the coordinates for the
particles at a single timestep. For a visualization with VMD, one
structure block and at least one coordinate block is required.

Files in the VSF format contain a single structure block, files in the
VCF format contain at least one coordinate block, while files in the VTF
format contain a single structure block first and an arbitrary number of
coordinate blocks afterwards, thus allowing to store all information for
a whole simulation in a single file. For more details on the format,
refer to the homepage of the format [2]_.

Creating files in these formats from within is supported by the commands
and , that write a structure respectively a coordinate block to the
given Tcl channel. To create a VTF file, first use at the beginning of
the simulation, and then ``writevcf`` after each timestep to generate a
trajectory of the whole simulation.

The structure definitions in the VTF/VSF formats are incremental, a user
can easily add further structure lines to the VTF/VSF file after a
structure block has been written to specify further particle properties
for visualization.

Note that the ids of the particles in and VMD may differ. VMD requires
the particle ids to be enumerated continuously without any holes, while
this is not required in . When using and , the particle ids are
automatically translated into VMD particle ids. The function allows the
user to get the VMD particle id for a given particle id.

Also note, that these formats can not be used to write trajectories
where the number of particles or their types varies between the
timesteps. This is a restriction of VMD itself, not of the format.

``writevsf``: Writing the topology
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

writevsf

Writes a structure block describing the system’s structure to the
channel given by . must be an identifier for an open channel such as the
return value of an invocation of . The output of this command can be
used for a standalone VSF file, or at the beginning of a VTF file that
contains a trajectory of a whole simulation.

``writevcf``: Writing the coordinates
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

writevcf

Writes a coordinate (or timestep) block that contains all coordinates of
the system’s particles to the channel given by . must be an identifier
for an open channel such as the return value of an invocation of .

Specify, whether the output is in a human-readable, but somewhat longer
format (), or in a more compact form (). The default is .

Specify whether the particle positions are written in absolute
coordinates () or folded into the central image of a periodic system ().
The default is .

Specify the coordinates of which particles should be written. If is
used, all coordinates will be written (in the ordered timestep format).
Otherwise, has to be a Tcl-list specifying the pids of the particles.
The default is . ``pids {0 23 42}``

Specify arbitrary user data for the particles. has to be a Tcl list
containing the user data for every particle. The user data is appended
to the coordinate line and can be read into VMD via the VMD plugin
``VTFTools``. The default is to provide no userdata.
``userdata {"red" "blue" "green"}``

``vtfpid``: Translating particles ids to VMD particle ids
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

vtfpid

If is the id of a particle as used in , this command returns the atom id
used in the VTF, VSF or VCF formats.

``writevtk``: Particle Visualization in paraview
------------------------------------------------

This feature allows to export the particle positions in a paraview  [3]_
compatible VTK file. Paraview is a powerful and easy to use open-source
visualization program for scientific data. Since can export the
lattice-Boltzmann velocity field [ssec:LBvisualization] in the VTK
format as well and paraview allows to visualize particles with glyphs
and vector fields with stream lines, glyphs, contourplots, etc., one can
use it so completely visualize a coupled lattice-Boltzmann MD
simulation. It can also create videos without much effort if one exports
data of individual time steps into separate files with filenames
including a running index (``data_0.vtk``, ``data_1.vtk``, ...).

writevtk

Name of the file to export the particle positions into.

Specifies a list of particle types which should be exported. The default
is . Alternatively, a list of type number can be given. Exporting the
positions of all particles but in separate files might make sense if one
wants to distinguish the different particle types in the visualization
(i.e. by color or size). To export a type ``1`` use something along
``writevtk test.tcl 1``. To export types ``1``, ``5``, ``7``, which are
not to be distinguished in the visualization, use
``writevtk test.tcl 7 1 5``. The order in the list is arbitrary, but
duplicates are *not* ignored!

Reading and Writing PDB/PSF files
---------------------------------

The PDB (Brookhaven Protein DataBase) format is a widely used format for
describing atomistic configurations. PSF is a format that is used to
describe the topology of a PDB file.

When visualizing your system with VMD, it is recommended to use the VTF
format instead (see section [sec:vtf]), as it was specifically designed
for visualizations with VMD. In contrast to the PDB/PSF formats, in VTF
files it is possible to specify the VDW radii of the particles, to have
a varying simulation box size, etc.

: Writing the topology
~~~~~~~~~~~~~~~~~~~~~~

writepsf

Writes the current topology to the file (here, is not a channel, since
additional information cannot be written anyway). , and so on are
parameters describing a system consisting of equally long charged
polymers, counterions and salt. This information is used to set the
residue name and can be used to color the atoms in VMD. If you specify ,
the residue name is taken from the molecule identity of the particle. Of
course different kinds of topologies can also be handled by modified
versions of .

: Writing the coordinates
~~~~~~~~~~~~~~~~~~~~~~~~~

writepdb writepdbfoldchains writepdbfoldtopo

Variant writes the corresponding particle data.

Variant writes folded particle data where the folding is performed on
chain centers of mass rather than single particles. In order to fold in
this way the chain topology and box length must be specified. Note that
this method is outdated. Use variant instead.

Variant writes folded particle data where the folding is performed on
chain centers of mass rather than single particles. This method uses the
internal box length and topology information from espresso. If you wish
to shift particles prior to folding then supply the optional shift
information. should be a three member tcl list consisting of x, y, and z
shifts respectively and each number should be a floating point (ie with
decimal point).

: Reading the coordinates and interactions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

| readpdb pdb\_file type first\_id

Reads the positions and possibly charges, types and Lennard-Jones
interactions from the file and a corresponding Gromacs topology file .
The topology file must contain the ``atoms`` and ``atomtypes`` sections,
it may be necessary to use the Gromacs preprocessor to obtain a complete
file from a system configuration and a force field.

Any offset of the particle positions if removed, such that the lower
left corner bounding box of the particles is in the origin. If
``fit_to_box`` is given, the box size if increased to hold the particles
if necessary. If it is not set and the particles do not fit into the
box, the behavior is undefined.

sets the particle type for the added particles. If there is a topology
file give that contains a types for the particles, the particles get
types by the order in the topology file plus . If the corresponding type
in the topology file has a charge, it is used, otherwise the particle
charge defaults to zero.

The particles get consecutive id’s in the order of the pdb file,
starting at . Please be aware that existing particles get overwritten by
values from the file.

The ``lj_with`` section produces Lennard-Jones interactions between the
type and the types defined by the topology file. The interaction
parameters are calculated as :math:`\epsilon_{\text{othertype},j} =
\sqrt{\epsilon_{\text{othertype}} \epsilon_j}` and
:math:`\sigma_{\text{othertype},j}
=\frac{1}{2}\left( \sigma_{\text{othertype}} + \sigma_j \right)`, where
:math:`j` runs over the atomtypes defined in the topology file. This
corresponds to the combination rule 2 of Gromacs. There may be multiple
such sections. The cutoff is determined by as
:math:`\text{cutoff}\times \sigma_{ij}` in a relative fashion. The
potential is shifted so that it vanishes at the cutoff. The command
returns the number of particles that were successfully added.

Reading bonded interactions and dihedrals is currently not supported.

Online-visualisation with Mayavi or OpenGL
------------------------------------------

With the python interface, |es| features two possibilities for
online-visualization:

#. Using the mlab module to drive *Mayavi, a “3D scientific data
   visualization and plotting in Python”*. Mayavi has a user-friendly
   GUI to specify the appearance of the output.
   Additional requirements:
   python module *mayavi*, VTK (package *python-vtk* for Debian/Ubuntu).
   Note that only VTK from version 7.0.0 and higher has Python 3
   support.

#. A direct rendering engine based on *pyopengl*. As it is developed for |es|, 
   it supports the visualization of several specific features like
   external forces or constraints. It has no GUI to setup the
   appearance, but can be adjusted by a large set of parameters.
   Additional requirements:
   python module *PyOpenGL*.

Both are not meant to produce high quality renderings, but rather to
debug your setup and equilibration process.

General usage
~~~~~~~~~~~~~

The recommended usage of both tools is similar: Create the visualizer of
your choice and pass it the ``espressomd.System()`` object. Then write
your integration loop in a seperate function, which is started in a
non-blocking thread. Whenever needed, call ``update()`` to synchronize
the renderer with your system. Finally start the blocking visualization
window with ``start()``. See the following minimal code example::

    import espressomd 
    from espressomd import visualization 
    from threading import Thread

    system = espressomd.System() 
    system.cell_system.skin = 0.4
    system.time_step = 0.01
    system.box_l = [10,10,10]

    system.part.add(pos = [1,1,1]) system.part.add(pos = [9,9,9])

    visualizer = visualization.mayaviLive(system) 
    #visualizer = visualization.openGLLive(system)

    def main_thread(): 
        while True: 
            system.integrator.run(1)
            visualizer.update()

    t = Thread(target=main_thread) 
    t.daemon = True 
    t.start()
    visualizer.start()

Common methods for openGL and mayavi
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

| :meth:`espressomd.visualization.mayaviLive.update()` 
| :meth:`espressomd.visualization.openGLLive.update()`

``update()`` synchonizes system and visualizer, handles keyboard events for
openGLLive.

| :meth:`espressomd.visualization.mayaviLive.start()` 
| :meth:`espressomd.visualization.openGLLive.start()`

``start()`` starts the blocking visualizer window. 
Should be called after a seperate thread containing ``update()`` has been started.

| :meth:`espressomd.visualization.mayaviLive.registerCallback()`
| :meth:`espressomd.visualization.openGLLive.registerCallback()`

Registers the method ``callback()``, which is called every ``interval`` milliseconds. Useful for
live plotting (see sample script samples/python/visualization.py).

Mayavi visualizer
~~~~~~~~~~~~~~~~~

The mayavi visualizer is created with the following syntax:

:class:`espressomd.visualization.mayaviLive()`

Required paramters:
    * `system`: The espressomd.System() object.
Optional keywords:
    * `particle_sizes`:
        * `"auto"` (default)`: The Lennard-Jones sigma value of the self-interaction is used for the particle diameter.
        * `callable`: A lambda function with one argument. Internally, the numerical particle type is passed to the lambda function to determine the particle radius.
        * `list`: A list of particle radii, indexed by the particle type.

OpenGL visualizer
~~~~~~~~~~~~~~~~~

:class:`espressomd.visualization.openGLLive()`

The optional keywords in ``**kwargs`` to adjust the appearance of the visualization
have suitable default values for most simulations. Colors for particles,
bonds and constraints are specified by RGBA arrays, materials by an
array for the ambient, diffuse and specular (ADS) components. To
distinguish particle groups, arrays of RGBA or ADS entries are used,
which are indexed circularly by the numerical particle type.

Required paramters:
    * `system`: The espressomd.System() object.
Optional keywords:
    * `window_size`: Size of the visualizer window in pixels.
    * `name`: The name of the visualizer window.
    * `background_color`: RGB of the background.
    * `periodic_images`: Periodic repetitions on both sides of the box in xyzdirection.
    * `draw_box`: Draw wireframe boundaries.
    * `quality_spheres`: The number of subdivisions for spheres.
    * `quality_bonds`: The number of subdivisions for cylindrical bonds.
    * `quality_arrows`: The number of subdivisions for external force arrows.
    * `close_cut_distance`: The distance from the viewer to the near clipping plane.
    * `far_cut_distance`: The distance from the viewer to the far clipping plane.
    * `camera_position`: Initial camera position.
    * `camera_rotation`: Initial camera angles.
    * `particle_sizes`:     
        * `"auto"` (default)`: The Lennard-Jones sigma value of the self-interaction is used for the particle diameter.
        * `callable`: A lambda function with one argument. Internally, the numerical particle type is passed to the lambda function to determine the particle radius.
        * `list`: A list of particle radii, indexed by the particle type.
    * `particle_coloring`:  
        * `"auto"` (default)`: Colors of charged particles are specified by particle_charge_colors, neutral particles by particle_type_colors
        * `charge`: Minimum and maximum charge of all particles is determined by the visualizer. All particles are colored by a linear interpolation of the two colors given by particle_charge_colors according to their charge.
        * `type`: Particle colors are specified by particle_type_colors, indexed by their numerical particle type.
    * `particle_type_colors`: Colors for particle types.
    * `particle_type_materials`: Materials of the particle types.
    * `particle_charge_colors`: Two colors for min/max charged particles.
    * `draw_constraints`: Enables constraint visualization. For simple constraints (planes, spheres and cylinders), OpenGL primitives are used. Otherwise, visualization by rasterization is used.
    * `rasterize_pointsize`: Point size for the rasterization dots.
    * `rasterize_resolution`: Accuracy of the rasterization.
    * `quality_constraints`: The number of subdivisions for primitive constraints.
    * `constraint_type_colors`: Colors of the constaints by type.
    * `constraint_type_materials`: Materials of the constraints by type.
    * `draw_bonds`: Enables bond visualization.
    * `bond_type_radius`: Radii of bonds by type.
    * `bond_type_colors`: Color of bonds by type.
    * `bond_type_materials`: Materials of bonds by type.
    * `ext_force_arrows`: Enables external force visualization.
    * `ext_force_arrows_scale`: Scale factor for external force arrows.
    * `drag_enabled`: Enables mouse-controlled particles dragging (Default`: False)
    * `drag_force`: Factor for particle dragging
    * `light_pos`: If `auto` (default) is used, the light is placed dynamically in the particle barycenter of the system. Otherwise, a fixed coordinate can be set.
    * `light_color`: Light color
    * `light_brightness`: Brightness (inverse constant attenuation) of the light.
    * `light_size`: Size (inverse linear attenuation) of the light.

Keyboard controls
^^^^^^^^^^^^^^^^^

The camera is controlled via mouse (camera look direction),
WASD-Keyboard control (WS: move forwards/backwards, AD: move sidewards)
and the key pairs QE, RF, ZC (camera roll). With the keyword
``drag_enabled`` set to ``True``, the mouse can be used to exert a force
on particles in drag direction (scaled by ``drag_force`` and the
distance of particle and mouse cursor). Additional input functionality
for mouse and keyboard is possible by assigning callbacks to specified
keyboard or mouse buttons. This may be useful for realtime adjustment of
system parameters (temperature, interactions, particle properties etc)
of for demonstration purposes. An example can be found in
samples/python/billard.py.

Visualization example scripts
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Various example scripts can be found in the samples/python folder or in
some tutorials:

-  samples/python/visualization.py: LJ-Liquid with live plotting.

-  samples/python/visualization\_bonded.py: Sample for bond
   visualization.

-  samples/python/billard.py: Simple billard game including many
   features of the openGL visualizer.

-  samples/python/visualization\_openGL.py: Timer and keyboard callbacks
   for the openGL visualizer.

-  doc/tutorials/python/02-charged\_system/scripts/nacl\_units\_vis.py:
   Periodic NaCl crystal, see tutorial “Charged Systems”.

-  doc/tutorials/python/02-charged\_system/scripts/nacl\_units\_confined\_vis.py:
   Confined NaCl with interactively adjustable electric field, see
   tutorial “Charged Systems”.

-  doc/tutorials/python/08-visualization/scripts/visualization.py:
   LJ-Liquid visualization along with tutorial “Visualization”.

Finally, it is recommended to go through tutorial “Visualization” for
further code explanations. Also, the tutorial “Charged Systems” has two
visualization examples.

