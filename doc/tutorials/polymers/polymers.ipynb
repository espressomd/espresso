{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic polymer simulations in ESPResSo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we are going to investigate diffusion of a dissolved polymer using **ESPResSo**. For this tutorial, you should have fundamental knowledge of the lattice-Boltzmann method and Langevin dynamics. If you are unfamiliar with those, you can go through the respective tutorials in the `lattice_boltzmann` and `langevin_dynamics` folders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In these exercises we want to reproduce a classic result of polymer physics: the dependence \n",
    "of the diffusion coefficient of a polymer on its chain length. If no hydrodynamic interactions\n",
    "are present, one expects a scaling law $D \\propto N ^{- 1}$ and if they are present, a scaling law\n",
    "$D \\propto N^{- \\nu}$ is expected. Here $\\nu$ is the Flory exponent that plays a very prominent\n",
    "role in polymer physics. It has a value of $\\sim 3/5$ in good solvent conditions in 3D.\n",
    "Discussions on these scaling laws can be found in polymer physics textbooks like <a href='#[1]'>[1]</a>, <a href='#[2]'>[2]</a>, and <a href='#[3]'>[3, chapter 8]</a>.\n",
    "\n",
    "The reason for the different scaling law is the following: when being transported, every monomer\n",
    "creates a flow field that follows the direction of its motion. This flow field makes it easier for\n",
    "other monomers to follow its motion. This makes a polymer (given it is sufficiently long) diffuse\n",
    "more like a compact object including the fluid inside it, although it does not have clear boundaries.\n",
    "It can be shown that its motion can be described by its hydrodynamic radius. It is defined as:\n",
    "\n",
    "$$\n",
    "  \\left\\langle \\frac{1}{R_h} \\right\\rangle = \\left\\langle \\frac{1}{N^2}\\sum_{i\\neq j} \\frac{1}{\\left| r_i - r_j \\right|} \\right\\rangle\n",
    "$$\n",
    "\n",
    "This hydrodynamic radius exhibits the scaling law  $R_h \\propto N^{\\nu}$\n",
    "and the diffusion coefficient of a long polymer is proportional to its inverse $R_h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polymer models\n",
    "\n",
    "The diffusion coefficient $D$ of a spherical particle in a carrier fluid experiencing drag is\n",
    "related to the friction coefficient $\\zeta$ via the Einstein relation:\n",
    "\n",
    "$$\n",
    "  D = \\frac{k_{\\mathrm{B}}T}{\\zeta},\n",
    "$$\n",
    "\n",
    "with $k_{\\mathrm{B}}$ the Boltzmann constant and $T$ the temperature. For a sphere of radius $R$\n",
    "moving in a fluid of viscosity $\\eta$, the friction coefficient is obtained via the Stokes law:\n",
    "\n",
    "$$\n",
    "  \\zeta = 6\\pi\\eta R.\n",
    "$$\n",
    "\n",
    "Combining both equations yields the Stokes–Einstein relation:\n",
    "\n",
    "$$\n",
    "  D = \\frac{k_{\\mathrm{B}}T}{6\\pi\\eta R}.\n",
    "$$\n",
    "\n",
    "The simplest description of a polymer is the Rouse model, where beads are connected by springs.\n",
    "All beads experience a drag from the solvent, and the friction coefficient $\\gamma$ is identical\n",
    "for all beads. The solvent flows freely between beads and hydrodynamic interactions are neglected.\n",
    "The diffusion coefficient takes the following form:\n",
    "\n",
    "$$\n",
    "  D_{\\mathrm{R}} = \\frac{D_0}{N} = \\frac{k_{\\mathrm{B}}T}{\\gamma N},\n",
    "$$\n",
    "\n",
    "where $D_0$ is the diffusion coefficient of a single bead.\n",
    "\n",
    "To account for hydrodynamic interactions mediated by the solvent, i.e. the transport of solvent\n",
    "in contact with the beads and the correlation in the motion of beads due to the carried solvent,\n",
    "the Zimm model was created. For an ideal chain, it takes the following form:\n",
    "\n",
    "$$\n",
    "  D_{\\mathrm{Z}} = \\frac{8}{3\\sqrt{6\\pi^3}}\\frac{k_B T}{\\eta R} \\simeq 0.196\\frac{k_B T}{\\eta b N^{\\nu}},\n",
    "$$\n",
    "\n",
    "with $R$ the radius of the polymer and $b$ the length of the spring connecting the beads.\n",
    "\n",
    "For shorter polymers there is a transition region. It can be described\n",
    "by the Kirkwood–Zimm model:\n",
    "\n",
    "$$\n",
    "  D=\\frac{D_0}{N} + \\frac{k_B T}{6 \\pi \\eta } \\left\\langle \\frac{1}{R_h} \\right\\rangle\n",
    "$$\n",
    "\n",
    "Here $D_0$ is the monomer diffusion coefficient and $\\eta$ the \n",
    "viscosity of the fluid. For a finite system size the second part of the\n",
    "diffusion is subject to a $1/L$ finite size effect, because\n",
    "hydrodynamic interactions are proportional to the inverse\n",
    "distance and thus long ranged. It can be taken into account\n",
    "by a correction:\n",
    "\n",
    "$$\n",
    "  D=\\frac{D_0}{N} + \\frac{k_B T}{6 \\pi \\eta } \\left\\langle \\frac{1}{R_h} \\right\\rangle \\left( 1- \\left\\langle\\frac{R_h}{L} \\right\\rangle \\right)\n",
    "$$\n",
    "\n",
    "It is quite difficult to fit this analytical expression to simulation data with good accuracy.\n",
    "It will need a LB fluid, long simulation times and a careful analysis. For this tutorial, we\n",
    "will use an implicit solvent and short polymer lengths to keep the runtime short. If you want\n",
    "to collect data suitable for the Zimm model, simply set the global variable `POLYMER_MODEL` to\n",
    "`'Zimm'`, and increase the box size and number of beads in the polymer.\n",
    "\n",
    "We want to determine the long-time self diffusion coefficient from the mean square\n",
    "displacement of the center-of-mass of a single polymer. For large $t$ the mean square displacement is\n",
    "proportional to the time and the diffusion coefficient occurs as a \n",
    "prefactor:\n",
    "\n",
    "$$\n",
    "    D = \\lim_{t\\to\\infty}\\left[ \\frac{1}{6t} \\left\\langle \\left(\\vec{r}(t) - \\vec{r}(0)\\right)^2 \\right\\rangle \\right].\n",
    "$$\n",
    "\n",
    "This equation can be found in virtually any simulation textbook, like <a href='#[4]'>[4]</a>. We will set up a\n",
    "polymer in an implicit solvent, simulate for an appropriate amount of time, calculate the mean square\n",
    "displacement as a function of time and obtain the diffusion coefficient from a linear\n",
    "fit. However we will have a couple of steps inbetween and divide the full problem into\n",
    "subproblems that allow to (hopefully) fully understand the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diffusion of a polymer\n",
    "\n",
    "One of the typical applications of **ESPResSo** is the simulation of polymer chains with a bead-spring-model. For this we need a repulsive interaction between all beads, for which one usually takes a shifted and truncated Lennard-Jones (so-called Weeks–Chandler–Andersen or WCA) interaction, and additionally a bonded interaction between adjacent beads to hold the polymer together. You have already learned that the command\n",
    "\n",
    "```python\n",
    "system.non_bonded_inter[0, 0].lennard_jones.set_params(\n",
    "    epsilon=1.0, sigma=1.0, shift=0.25, cutoff=1.1225)\n",
    "```\n",
    "\n",
    "creates a Lennard-Jones interaction with $\\varepsilon=1.$, $\\sigma=1.$,\n",
    "$r_{\\text{cut}} = 1.1225$ and $\\varepsilon_{\\text{shift}}=0.25$ between particles\n",
    "of type 0, which is the desired repulsive interaction. The command\n",
    "\n",
    "```python\n",
    "fene = espressomd.interactions.FeneBond(k=7, r_0=1, d_r_max=2)\n",
    "```\n",
    "\n",
    "creates a `FeneBond` object (see **ESPResSo** manual for the details). What is left to be done is to add this bonded interaction to the system via\n",
    "\n",
    "```python\n",
    "system.bonded_inter.add(fene)\n",
    "```\n",
    "\n",
    "and to apply the bonded interaction to all monomer pairs of the polymer as shown in the script below.\n",
    "\n",
    "**ESPResSo** provides a function that tries to find monomer positions that minimize the overlap between\n",
    "monomers of a chain, *e.g.*:\n",
    "\n",
    "```python\n",
    "positions = espressomd.polymer.linear_polymer_positions(n_polymers=1,\n",
    "                                                        beads_per_chain=10,\n",
    "                                                        bond_length=1, seed=42,\n",
    "                                                        min_distance=0.9)\n",
    "```\n",
    "\n",
    "which would create positions for a single polymer with 10 monomers. Please check the documentation for a more detailed description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setting up the polymer and observables\n",
    "\n",
    "The first task is to compute the average hydrodynamic radius $R_h$, end-to-end distance $R_F$\n",
    "and radius of gyration $R_g$ for different polymer lengths. This will be achieved with the\n",
    "corresponding observables described in the user guide under\n",
    "[Analysis / Direct analysis routines / Chains](https://espressomd.github.io/doc/analysis.html#chains).\n",
    "\n",
    "The second task is to estimate the polymer diffusion coefficient for different polymer lengths\n",
    "using two methods:\n",
    "* the center of mass mean squared displacement method (introduced in a previous part of this tutorial)\n",
    "* the center of mass velocity autocorrelation method (also known as Green–Kubo method)\n",
    "\n",
    "For this purpose we can again use the [multiple tau correlator](https://espressomd.github.io/doc/analysis.html#details-of-the-multiple-tau-correlation-algorithm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Write a function with signature `build_polymer(system, n_monomers, polymer_params, fene)` that creates\n",
    "a linear polymer made of `n_monomers` particles, with parameters `polymer_params`. The particles need\n",
    "to be created and linked together with the `fene` bond."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "```python\n",
    "def build_polymer(system, n_monomers, polymer_params, fene):\n",
    "    positions = espressomd.polymer.linear_polymer_positions(\n",
    "        beads_per_chain=n_monomers, **polymer_params)\n",
    "    p_previous = None\n",
    "    for i, pos in enumerate(positions[0]):\n",
    "        p = system.part.add(pos=pos)\n",
    "        if p_previous is not None:\n",
    "            p.add_bond((fene, p_previous))\n",
    "        p_previous = p\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Write a function with signature `correlator_msd(pids_monomers, tau_max)` that returns a center-of-mass\n",
    "mean-squared displacement correlator that is updated every time step, and a function with signature\n",
    "`correlator_gk(pids_monomers, tau_max)` that returns a center-of-mass velocity correlator that is updated\n",
    "every 10 time steps. You can find examples in the user guide section\n",
    "[calculating a particle's diffusion coefficient](https://espressomd.github.io/doc/analysis.html#example-calculating-a-particle-s-diffusion-coefficient)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "```python\n",
    "def correlator_msd(pids_monomers, tau_max):\n",
    "    com_pos = espressomd.observables.ComPosition(ids=pids_monomers)\n",
    "    com_pos_cor = espressomd.accumulators.Correlator(\n",
    "        obs1=com_pos, tau_lin=16, tau_max=tau_max, delta_N=5,\n",
    "        corr_operation=\"square_distance_componentwise\", compress1=\"discard1\")\n",
    "    return com_pos_cor\n",
    "\n",
    "\n",
    "def correlator_gk(pids_monomers, tau_max):\n",
    "    com_vel = espressomd.observables.ComVelocity(ids=pids_monomers)\n",
    "    com_vel_cor = espressomd.accumulators.Correlator(\n",
    "        obs1=com_vel, tau_lin=16, tau_max=tau_max, delta_N=10,\n",
    "        corr_operation=\"scalar_product\", compress1=\"discard1\")\n",
    "    return com_vel_cor\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can simulate a polymer in the Rouse regime using an implicit solvent model, e.g. Langevin dynamics,\n",
    "or in the Zimm regime using a lattice-Boltzmann fluid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solvent_langevin(system, kT, gamma):\n",
    "    '''\n",
    "    Implicit solvation model based on Langevin dynamics (Rouse model).\n",
    "    '''\n",
    "    system.thermostat.set_langevin(kT=kT, gamma=gamma, seed=42)\n",
    "\n",
    "\n",
    "def solvent_lbm(system, kT, gamma):\n",
    "    '''\n",
    "    Lattice-based solvation model based on the LBM (Zimm model).\n",
    "    '''\n",
    "    lbf = espressomd.lb.LBFluidWalberla(kT=kT, seed=42, agrid=1, density=1,\n",
    "                                        kinematic_viscosity=5, tau=system.time_step,\n",
    "                                        single_precision=True)\n",
    "    system.actors.add(lbf)\n",
    "    system.thermostat.set_lb(LB_fluid=lbf, gamma=gamma, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Simulating the polymer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "\n",
    "import espressomd\n",
    "import espressomd.analyze\n",
    "import espressomd.accumulators\n",
    "import espressomd.observables\n",
    "import espressomd.polymer\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "espressomd.assert_features(['LENNARD_JONES'])\n",
    "\n",
    "# Setup constants\n",
    "BOX_L = 12.0\n",
    "TIME_STEP = 0.01\n",
    "LOOPS = 4000\n",
    "STEPS = 100\n",
    "KT = 1.0\n",
    "GAMMA = 5.0\n",
    "POLYMER_PARAMS = {'n_polymers': 1, 'bond_length': 1, 'seed': 42, 'min_distance': 0.9}\n",
    "POLYMER_MODEL = 'Rouse'\n",
    "assert POLYMER_MODEL in ('Rouse', 'Zimm')\n",
    "if POLYMER_MODEL == 'Zimm':\n",
    "    espressomd.assert_features(['WALBERLA'])\n",
    "    import espressomd.lb\n",
    "\n",
    "# System setup\n",
    "system = espressomd.System(box_l=3 * [BOX_L])\n",
    "system.cell_system.skin = 0.4\n",
    "\n",
    "# Lennard-Jones interaction\n",
    "system.non_bonded_inter[0, 0].lennard_jones.set_params(\n",
    "    epsilon=1.0, sigma=1.0, shift=\"auto\", cutoff=2.0**(1.0 / 6.0))\n",
    "\n",
    "# Fene interaction\n",
    "fene = espressomd.interactions.FeneBond(k=7, r_0=1, d_r_max=2)\n",
    "system.bonded_inter.add(fene)\n",
    "\n",
    "N_MONOMERS = np.array([6, 8, 10])\n",
    "\n",
    "com_pos_tau_results = []\n",
    "com_pos_msd_results = []\n",
    "com_vel_tau_results = []\n",
    "com_vel_acf_results = []\n",
    "rh_results = []\n",
    "rf_results = []\n",
    "rg_results = []\n",
    "for index, N in enumerate(N_MONOMERS):\n",
    "    logging.info(f\"Polymer size: {N}\")\n",
    "    build_polymer(system, N, POLYMER_PARAMS, fene)\n",
    "\n",
    "    logging.info(\"Warming up the polymer chain.\")\n",
    "    system.time_step = 0.002\n",
    "    system.integrator.set_steepest_descent(\n",
    "        f_max=1.0,\n",
    "        gamma=10,\n",
    "        max_displacement=0.01)\n",
    "    system.integrator.run(2000)\n",
    "    system.integrator.set_vv()\n",
    "    logging.info(\"Warmup finished.\")\n",
    "\n",
    "    logging.info(\"Equilibration.\")\n",
    "    system.time_step = TIME_STEP\n",
    "    system.thermostat.set_langevin(kT=1.0, gamma=50, seed=42)\n",
    "    system.integrator.run(2000)\n",
    "    logging.info(\"Equilibration finished.\")\n",
    "\n",
    "    system.thermostat.turn_off()\n",
    "\n",
    "    if POLYMER_MODEL == 'Rouse':\n",
    "        solvent_langevin(system, KT, GAMMA)\n",
    "    elif POLYMER_MODEL == 'Zimm':\n",
    "        solvent_lbm(system, KT, GAMMA)\n",
    "\n",
    "    logging.info(\"Warming up the system with the fluid.\")\n",
    "    system.integrator.run(1000)\n",
    "    logging.info(\"Warming up the system with the fluid finished.\")\n",
    "\n",
    "    # configure MSD correlator\n",
    "    com_pos_cor = correlator_msd(np.arange(N), LOOPS * STEPS)\n",
    "    system.auto_update_accumulators.add(com_pos_cor)\n",
    "\n",
    "    # configure Green-Kubo correlator\n",
    "    com_vel_cor = correlator_gk(np.arange(N), LOOPS * STEPS)\n",
    "    system.auto_update_accumulators.add(com_vel_cor)\n",
    "\n",
    "    logging.info(\"Sampling started.\")\n",
    "    rhs = np.zeros(LOOPS)\n",
    "    rfs = np.zeros(LOOPS)\n",
    "    rgs = np.zeros(LOOPS)\n",
    "    for i in range(LOOPS):\n",
    "        system.integrator.run(STEPS)\n",
    "        rhs[i] = system.analysis.calc_rh(\n",
    "            chain_start=0,\n",
    "            number_of_chains=1,\n",
    "            chain_length=N)[0]\n",
    "        rfs[i] = system.analysis.calc_re(\n",
    "            chain_start=0,\n",
    "            number_of_chains=1,\n",
    "            chain_length=N)[0]\n",
    "        rgs[i] = system.analysis.calc_rg(\n",
    "            chain_start=0,\n",
    "            number_of_chains=1,\n",
    "            chain_length=N)[0]\n",
    "    logging.info(\"Sampling finished.\")\n",
    "\n",
    "    # store results\n",
    "    com_pos_cor.finalize()\n",
    "    com_pos_tau_results.append(com_pos_cor.lag_times())\n",
    "    com_pos_msd_results.append(np.sum(com_pos_cor.result(), axis=1))\n",
    "    com_vel_cor.finalize()\n",
    "    com_vel_tau_results.append(com_vel_cor.lag_times())\n",
    "    com_vel_acf_results.append(com_vel_cor.result())\n",
    "    rh_results.append(rhs)\n",
    "    rf_results.append(rfs)\n",
    "    rg_results.append(rgs)\n",
    "\n",
    "    # reset system\n",
    "    system.part.clear()\n",
    "    system.actors.clear()\n",
    "    system.thermostat.turn_off()\n",
    "    system.auto_update_accumulators.clear()\n",
    "\n",
    "rh_results = np.array(rh_results)\n",
    "rf_results = np.array(rf_results)\n",
    "rg_results = np.array(rg_results)\n",
    "com_pos_tau_results = np.array(com_pos_tau_results)\n",
    "com_pos_msd_results = np.reshape(com_pos_msd_results, [len(N_MONOMERS), -1])\n",
    "com_vel_tau_results = np.array(com_vel_tau_results)\n",
    "com_vel_acf_results = np.reshape(com_vel_acf_results, [len(N_MONOMERS), -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data analysis\n",
    "\n",
    "We will calculate the means of time series with error bars obtained from\n",
    "the correlation-corrected standard error of the mean [<a href='#[5]'>5</a>,<a href='#[6]'>6</a>]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_error_mean_autocorrelation(time_series, variable_label):\n",
    "    '''\n",
    "    Calculate the mean and the correlation-corrected standard error\n",
    "    of the mean of time series by integrating the autocorrelation\n",
    "    function. See Janke 2002 [5] and Weigel, Janke 2010 [6].\n",
    "\n",
    "    Due to the short simulation length, it is not possible to fit an\n",
    "    exponential to the long-time tail. Instead, return a percentile.\n",
    "    '''\n",
    "    summary = []\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    for signal, N in zip(time_series, N_MONOMERS):\n",
    "        acf = espressomd.analyze.autocorrelation(signal - np.mean(signal))\n",
    "        # the acf cannot be integrated beyond tau=N/2\n",
    "        integral = np.array([acf[0] + 2 * np.sum(acf[1:j]) for j in np.arange(1, len(acf) // 2)])\n",
    "        # remove the noisy part of the integral\n",
    "        negative_number_list = np.nonzero(integral < 0)\n",
    "        if negative_number_list[0].size:\n",
    "            integral = integral[:int(0.95 * negative_number_list[0][0])]\n",
    "        # compute the standard error of the mean\n",
    "        std_err = np.sqrt(integral / acf.size)\n",
    "        # due to the small sample size, the long-time tail is not\n",
    "        # well resolved and cannot be fitted, so we use a percentile\n",
    "        asymptote = np.percentile(std_err, 75)\n",
    "        # plot the integral and asymptote\n",
    "        p = plt.plot([0, len(std_err)], 2 * [asymptote], '--')\n",
    "        plt.plot(np.arange(len(std_err)) + 1, std_err,\n",
    "                 '-', color=p[0].get_color(),\n",
    "                 label=rf'$\\int {variable_label}$ for N={N}')\n",
    "        summary.append((np.mean(signal), asymptote))\n",
    "    plt.xlabel(r'Lag time $\\tau / \\Delta t$')\n",
    "    plt.ylabel(rf'$\\int_{{-\\tau}}^{{+\\tau}} {variable_label}$')\n",
    "    plt.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return np.array(summary)\n",
    "\n",
    "\n",
    "def fitting_polymer_theory(polymer_model, n_monomers, diffusion, rh_exponent):\n",
    "    '''\n",
    "    Fit the appropriate polymer diffusion coefficient equation (Rouse or\n",
    "    Kirkwood-Zimm).\n",
    "    '''\n",
    "    def rouse(x, a):\n",
    "        return a / x\n",
    "\n",
    "    def kirkwood_zimm(x, a, b, exponent):\n",
    "        return a / x + b / x**exponent\n",
    "\n",
    "    x = np.linspace(min(n_monomers) - 0.5, max(n_monomers) + 0.5, 20)\n",
    "\n",
    "    if polymer_model == 'Rouse':\n",
    "        popt, _ = scipy.optimize.curve_fit(rouse, n_monomers, diffusion)\n",
    "        label = rf'$D^{{\\mathrm{{fit}}}} = \\frac{{{popt[0]:.2f}}}{{N}}$'\n",
    "        y = rouse(x, popt[0])\n",
    "    elif polymer_model == 'Zimm':\n",
    "        fitting_function = kirkwood_zimm\n",
    "        popt, _ = scipy.optimize.curve_fit(\n",
    "            lambda x, a, b: kirkwood_zimm(x, a, b, rh_exponent), n_monomers, diffusion)\n",
    "        y = kirkwood_zimm(x, popt[0], popt[1], rh_exponent)\n",
    "        label = f'''\\\n",
    "        $D^{{\\\\mathrm{{fit}}}} = \\\n",
    "            \\\\frac{{{popt[0]:.2f}}}{{N}} + \\\n",
    "            \\\\frac{{{popt[1] * 6 * np.pi:.3f} }}{{6\\\\pi}} \\\\cdot \\\n",
    "            \\\\frac{{{1}}}{{N^{{{rh_exponent:.2f}}}}}$ \\\n",
    "        '''\n",
    "    return x, y, label, popt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Distance-based macromolecular properties\n",
    "\n",
    "How do $R_h$, $R_g$, $R_F$ and the diffusion coefficient $D$ depend on the number of monomers?\n",
    "You can refer to the Flory theory of polymers, and assume you are simulating a real polymer in a\n",
    "good solvent, with Flory exponent $\\nu \\approx 0.588$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the end-to-end distance $R_F$ of the polymer as a function of the number of monomers. What relation do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end-to-end distance follows the law $R_F = c_F N^\\nu$ with $c_F$ a constant and $\\nu$ the Flory exponent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_summary = standard_error_mean_autocorrelation(rf_results, r'\\operatorname{acf}(R_F)')\n",
    "rf_exponent, rf_prefactor = np.polyfit(np.log(N_MONOMERS), np.log(rf_summary[:, 0]), 1)\n",
    "rf_prefactor = np.exp(rf_prefactor)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "x = np.linspace(min(N_MONOMERS) - 0.5, max(N_MONOMERS) + 0.5, 20)\n",
    "plt.plot(x, rf_prefactor * x**rf_exponent, '-',\n",
    "         label=rf'$R_F^{{\\mathrm{{fit}}}} = {rf_prefactor:.2f} N^{{{rf_exponent:.2f}}}$')\n",
    "plt.errorbar(N_MONOMERS, rf_summary[:, 0],\n",
    "             yerr=rf_summary[:, 1],\n",
    "             ls='', marker='o', capsize=5, capthick=1,\n",
    "             label=r'$R_F^{\\mathrm{simulation}}$')\n",
    "plt.xlabel('Number of monomers $N$')\n",
    "plt.ylabel(r'End-to-end distance [$\\sigma$]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the radius of gyration $R_g$ of the polymer as a function of the number of monomers. What relation do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The radius of gyration follows the law $R_g = c_g N^\\nu$ with $c_g$ a constant and $\\nu$ the Flory exponent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_summary = standard_error_mean_autocorrelation(rg_results, r'\\operatorname{acf}(R_g)')\n",
    "rg_exponent, rg_prefactor = np.polyfit(np.log(N_MONOMERS), np.log(rg_summary[:, 0]), 1)\n",
    "rg_prefactor = np.exp(rg_prefactor)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "x = np.linspace(min(N_MONOMERS) - 0.5, max(N_MONOMERS) + 0.5, 20)\n",
    "plt.plot(x, rg_prefactor * x**rg_exponent, '-',\n",
    "         label=rf'$R_g^{{\\mathrm{{fit}}}} = {rg_prefactor:.2f} N^{{{rg_exponent:.2f}}}$')\n",
    "plt.errorbar(N_MONOMERS, rg_summary[:, 0],\n",
    "             yerr=rg_summary[:, 1],\n",
    "             ls='', marker='o', capsize=5, capthick=1,\n",
    "             label=r'$R_g^{\\mathrm{simulation}}$')\n",
    "plt.xlabel('Number of monomers $N$')\n",
    "plt.ylabel('Radius of gyration [$\\sigma$]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an ideal polymer:\n",
    "\n",
    "$$\\frac{R_F^2}{R_g^2} = 6$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2_rg2_ratio = rf_summary[:, 0]**2 / rg_summary[:, 0]**2\n",
    "print(np.around(rf2_rg2_ratio, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the hydrodynamic radius $R_h$ of the polymers as a function of the number of monomers. What relation do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hydrodynamic radius can be calculated via the Stokes radius, i.e. the radius of a sphere that\n",
    "diffuses at the same rate as the polymer. An approximative formula is $R_h \\approx c_h N^{1/3}$\n",
    "with $c_h$ a constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rh_summary = standard_error_mean_autocorrelation(rh_results, r'\\operatorname{acf}(R_h)')\n",
    "rh_exponent, rh_prefactor = np.polyfit(np.log(N_MONOMERS), np.log(rh_summary[:, 0]), 1)\n",
    "rh_prefactor = np.exp(rh_prefactor)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "x = np.linspace(min(N_MONOMERS) - 0.5, max(N_MONOMERS) + 0.5, 20)\n",
    "plt.plot(x, rh_prefactor * x**rh_exponent, '-',\n",
    "         label=rf'$R_h^{{\\mathrm{{fit}}}} = {rh_prefactor:.2f} N^{{{rh_exponent:.2f}}}$')\n",
    "plt.errorbar(N_MONOMERS, rh_summary[:, 0],\n",
    "             yerr=rh_summary[:, 1],\n",
    "             ls='', marker='o', capsize=5, capthick=1,\n",
    "             label=r'$R_h^{\\mathrm{simulation}}$')\n",
    "plt.xlabel('Number of monomers $N$')\n",
    "plt.ylabel('Hydrodynamic radius [$\\sigma$]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Diffusion coefficient using the MSD method\n",
    "\n",
    "Calculate the diffusion coefficient of the polymers using the mean-squared displacement.\n",
    "\n",
    "Recalling that for large $t$ the diffusion coefficient can be expressed as:\n",
    "\n",
    "$$6D = \\lim_{t\\to\\infty} \\frac{\\partial \\operatorname{MSD}(t)}{\\partial t}$$\n",
    "\n",
    "which is simply the slope of the MSD in the diffusive mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff for the diffusive regime (approximative)\n",
    "tau_f_index = 40\n",
    "# cutoff for the data series (larger lag times have larger variance due to undersampling)\n",
    "tau_max_index = 70\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.xlabel(r'$\\tau$ [$\\Delta t$]')\n",
    "plt.ylabel(r'MSD [$\\sigma^2$]')\n",
    "for index, (tau, msd) in enumerate(zip(com_pos_tau_results, com_pos_msd_results)):\n",
    "    plt.loglog(tau[1:120], msd[1:120], label=f'N={N_MONOMERS[index]}')\n",
    "plt.loglog(2 * [tau[tau_f_index]], [0, np.max(com_pos_msd_results)], '-', color='black')\n",
    "plt.text(tau[tau_f_index], np.max(com_pos_msd_results), r'$\\tau_{f}$')\n",
    "plt.loglog(2 * [tau[tau_max_index]], [0, np.max(com_pos_msd_results)], '-', color='black')\n",
    "plt.text(tau[tau_max_index], np.max(com_pos_msd_results), r'$\\tau_{max}$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_msd = np.zeros(len(N_MONOMERS))\n",
    "plt.figure(figsize=(10, 8))\n",
    "weights = com_pos_cor.sample_sizes()\n",
    "for index, (tau, msd) in enumerate(zip(com_pos_tau_results, com_pos_msd_results)):\n",
    "    a, b = np.polyfit(tau[tau_f_index:tau_max_index], msd[tau_f_index:tau_max_index],\n",
    "                      1, w=weights[tau_f_index:tau_max_index])\n",
    "    x = np.array([tau[1], tau[tau_max_index - 1]])\n",
    "    p = plt.plot(x, a * x + b, '-')\n",
    "    plt.plot(tau[1:tau_max_index], msd[1:tau_max_index], 'o', color=p[0].get_color(),\n",
    "             label=rf'$N=${N_MONOMERS[index]}')\n",
    "    diffusion_msd[index] = a / 6\n",
    "plt.xlabel(r'$\\tau$ [$\\Delta t$]')\n",
    "plt.ylabel(r'MSD [$\\sigma^2$]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the dependence of the diffusion coefficient on the hydrodynamic radius.\n",
    "\n",
    "Recalling the formula for the diffusion coefficient of a short polymer in the Kirkwood–Zimm model:\n",
    "\n",
    "$$D = \\frac{D_0}{N} + \\frac{k_B T}{6 \\pi \\eta} \\left\\langle \\frac{1}{R_h} \\right\\rangle$$\n",
    "\n",
    "where $\\eta$ is the fluid viscosity and $D_0 = k_BT\\gamma^{-1}$ the monomer diffusion coefficient,\n",
    "with $\\gamma$ the fluid friction coefficient. For the Rouse regime (implicit solvent),\n",
    "the second term disappears.\n",
    "\n",
    "Hint:\n",
    "\n",
    "* for the Rouse regime, use $D = \\alpha N^{-1}$ and solve for $\\alpha$\n",
    "* for the Zimm regime, use $D = \\alpha_1 N^{-1} + \\alpha_2 N^{-\\beta}$\n",
    "  with `rh_exponent` for $\\beta$ and solve for $\\alpha_1, \\alpha_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "x, y, label, popt_msd = fitting_polymer_theory(POLYMER_MODEL, N_MONOMERS, diffusion_msd, rh_exponent)\n",
    "plt.plot(x, y, '-', label=label)\n",
    "plt.plot(N_MONOMERS, diffusion_msd, 'o', label=r'$D^{\\mathrm{simulation}}$')\n",
    "plt.xlabel('Number of monomers $N$')\n",
    "plt.ylabel(r'Diffusion coefficient [$\\sigma^2/t$]')\n",
    "plt.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Diffusion coefficient using the Green–Kubo method\n",
    "\n",
    "Plot the autocorrelation function and check that the decay is roughly exponential.\n",
    "\n",
    "Hint: use $D = \\alpha e^{-\\beta \\tau}$ and solve for $\\alpha, \\beta$. You can leave out\n",
    "the first data point in the ACF if necessary, and limit the fit to the stable region\n",
    "in the first 20 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential(x, a, b):\n",
    "    return a * np.exp(-b * x)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "for N, tau, acf in zip(N_MONOMERS, com_vel_tau_results, com_vel_acf_results):\n",
    "    popt, _ = scipy.optimize.curve_fit(exponential, tau[:20], acf[:20])\n",
    "    x = np.linspace(tau[0], tau[20 - 1], 100)\n",
    "    p = plt.plot(x, exponential(x, *popt), '-')\n",
    "    plt.plot(tau[:20], acf[:20], 'o',\n",
    "             color=p[0].get_color(), label=rf'$R(\\tau)$ for N = {N}')\n",
    "plt.xlabel(r'$\\tau$')\n",
    "plt.ylabel('Autocorrelation function')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Green–Kubo integral for the diffusion coefficient take the following form:\n",
    "\n",
    "$$D = \\frac{1}{3} \\int_0^{+\\infty} \\left<\\vec{v_c}(\\tau)\\cdot\\vec{v_c}(0)\\right>\\, \\mathrm{d}\\tau$$\n",
    "\n",
    "Since our simulation is finite in time, we need to integrate up until $\\tau_{\\mathrm{int}}$. To find\n",
    "the optimal value of $\\tau_{\\mathrm{int}}$, plot the integral as a function of $\\tau_{\\mathrm{int}}$\n",
    "until you see a plateau. This plateau is usually followed by strong oscillations due to low\n",
    "statistics in the long time tail of the autocorrelation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_gk = []\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "for N, tau, acf in zip(N_MONOMERS, com_vel_tau_results, com_vel_acf_results):\n",
    "    x = np.arange(2, 28)\n",
    "    y = [1 / 3 * np.trapz(acf[:j], tau[:j]) for j in x]\n",
    "    plt.plot(tau[x], y, label=rf'$D(\\tau_{{\\mathrm{{int}}}})$ for $N = {N}$')\n",
    "    diffusion_gk.append(np.mean(y[10:]))\n",
    "plt.xlabel(r'$\\tau_{\\mathrm{int}}$')\n",
    "plt.ylabel(r'$\\frac{1}{3} \\int_{\\tau=0}^{\\tau_{\\mathrm{int}}} \\left<\\vec{v_c}(\\tau)\\cdot\\vec{v_c}(0)\\right>\\, \\mathrm{d}\\tau$')\n",
    "plt.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the dependence of the diffusion coefficient on the hydrodynamic radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "x, y, label, popt_gk = fitting_polymer_theory(POLYMER_MODEL, N_MONOMERS, diffusion_gk, rh_exponent)\n",
    "plt.plot(x, y, '-', label=label)\n",
    "plt.plot(N_MONOMERS, diffusion_gk, 'o', label=r'$D^{\\mathrm{simulation}}$')\n",
    "plt.xlabel('Number of monomers $N$')\n",
    "plt.ylabel(r'Diffusion coefficient [$\\sigma^2/t$]')\n",
    "plt.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare the value of the diffusion coefficients calculated with the MSD and Green–Kubo methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'N\\tMSD\\t\\tGK\\t\\tdifference')\n",
    "for N, d_msd, d_gk in zip(N_MONOMERS, diffusion_msd, diffusion_gk):\n",
    "    print(f'{N}\\t{d_msd:.2e}\\t{d_gk:.2e}\\t{np.ceil(np.abs(d_msd-d_gk) * 100 / d_msd):.0f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "<a id='[1]'></a>[1] P. G. de Gennes. *Scaling Concepts in Polymer Physics*. Cornell University Press, Ithaca, NY, 1979.  \n",
    "<a id='[2]'></a>[2] M. Doi. *Introduction to Polymer Physics.* Clarendon Press, Oxford, 1996.  \n",
    "<a id='[3]'></a>[3] Michael Rubinstein and Ralph H. Colby. *Polymer Physics.* Oxford University Press, Oxford, UK, 2003. ISBN: 978-0-19-852059-7  \n",
    "<a id='[4]'></a>[4] Daan Frenkel and Berend Smit. *Understanding Molecular Simulation*, section 4.4.1. Academic Press, San Diego, second edition, 2002.  \n",
    "<a id='[5]'></a>[5] W. Janke, Statistical analysis of simulations: Data correlations and error estimation, *Quantum Simulations of Complex Many-Body Systems: From Theory to Algorithms*, Lecture Notes, J. Grotendorst, D. Marx, A. Muramatsu (Eds.), John von Neumann Institute for Computing, 10:423–445, 2002. https://www.physik.uni-leipzig.de/~janke/Paper/nic10_423_2002.pdf  \n",
    "<a id='[6]'></a>[6] M. Weigel, W. Janke, Error estimation and reduction with cross correlations, *Phys. Rev. E*, 81:066701, 2010, doi:[10.1103/PhysRevE.81.066701](https://doi.org/10.1103/PhysRevE.81.066701); Erratum-ibid 81:069902, 2010, doi:[10.1103/PhysRevE.81.069902](https://doi.org/10.1103/PhysRevE.81.069902).  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
